{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import fitz\n",
    "import warnings , math, collections , os, re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\"\n",
    "#path = r\"C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\"\n",
    "\n",
    "samco_path = path + r\"\\files\\samco\\58_30-Apr-24_FS.pdf\"\n",
    "dry_run_path = path + r\"\\output\\DryRun.pdf\"\n",
    "indice_path = path + r\"\\output\\pkl\\indices_var.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_financial_indices(path:str):\n",
    "    final_indices = set()\n",
    "    with open(path , 'rb') as file:\n",
    "        indices = pickle.load(file)  \n",
    "        for k,v in indices.items():\n",
    "            temp = [k] + v\n",
    "            for t in temp:\n",
    "                final_indices.add(t)\n",
    "    \n",
    "    return list(final_indices)\n",
    "\n",
    "\"\"\" Highlights important financial indices in the pdf, does other pre\n",
    "analysis of data.\n",
    "Args: list of indices, string of pdf path\n",
    "Returns: dict of pages highlighted, string of output pdf, dict of pages contaiting FUND NAMES\n",
    "\"\"\"\n",
    "def check_indice_highlight(path:str, indices_variations:list, fund_pattern:str, fund_size:int):\n",
    "    doc = fitz.open(path)\n",
    "    page_count = doc.page_count #No of pages\n",
    "    \n",
    "    pages = [i for i in range(page_count)]\n",
    "    important_pages = dict.fromkeys(pages, 0)\n",
    "    fund_titles = dict.fromkeys(pages, \"\")\n",
    "\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        \n",
    "        text_instances = page.get_text('dict')[\"blocks\"]\n",
    "        \n",
    "        #sort for all data in pdf document \n",
    "        sorted_text_instances = sorted(text_instances, key=lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "        \n",
    "        # rect = fitz.Rect((35,120,250,765))\n",
    "        # page.add_highlight_annot(rect)\n",
    "\n",
    "        for pgn,block in enumerate(sorted_text_instances):     \n",
    "            if \"lines\" not in block:\n",
    "                continue\n",
    "            \n",
    "            for line in block[\"lines\"]: \n",
    "                for span in line[\"spans\"]:\n",
    "                    if span['flags'] in [20,25]:  # learn flag logic , rn set for all flags value\n",
    "                        span_text = span['text'].strip().lower()\n",
    "                        \n",
    "                        \n",
    "                        #FUND PAGE CHECK\n",
    "                        conditions = [\n",
    "                            pgn in range(0,15),\n",
    "                            re.match(fund_pattern, span_text, re.IGNORECASE),\n",
    "                            span['size'] >fund_size\n",
    "                        ]\n",
    "                        if all(conditions):\n",
    "        \n",
    "                            fund_titles[page_num] = span_text  \n",
    "                        \n",
    "                        #CHECK IMP FINANCE INDICES  \n",
    "                        for term in indices_variations:  \n",
    "                            pattern = r'\\b' + re.escape(term.lower()) + r'\\b'\n",
    "                            if re.search(pattern, span_text):\n",
    "\n",
    "                                #count highlights\n",
    "                                important_pages[page_num] +=1\n",
    "                                #mark content\n",
    "                                rect = fitz.Rect(span['bbox']) \n",
    "                                page.add_highlight_annot(rect)\n",
    "                                break  #optional , one highlight\n",
    "\n",
    "    \n",
    "    output_path = None\n",
    "    if any(important_pages.values()):\n",
    "        output_path = path.replace('.pdf', '_highlighted.pdf')\n",
    "        doc.save(output_path)\n",
    "\n",
    "    doc.close()\n",
    "    return important_pages, output_path, fund_titles\n",
    "\n",
    "\n",
    "\"\"\" Get the clipped data in the bbox provided and store in nested dict\n",
    "Args: input path, dryrun path, important pages, bbox coords\n",
    "Returns: dict { 'page' : int 'block': dict}\"\"\"\n",
    "def get_clipped_data(input:str, output:str, pageSelect:list, bbox:list[set], fund_names:dict):\n",
    "    \n",
    "    document = fitz.open(input)\n",
    "    finalData = []\n",
    "    \n",
    "    for pgn in pageSelect:\n",
    "        #get the page\n",
    "        page = document[pgn]\n",
    "        fundName = fund_names[pgn]\n",
    "\n",
    "        #get all block\n",
    "        final_blocks = []\n",
    "        for box in bbox:\n",
    "            blocks = page.get_text('dict', clip = box)['blocks'] #get all blocks\n",
    "            filtered_blocks = [block for block in blocks if block['type']==0 and 'lines' in block] #only text blocks\n",
    "            sorted_blocks = sorted(filtered_blocks, key= lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "            final_blocks.extend(sorted_blocks)\n",
    "        \n",
    "        \n",
    "        finalData.append({\n",
    "            \"page\": pgn,\n",
    "            \"fundname\": fundName,\n",
    "            \"block\": final_blocks,\n",
    "        })\n",
    "            \n",
    "    return finalData\n",
    "\n",
    "\n",
    "def get_pdf_data(input:str, pageSelect:list, fund_names:dict):\n",
    "    \n",
    "    document = fitz.open(input)\n",
    "    finalData = []\n",
    "    \n",
    "    for pgn in pageSelect:\n",
    "        #get the page\n",
    "        page = document[pgn]\n",
    "        fundName = fund_names[pgn]\n",
    "    \n",
    "        blocks = page.get_text('dict')['blocks'] #get all blocks\n",
    "        \n",
    "        filtered_blocks = [block for block in blocks if block['type']==0 and 'lines' in block]\n",
    "        sorted_blocks = sorted(filtered_blocks, key= lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "        \n",
    "        finalData.append({\n",
    "            \"page\": pgn,\n",
    "            \"fundname\": fundName,\n",
    "            \"block\": sorted_blocks,\n",
    "        })\n",
    "            \n",
    "    return finalData\n",
    "\n",
    "\n",
    "def get_pdf_text_data(path:str, pageSelect:list, fund_names:dict):\n",
    "    document = fitz.open(path)\n",
    "    page_count = document.page_count\n",
    "    finalData = list()\n",
    "    \n",
    "    for pgn in pageSelect:\n",
    "        page = document[pgn]\n",
    "        fund_name = fund_names[pgn]\n",
    "        blocks = page.get_text('text')\n",
    "        \n",
    "        finalData.append({\n",
    "            'page': pgn,\n",
    "            'fundname': fund_name,\n",
    "            'block': blocks\n",
    "        })\n",
    "    \n",
    "    return finalData\n",
    "        \n",
    "\n",
    "def extract_span_data(data:list, name:list): #all\n",
    "    final_data = dict()\n",
    "    for pgn,page in enumerate(data):\n",
    "        pgn_content = []\n",
    "        for blocks in page['block']:\n",
    "            for line in blocks['lines']:\n",
    "                spans = line.get('spans',[])\n",
    "                for span in spans:\n",
    "                    \n",
    "                    text = span['text'].strip()\n",
    "                    size = span['size']\n",
    "                    color = span['color']\n",
    "                    origin = span['origin']\n",
    "                    bbox = span['bbox']\n",
    "                \n",
    "                    pgn_content.append([size,text,color,origin,bbox])\n",
    "                    \n",
    "        final_data[page['fundname']] = pgn_content\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def clean_block_data(blocks):\n",
    "    \n",
    "    remove_text = ['Purchase','Amount','thereafter','.','. ',',',':','st',\";\",\"-\",'st ',' ','th', 'th ', 'rd', 'rd ', 'nd', 'nd ','','`','(Date of Allotment)']\n",
    "    \n",
    "    sorted_blocks = sorted(blocks, key=lambda x: (x[3][1],x[3][0]))\n",
    "    \n",
    "    cleaned_blocks = []\n",
    "    for block in sorted_blocks:\n",
    "        size, text, color, origin, bbox = block\n",
    "        if text not in remove_text:\n",
    "            cleaned_blocks.append(block)\n",
    " \n",
    "    processed_blocks = []\n",
    "    # adjust size based on color and size\n",
    "    for block in cleaned_blocks:\n",
    "        size, text, color, origin, bbox = block\n",
    "        text = text.strip()\n",
    "        if size in [9.0,8.0] and color == -1:\n",
    "            size = 20.0  # Update size to 20.0\n",
    "        processed_blocks.append([size, text, color, origin, bbox])\n",
    "                \n",
    "\n",
    "    # group blocks by rounded y-coordinate\n",
    "    grouped_blocks = defaultdict(list)\n",
    "    for block in processed_blocks:\n",
    "        y_coord = math.ceil(block[3][1])# Extract and round the y-coordinate\n",
    "        size = block[0]\n",
    "        grouped_blocks[(y_coord,size)].append(block)\n",
    "\n",
    "    # Combine blocks with the same y-coordinate\n",
    "    combined_blocks = []\n",
    "    for key, group in grouped_blocks.items():\n",
    "        \n",
    "        if key[1] == 20:\n",
    "            combined_text = \" \".join(item[1] for item in group).strip()\n",
    "            if combined_text:  # Ignore whitespace-only text\n",
    "                size, color, origin, bbox = group[0][0], group[0][2], group[0][3],group[0][4]\n",
    "                combined_blocks.append([size, combined_text, color, origin,bbox])\n",
    "        \n",
    "        else:\n",
    "            for item in group:\n",
    "                combined_blocks.append(item)\n",
    "\n",
    "    return combined_blocks\n",
    "\n",
    "def process_text_data(text_data):\n",
    "    \n",
    "    updated_text_data = {}\n",
    "\n",
    "    for fund, data in text_data.items():\n",
    "        blocks = data\n",
    "        cleaned_blocks = clean_block_data(blocks)\n",
    "        updated_text_data[fund] = cleaned_blocks\n",
    "\n",
    "    return updated_text_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "financial_indices = get_financial_indices(indice_path)\n",
    "pdfInd = pd.DataFrame({'indexes': financial_indices})\n",
    "\n",
    "excel_path  = path+ r'\\files\\financial_indices.xlsx'\n",
    "pdfInd.indexes.to_excel(excel_path) #remove first col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path  = samco_path\n",
    "financial_indices = get_financial_indices(indice_path)\n",
    "fund_pattern = r\"^(samco|tata|canara)\"\n",
    "fund_size = 16 #anything greater than this\n",
    "\n",
    "highlight_pages, saved_path, fund_pages =  check_indice_highlight(file_path, financial_indices, fund_pattern, fund_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagedf = pd.DataFrame({'title': fund_pages.values(),'highlight_count': highlight_pages.values()})\n",
    "\n",
    "\"\"\"_summary_ fund is located only on certain pages, based on no. of \n",
    "highlights we know which pages are imp. automate this content later\n",
    "\"\"\"\n",
    "pagedf.to_excel(path + r'\\output\\example.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [ 3,5,7,9,11]\n",
    "bbox = [(35,120,250,765)]\n",
    "fund_pages = fund_pages\n",
    "file_path = samco_path\n",
    "\n",
    "data = get_clipped_data(file_path, dry_run_path, pages, bbox, fund_pages)\n",
    "text_data = extract_span_data(data,[])\n",
    "cleaned_data = process_text_data(text_data) #personalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pdf_new( data:list, output_path:str):\n",
    "    pdf = fitz.open()\n",
    "    \n",
    "    for fund, item in data.items():\n",
    "        page = pdf.new_page()\n",
    "        \n",
    "        text_position = 32\n",
    "        #section title\n",
    "        title_font_size = 24\n",
    "        try:\n",
    "            page.insert_text(\n",
    "                (72, text_position), #initalizor\n",
    "                fund,\n",
    "                fontsize=title_font_size,\n",
    "                fontname=\"helv\",\n",
    "                color=(0, 0, 1),\n",
    "            )        \n",
    "        except Exception as e:\n",
    "            print(f\"Error while parsing fund {e}\")\n",
    "        \n",
    "        for block in item:\n",
    "            size,text,color,origin,bbox = block\n",
    "            #print(block)\n",
    "            try:\n",
    "                page.insert_text(\n",
    "                    (origin[0], origin[1]),\n",
    "                    text,\n",
    "                    fontsize=size,\n",
    "                    fontname=\"helv\",\n",
    "                    color=tuple(int(color & 0xFFFFFF) for _ in range(3)))#unsigned int value so (0,0,0)\n",
    "            \n",
    "            except Exception:\n",
    "                page.insert_text(\n",
    "                    (origin[0], origin[1]),\n",
    "                    text,\n",
    "                    fontsize=size,\n",
    "                    fontname=\"helv\",\n",
    "                    color=(1, 0, 0),\n",
    "                )\n",
    "                \n",
    "    pdf.save(output_path)\n",
    "    pdf.close()\n",
    "    print(f\" PDF generated to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_size = 20\n",
    "content_size = 10\n",
    "\n",
    "def create_nested_dict(cleaned_data:dict,header_size:float, content_size:float):\n",
    "    final_text_data = dict()\n",
    "    final_matrix = dict()\n",
    "\n",
    "    for fund, items in cleaned_data.items(): #ech fund\n",
    "        \n",
    "        #step 1 extract size, coord\n",
    "        coordinates = list()\n",
    "        sizes = set()\n",
    "        \n",
    "        for item in items: #size,text,color,origin\n",
    "            origin = tuple(item[3])\n",
    "            coordinates.append(origin)\n",
    "            sizes.add(item[0])\n",
    "        \n",
    "        coordinates = sorted(set(coordinates), key=lambda c: (c[1], c[0]))  # Sort by y, then x\n",
    "        sizes = sorted(sizes, reverse=True)  \n",
    "        \n",
    "        #step 2 create matrix\n",
    "        coord_to_index = {coord: idx for idx, coord in enumerate(coordinates)}  # (x,y) at pos 0 etc. ROWS\n",
    "        size_to_index = {font: idx for idx, font in enumerate(sizes)}  # COLUMNS\n",
    "        matrix = np.zeros((len(coordinates), len(sizes)), dtype=object)\n",
    "        \n",
    "        \n",
    "        #step 3\n",
    "        nested_dict = {}\n",
    "        current_header = None\n",
    "        for item in items:\n",
    "            origin = tuple(item[3])\n",
    "            size = item[0]\n",
    "            text = item[1].strip()\n",
    "            \n",
    "            #populate the matrix\n",
    "            if origin in coord_to_index and size in size_to_index:\n",
    "                row = coord_to_index[origin]\n",
    "                col = size_to_index[size]\n",
    "                \n",
    "                if matrix[row,col] == 0:\n",
    "                    matrix[row,col] ==r\"nil\"\n",
    "                matrix[row,col] == text\n",
    "            \n",
    "            #build nested dict\n",
    "            if size == header_size:\n",
    "                current_header = \" \".join(txt for txt in text.split(\" \") if txt !=\"\").lower()\n",
    "                nested_dict[current_header] = []\n",
    "            elif size<= content_size and current_header:\n",
    "                nested_dict[current_header].append(item)\n",
    "                \n",
    "        final_text_data[fund] = nested_dict        \n",
    "        matrix_df = pd.DataFrame(matrix, index=coordinates, columns=sizes)\n",
    "        final_matrix[fund] = matrix_df\n",
    "    \n",
    "    return final_text_data, final_matrix\n",
    "def generate_pdf_from_data(data:list, output_path:str):\n",
    "    \n",
    "    pdf_doc = fitz.open()\n",
    "    \n",
    "    for header, items in data.items():\n",
    "        \n",
    "        page = pdf_doc.new_page()\n",
    "        text_position = 72  # for title initalize something\n",
    "\n",
    "        #section title\n",
    "        title_font_size = 24\n",
    "        try:\n",
    "            page.insert_text(\n",
    "                (72, text_position), #initalizor\n",
    "                header,\n",
    "                fontsize=title_font_size,\n",
    "                fontname=\"helv\",\n",
    "                color=(0, 0, 1),\n",
    "            )        \n",
    "        except Exception as e:\n",
    "            print(f\"Error while parsing fund {e}\")\n",
    "            \n",
    "        for item in items:\n",
    "            \n",
    "            bbox = item[3] #origin coords\n",
    "            text = item[1]\n",
    "            size = item[0]\n",
    "            color = item[2]\n",
    "   \n",
    "            #Errror in fitz font \n",
    "            try:\n",
    "                page.insert_text(\n",
    "                    (bbox[0], bbox[1]),\n",
    "                    text,\n",
    "                    fontsize=size,\n",
    "                    fontname=\"helv\",\n",
    "                    color=tuple(int(color & 0xFFFFFF) for _ in range(3)))#unsigned int value so (0,0,0)\n",
    "                \n",
    "            except Exception:\n",
    "                page.insert_text(\n",
    "                    (bbox[0], bbox[1]),\n",
    "                    text,\n",
    "                    fontsize=size,\n",
    "                    fontname=\"helv\",\n",
    "                    color=(1, 0, 0),\n",
    "                )\n",
    "\n",
    "    # Save the created PDF\n",
    "    pdf_doc.save(output_path)\n",
    "    pdf_doc.close()\n",
    "    print(f\" PDF generated to: {output_path}\")\n",
    "\n",
    "def extract_data_from_pdf(path:str):\n",
    "    \n",
    "    def replace_main_key(string: str):\n",
    "        replace_key = string\n",
    "        if re.match(r'^nav.*', string, re.IGNORECASE):\n",
    "            replace_key = \"nav\"\n",
    "        elif re.match(r\"^market\", string, re.IGNORECASE):\n",
    "            replace_key = \"market_capital\"  \n",
    "        elif re.match(r\"^assets\", string, re.IGNORECASE):\n",
    "            replace_key = \"assets_under_management\"\n",
    "        elif re.match(r\"^fund\", string, re.IGNORECASE):\n",
    "            replace_key = \"fund_manager\" \n",
    "        elif re.match(r\"^scheme\", string, re.IGNORECASE):\n",
    "            replace_key = \"scheme_details\" \n",
    "        elif re.match(r\"^investment\", string, re.IGNORECASE):\n",
    "            replace_key = \"investment_objective\"\n",
    "        elif re.match(r\"^quanti\", string, re.IGNORECASE):\n",
    "            replace_key = \"quantitative_data\"\n",
    "        elif re.match(r\"^portfolio\", string, re.IGNORECASE):\n",
    "            replace_key = \"portfilio\" \n",
    "        elif re.match(r\"^industry\", string, re.IGNORECASE):\n",
    "            replace_key = \"industry_allocation_of_equity\"       \n",
    "        return replace_key\n",
    "    \n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        final_data = []\n",
    "        final_data_generated = {}\n",
    "        \n",
    "        for page in pdf.pages:\n",
    "            # extract text from the page\n",
    "            text = page.extract_text()\n",
    "            final_data.append(text)\n",
    "        #print(final_data)\n",
    "        \n",
    "        #store them in a dict for each page\n",
    "        for data in final_data:\n",
    "            content = data.split('\\n')\n",
    "            main_key = replace_main_key(content[0])\n",
    "            #print(main_key)\n",
    "            values = content[1:]\n",
    "        \n",
    "            final_data_generated[main_key] = values\n",
    "\n",
    "        #sort the headers in lex order\n",
    "        sorted_final_generated = {key: final_data_generated[key] for key in sorted(final_data_generated)}\n",
    "\n",
    "    return sorted_final_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text_data, final_matrix = create_nested_dict(cleaned_data, 20.0 , 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samco flexi cap fund\n",
      " PDF generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "samco elss tax saver fund\n",
      " PDF generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "samco active momentum fund\n",
      " PDF generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "samco dynamic asset allocation fund\n",
      " PDF generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "samco overnight fund\n",
      " PDF generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n"
     ]
    }
   ],
   "source": [
    "final_extracted_text = dict()\n",
    "for fund, items in final_text_data.items():\n",
    "    print(fund)\n",
    "    generate_pdf_from_data(items, dry_run_path)\n",
    "    extract_data = extract_data_from_pdf(dry_run_path)\n",
    "    final_extracted_text[fund] = extract_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON CREATED\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(path +r\"\\output\\dump58_29-Feb-24_FS.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(final_extracted_text, file, ensure_ascii=False, indent=4)\n",
    "    print(\"JSON CREATED\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGEX FUNCTIONS\n",
    "\n",
    "def return_invest_data(key:str,data:list):\n",
    "    investment_objective = data\n",
    "    values = \" \".join(txt for txt in investment_objective)\n",
    "\n",
    "    data = {\n",
    "        key:values\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "def return_scheme_data(key:str,data:list):\n",
    "    scheme_data = data\n",
    "    main_key = key\n",
    "    structured_data = {main_key: {}}\n",
    "\n",
    "    # Patterns\n",
    "    date_pattern = r\"^(.*?date)\\s(\\d{2}-[A-Za-z]{3}-\\d{4})$\"\n",
    "    benchmark_pattern = r\"^(Benchmark)\\s+(.*)$\"\n",
    "    application_pattern = r\"(?:·)?\\d+(?:,\\d{3})*(?:\\.\\d+)?/-\"\n",
    "\n",
    "    for data in scheme_data:\n",
    "        if re.search(date_pattern, data, re.IGNORECASE):\n",
    "            match = re.match(date_pattern, data, re.IGNORECASE)\n",
    "            if match:\n",
    "                key = match.group(1)\n",
    "                value = match.group(2)\n",
    "                structured_data[main_key][key] = value\n",
    "        elif re.search(benchmark_pattern, data, re.IGNORECASE):\n",
    "            match = re.match(benchmark_pattern, data, re.IGNORECASE)\n",
    "            if match:\n",
    "                key = match.group(1)\n",
    "                value = match.group(2)\n",
    "                structured_data[main_key][key] = value\n",
    "        elif re.search(r\"\\b(min|application)\\b\", data, re.IGNORECASE):\n",
    "            matches = re.findall(application_pattern, data, re.IGNORECASE)\n",
    "            if matches:\n",
    "                cleaned_matches = [match.replace('·', '') for match in matches]\n",
    "                structured_data[main_key][\"min_appl_amt\"] = cleaned_matches\n",
    "        elif re.search(r\"\\b(additional.* and in multiples of)\\b\", data, re.IGNORECASE):\n",
    "            matches = re.findall(application_pattern, data, re.IGNORECASE)\n",
    "            if matches:\n",
    "                cleaned_matches = [match.replace('·', '') for match in matches]\n",
    "                structured_data[main_key][\"additional_amt\"] = cleaned_matches\n",
    "\n",
    "    return structured_data\n",
    "\n",
    "def return_fund_data(key:str,data:list):\n",
    "    fund_manager = data\n",
    "    main_key = key\n",
    "    strucuted_data = {main_key:[]}\n",
    "    current_entry = None\n",
    "    name_pattern = r'^(Ms\\.|Mr\\.)'\n",
    "    manage_pattern = r'^\\(|\\)$'\n",
    "    date_pattern = r'\\b\\w+ \\d{1,2}, \\d{4}\\b'\n",
    "    experience_pattern = r'^Total Experience: (.+)$'\n",
    "\n",
    "    for data in fund_manager:\n",
    "        if re.match(name_pattern,data):\n",
    "            if current_entry:\n",
    "                strucuted_data[main_key].append(current_entry)\n",
    "            current_entry = {\n",
    "                'name': data.split(\",\")[0].strip().lower(),\n",
    "                'designation': \"\".join(data.split(\",\")[1:]).strip().lower()\n",
    "            }\n",
    "            #print(data.split(\",\")[0],\"\".join(data.split(\",\")[1:]))\n",
    "        elif re.match(manage_pattern,data):\n",
    "            if \"inception\" in data.lower():\n",
    "                current_entry['managing_since'] = 'inception'\n",
    "            else:\n",
    "                date = re.search(date_pattern, data)\n",
    "                current_entry['managing_since'] = date.group() if date != None else None\n",
    "        elif re.match(experience_pattern,data):\n",
    "            current_entry['total_experience'] = data.split(\":\")[1].strip().lower()\n",
    "            #print(data.split(\":\")[1])\n",
    "\n",
    "        \n",
    "    if current_entry:  # Append the last entry\n",
    "        strucuted_data[main_key].append(current_entry)\n",
    "            \n",
    "    return strucuted_data\n",
    "\n",
    "def return_nav_data(key:str,data:list):\n",
    "    main_key = key\n",
    "    structured_data = {main_key: {}}\n",
    "    \n",
    "    growth_pattern = r\"((?:Regular|Direct)\\s+(?:Growth|IDCW))\\s*:?\\s*·\\s*([\\d.]+)\"\n",
    "    \n",
    "    for line in data:\n",
    "        matches = re.findall(growth_pattern, line)\n",
    "        for key, value in matches:\n",
    "            structured_data[main_key][key.strip().lower()] = float(value)\n",
    "        \n",
    "    return structured_data\n",
    "\n",
    "def return_quant_data(key:str,data:list):\n",
    "    qunatitative_data = data\n",
    "    main_key = key\n",
    "\n",
    "    strucuted_data = {main_key:{}}\n",
    "    current_entry = None\n",
    "    comment = \"\"\n",
    "\n",
    "    ratio_pattern = r\"\\b(ratio|turnover)\\b\"\n",
    "    annual_pattern = r'\\b(annualised|YTM)\\b'\n",
    "    macaulay_pattern = r\"\\b(macaulay.*duration)\\b\"\n",
    "    residual_pattern = r\"\\b(residual.*maturity)\\b\"\n",
    "    modified_pattern = r\"\\b(modified.*duration)\\b\"\n",
    "\n",
    "    for data in qunatitative_data:\n",
    "        if re.search(ratio_pattern,data, re.IGNORECASE):\n",
    "            key = data.split(\":\")[0].lower().strip()\n",
    "            value = data.split(\":\")[1].lower().strip()\n",
    "        elif re.search(annual_pattern,data, re.IGNORECASE):\n",
    "            key = data.split(\":\")[0].lower().strip()\n",
    "            value = data.split(\":\")[1].lower().strip()\n",
    "        elif re.search(macaulay_pattern,data, re.IGNORECASE):\n",
    "            key = data.split(\":\")[0].lower().strip()\n",
    "            value = data.split(\":\")[1].lower().strip()\n",
    "        elif re.search(residual_pattern,data, re.IGNORECASE):\n",
    "            key = data.split(\":\")[0].lower().strip()\n",
    "            value = data.split(\":\")[1].lower().strip()\n",
    "        elif re.search(modified_pattern,data, re.IGNORECASE):\n",
    "            key = data.split(\":\")[0].lower().strip()\n",
    "            value = data.split(\":\")[1].lower().strip()\n",
    "        else:\n",
    "            comment+= data\n",
    "        strucuted_data[main_key][key] = value\n",
    "    \n",
    "    strucuted_data[main_key]['comment'] = comment\n",
    "\n",
    "    return strucuted_data\n",
    "\n",
    "def return_aum_data(key:str,data:list):\n",
    "    \n",
    "    aum = data\n",
    "    main_key = key\n",
    "    strucuted_data = {main_key:{}}\n",
    "\n",
    "    pattern = r\"\\b\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)? Crs\\b\"\n",
    "\n",
    "    for data in aum:\n",
    "        if re.search(r'average', data, re.IGNORECASE):\n",
    "            match = re.search(pattern, data)\n",
    "            key = 'avg_aum (crs)'\n",
    "        elif re.search(pattern, data):\n",
    "            match = re.search(pattern, data)\n",
    "            key = \"aum (crs)\"\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if match:\n",
    "            strucuted_data[main_key][key] = float(match.group().split(\" \")[0])\n",
    "\n",
    "    return strucuted_data\n",
    "\n",
    "def return_dummy_data(key:str,data:list):\n",
    "    return {key:{}}\n",
    "\n",
    "def return_required_regex(string: str):\n",
    "        replace_key = string\n",
    "        if re.match(r'^nav.*', string, re.IGNORECASE):\n",
    "            replace_key = \"nav\"\n",
    "        elif re.match(r\"^market\", string, re.IGNORECASE):\n",
    "            replace_key = \"market_capital\"  \n",
    "        elif re.match(r\"^assets\", string, re.IGNORECASE):\n",
    "            replace_key = \"assets_under_management\"\n",
    "        elif re.match(r\"^fund\", string, re.IGNORECASE):\n",
    "            replace_key = \"fund_manager\" \n",
    "        elif re.match(r\"^scheme\", string, re.IGNORECASE):\n",
    "            replace_key = \"scheme_details\" \n",
    "        elif re.match(r\"^investment\", string, re.IGNORECASE):\n",
    "            replace_key = \"investment_objective\"\n",
    "        elif re.match(r\"^quanti\", string, re.IGNORECASE):\n",
    "            replace_key = \"quantitative_data\"\n",
    "        elif re.match(r\"^portfolio\", string, re.IGNORECASE):\n",
    "            replace_key = \"portfilio\" \n",
    "        elif re.match(r\"^industry\", string, re.IGNORECASE):\n",
    "            replace_key = \"industry_allocation_of_equity\"       \n",
    "        return replace_key\n",
    "    \n",
    "def match_regex_to_content(string:str, data:list):\n",
    "    \n",
    "    check_header = string\n",
    "    \n",
    "    if re.match(r\"^Investment\", check_header, re.IGNORECASE):\n",
    "        return return_invest_data(string,data)\n",
    "    elif re.match(r\"^Scheme\", check_header, re.IGNORECASE):\n",
    "        return return_scheme_data(string, data)\n",
    "    \n",
    "    elif re.match(r\"^NAV\", check_header, re.IGNORECASE):\n",
    "        return return_nav_data(string, data)\n",
    "    \n",
    "    elif re.match(r\"^Quant\", check_header, re.IGNORECASE):\n",
    "        return return_quant_data(string, data)\n",
    "    \n",
    "    elif re.match(r\"^Fund\", check_header, re.IGNORECASE):\n",
    "        return return_fund_data(string, data)\n",
    "    \n",
    "    elif re.match(r\"^Assets\", check_header, re.IGNORECASE):\n",
    "        return return_aum_data(string, data)\n",
    "    \n",
    "    else:\n",
    "        return return_dummy_data(string,data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "for fund, page in final_extracted_text.items():\n",
    "    print(f\"\\n---------------{fund}---------------\\n\")\n",
    "    for header, content in page.items():\n",
    "        print(header)\n",
    "        pprint.pprint(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------samco flexi cap fund-------------------\n",
      "\n",
      "{'assets_under_management': {'aum (crs)': 711.98, 'avg_aum (crs)': 716.87}}\n",
      "\n",
      "\n",
      "{'fund_manager': [{'designation': '',\n",
      "                   'managing_since': 'inception',\n",
      "                   'name': 'ms. nirali bhansali fund manager - equity',\n",
      "                   'total_experience': 'around 9 years'},\n",
      "                  {'designation': '',\n",
      "                   'managing_since': 'August 01, 2023',\n",
      "                   'name': 'mr. umeshkumar mehta cio and co-fund manager - '\n",
      "                           'equity',\n",
      "                   'total_experience': 'over 20 years'},\n",
      "                  {'designation': '',\n",
      "                   'managing_since': 'inception',\n",
      "                   'name': 'mr. dhawal ghanshyam dhanani',\n",
      "                   'total_experience': 'around 6 years'}]}\n",
      "\n",
      "\n",
      "{'investment_objective': 'The investment objective of the Scheme is to seek to '\n",
      "                         'generate long-term capital growth from an actively '\n",
      "                         'managed portfolio of Indian & foreign equity '\n",
      "                         'instruments across market capitalisation. However, '\n",
      "                         'there is no assurance or guarantee that the '\n",
      "                         'investment objective of the Scheme will be achieved.'}\n",
      "\n",
      "\n",
      "{'nav': {'direct growth': 12.13, 'regular growth': 11.73}}\n",
      "\n",
      "\n",
      "{'quantitative_data': {'comment': 'Lower of sales or purchases divided by '\n",
      "                                  'average AUM for last rolling 12 months·',\n",
      "                       'portfolio turnover ratio': '0.34 times'}}\n",
      "\n",
      "\n",
      "{'scheme_details': {'Benchmark': 'Nifty 500 TRI',\n",
      "                    'Inception Date': '04-Feb-2022',\n",
      "                    'additional_amt': ['500/-', '1/-'],\n",
      "                    'min_appl_amt': ['5,000/-', '1/-']}}\n",
      "\n",
      "\n",
      "\n",
      "--------------------samco elss tax saver fund-------------------\n",
      "\n",
      "{'assets_under_management': {'aum (crs)': 100.64, 'avg_aum (crs)': 97.32}}\n",
      "\n",
      "\n",
      "{'fund_manager': [{'designation': '',\n",
      "                   'managing_since': 'inception',\n",
      "                   'name': 'ms. nirali bhansali',\n",
      "                   'total_experience': 'around 9 years'},\n",
      "                  {'designation': '',\n",
      "                   'managing_since': 'August 01, 2023',\n",
      "                   'name': 'mr. umeshkumar mehta cio and co-fund manager - '\n",
      "                           'equity',\n",
      "                   'total_experience': 'over 20 years'}]}\n",
      "\n",
      "\n",
      "{'investment_objective': 'The investment objective of the scheme is to '\n",
      "                         'generate long-term capital appreciation through '\n",
      "                         'investments made predominantly in equity and equity '\n",
      "                         'related instruments. However, there can be no '\n",
      "                         'assurance or guarantee that the investment objective '\n",
      "                         'of the scheme would be achieved.'}\n",
      "\n",
      "\n",
      "{'nav': {'direct growth': 13.93, 'regular growth': 13.65}}\n",
      "\n",
      "\n",
      "{'quantitative_data': {'comment': 'Lower of sales or purchases divided by '\n",
      "                                  'average AUM for last rolling 12 months',\n",
      "                       'portfolio turnover ratio': '0.08 times'}}\n",
      "\n",
      "\n",
      "{'scheme_details': {'Benchmark': 'Nifty 500 TRI',\n",
      "                    'Inception Date': '22-Dec-2022',\n",
      "                    'additional_amt': ['500/-', '500/-'],\n",
      "                    'min_appl_amt': ['500/-', '500/-']}}\n",
      "\n",
      "\n",
      "\n",
      "--------------------samco active momentum fund-------------------\n",
      "\n",
      "{'assets_under_management': {'aum (crs)': 761.52, 'avg_aum (crs)': 752.13}}\n",
      "\n",
      "\n",
      "{'fund_manager': [{'designation': '',\n",
      "                   'managing_since': 'inception',\n",
      "                   'name': 'mr. paras matalia',\n",
      "                   'total_experience': 'around 6 years'},\n",
      "                  {'designation': '',\n",
      "                   'managing_since': 'August 01, 2023',\n",
      "                   'name': 'mr. umeshkumar mehta cio and co-fund manager - '\n",
      "                           'equity',\n",
      "                   'total_experience': 'over 20 years'},\n",
      "                  {'designation': '',\n",
      "                   'managing_since': 'inception',\n",
      "                   'name': 'mr. dhawal ghanshyam dhanani',\n",
      "                   'total_experience': 'around 6 years'}]}\n",
      "\n",
      "\n",
      "{'investment_objective': 'The investment objective of the Scheme is to seek to '\n",
      "                         'generate long-term capital appreciation by investing '\n",
      "                         'in stocks showing strong momentum. Momentum stocks '\n",
      "                         'are such that exhibit positive price momentum · '\n",
      "                         'based on the phenomenon that stocks which have '\n",
      "                         'performed well in the past relative to other stocks '\n",
      "                         '(winners) continue to perform well in the future, '\n",
      "                         'and stocks that have performed relatively poorly '\n",
      "                         '(losers) continue to perform poorly. However, there '\n",
      "                         'can be no assurance or guarantee that the investment '\n",
      "                         'objective of the scheme would be achieved.'}\n",
      "\n",
      "\n",
      "{'nav': {'direct growth': 13.1, 'regular growth': 12.94}}\n",
      "\n",
      "\n",
      "{'scheme_details': {'Benchmark': 'Nifty 500 TRI',\n",
      "                    'Inception Date': '05-Jul-2023',\n",
      "                    'additional_amt': ['500/-', '1/-'],\n",
      "                    'min_appl_amt': ['5000/-', '1/-']}}\n",
      "\n",
      "\n",
      "\n",
      "--------------------samco dynamic asset allocation fund-------------------\n",
      "\n",
      "{'assets_under_management': {'aum (crs)': 582.41, 'avg_aum (crs)': 584.79}}\n",
      "\n",
      "\n",
      "{'fund_manager': [{'designation': '',\n",
      "                   'managing_since': 'inception',\n",
      "                   'name': 'mr. umeshkumar mehta cio and fund manager - equity',\n",
      "                   'total_experience': 'over 20 years'},\n",
      "                  {'designation': 'co-fund manager - equity',\n",
      "                   'managing_since': 'inception',\n",
      "                   'name': 'mr. paras matalia',\n",
      "                   'total_experience': 'around 6 years'},\n",
      "                  {'designation': '',\n",
      "                   'managing_since': 'inception',\n",
      "                   'name': 'mr. dhawal ghanshyam dhanani',\n",
      "                   'total_experience': 'around 6 years'}]}\n",
      "\n",
      "\n",
      "{'investment_objective': 'The investment objective of the Scheme is to '\n",
      "                         'generate income/long-term capital appreciation by '\n",
      "                         'investing in equity, equity derivatives, fixed '\n",
      "                         'income instruments and foreign securities. The '\n",
      "                         'allocation between equity instruments and fixed '\n",
      "                         'income will be managed dynamically so as to provide '\n",
      "                         'investors with long term capital appreciation while '\n",
      "                         'managing downside risk. However, there can be no '\n",
      "                         'assurance or guarantee that the investment objective '\n",
      "                         'of the scheme would be achieved.'}\n",
      "\n",
      "\n",
      "{'nav': {'direct growth': 10.25,\n",
      "         'direct idcw': 10.25,\n",
      "         'regular growth': 10.19,\n",
      "         'regular idcw': 10.19}}\n",
      "\n",
      "\n",
      "{'quantitative_data': {'annualised portfolio ytm': '8.15%',\n",
      "                       'comment': '',\n",
      "                       'macaulay duration': '1.70 years',\n",
      "                       'modified duration': '1.57 years',\n",
      "                       'residual maturity': '1.84 years'}}\n",
      "\n",
      "\n",
      "{'scheme_details': {'Benchmark': 'NIFTY50 Hybrid Composite Debt',\n",
      "                    'Inception Date': '28-Dec-2023',\n",
      "                    'additional_amt': ['500/-', '1/-'],\n",
      "                    'min_appl_amt': ['5000/-', '1/-']}}\n",
      "\n",
      "\n",
      "\n",
      "--------------------samco overnight fund-------------------\n",
      "\n",
      "{'assets_under_management': {'aum (crs)': 48.69, 'avg_aum (crs)': 47.24}}\n",
      "\n",
      "\n",
      "{'fund_manager': [{'designation': '',\n",
      "                   'managing_since': 'inception',\n",
      "                   'name': 'mr. dhawal ghanshyam dhanani',\n",
      "                   'total_experience': 'around 6 years'},\n",
      "                  {'designation': '',\n",
      "                   'managing_since': None,\n",
      "                   'name': 'mr. umeshkumar mehta cio & fund manager',\n",
      "                   'total_experience': 'over 20 years'}]}\n",
      "\n",
      "\n",
      "{'investment_objective': 'The investment objective of the Scheme is to provide '\n",
      "                         'reasonable returns commensurate with very low risk '\n",
      "                         'and providing a high level of liquidity, through '\n",
      "                         'investments made primarily in overnight securities '\n",
      "                         'having maturity/ residual maturity of 1 day. '\n",
      "                         'However, there can be no assurance or guarantee that '\n",
      "                         'the investment objective of the scheme would be '\n",
      "                         'achieved.'}\n",
      "\n",
      "\n",
      "{'nav': {'direct growth': 1104.5644, 'regular growth': 1100.6598}}\n",
      "\n",
      "\n",
      "{'quantitative_data': {'annualised portfolio ytm': '6.75%',\n",
      "                       'comment': '',\n",
      "                       'macaulay duration': '2 days',\n",
      "                       'modified duration': '2 days',\n",
      "                       'residual maturity': '2 days'}}\n",
      "\n",
      "\n",
      "{'scheme_details': {'Benchmark': 'CRISIL Liquid Overnight Index',\n",
      "                    'Inception Date': '12-Oct-2022',\n",
      "                    'additional_amt': ['500/-', '1/-'],\n",
      "                    'min_appl_amt': ['5,000/-', '1/-']}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "for fund, page in final_extracted_text.items():\n",
    "    print(f'\\n--------------------{fund}-------------------\\n')\n",
    "    \n",
    "    for header, item in page.items():\n",
    "        data = match_regex_to_content(header,item)\n",
    "        pprint.pprint(data)\n",
    "        print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

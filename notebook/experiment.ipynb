{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint, json, math, os, sys\n",
    "import fitz, pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "dir_path = \"C:\\\\Users\\\\Kaustubh.keny\\\\Projects\\\\office-work\\\\mywork-repo\"\n",
    "fund_path = \"C:\\\\Users\\\\Kaustubh.keny\\\\Projects\\\\Jan 25\"\n",
    "\n",
    "# dir_path = \"C:\\\\Users\\\\rando\\\\OneDrive\\\\Documents\\\\mywork-repo\"\n",
    "# fund_path =  \"C:\\\\Users\\\\rando\\\\OneDrive\\\\Documents\\\\Jan 25\"\n",
    "sys.path.append(os.path.abspath(dir_path))\n",
    "\n",
    "from app.utils import Helper\n",
    "from app.parse_regex import *\n",
    "\n",
    "dry_path = r'\\data\\output\\DryRun.pdf'\n",
    "fin_path = r'\\data\\input\\financial_indices.xlsx'\n",
    "mutual_fund = Helper.get_fund_paths(fund_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clipped_data(input:str, pages:list, bboxes:list):\n",
    "        \n",
    "        document = fitz.open(input)\n",
    "        final_list = []\n",
    "    \n",
    "        for pgn in pages:\n",
    "            page = document[pgn]\n",
    "            \n",
    "            all_blocks = [] #store every data from bboxes\n",
    "            \n",
    "            for bbox in bboxes:\n",
    "                blocks, seen_blocks = [], set()  #store unique blocks based on content and bbox\n",
    "                \n",
    "                page_blocks = page.get_text('dict', clip=bbox)['blocks']\n",
    "                for block in page_blocks:\n",
    "                    if block['type'] == 0 and 'lines' in block: #type 0 means text block\n",
    "                        #hash_key\n",
    "                        block_key = (tuple(block['bbox']), tuple(tuple(line['spans'][0]['text'] for line in block['lines'])))\n",
    "                        if block_key not in seen_blocks:\n",
    "                            seen_blocks.add(block_key)\n",
    "                            blocks.append(block)\n",
    "\n",
    "                sorted_blocks = sorted(blocks, key=lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "                all_blocks.append(sorted_blocks)\n",
    "\n",
    "            final_list.append({\n",
    "                \"pgn\": pgn,\n",
    "                \"block\": all_blocks #will be list[list,list,..]\n",
    "            })\n",
    "\n",
    "        document.close()\n",
    "        return final_list\n",
    "    \n",
    "def extract_data_relative_line(path: str, line_x: float, side: str):\n",
    "    doc = fitz.open(path)\n",
    "    pages = doc.page_count\n",
    "\n",
    "    final_list = []\n",
    "\n",
    "    for pgn in range(pages):\n",
    "        page = doc[pgn]\n",
    "\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        sorted_blocks = sorted(blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "        extracted_blocks = []\n",
    "\n",
    "        # Keep track of blocks to avoid duplicates\n",
    "        added_blocks = set()\n",
    "\n",
    "        for block in sorted_blocks:\n",
    "            block_id = id(block)  # Unique identifier for the block\n",
    "\n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line.get(\"spans\", []):\n",
    "                    origin = span[\"origin\"]\n",
    "                    x0, _ = origin\n",
    "\n",
    "                    # Check the side condition\n",
    "                    if side == \"left\" and x0 < line_x and block_id not in added_blocks:\n",
    "                        extracted_blocks.append(block)\n",
    "                        added_blocks.add(block_id)  # Mark block as added\n",
    "                    elif side == \"right\" and x0 > line_x and block_id not in added_blocks:\n",
    "                        extracted_blocks.append(block)\n",
    "                        added_blocks.add(block_id)  # Mark block as added\n",
    "\n",
    "      \n",
    "        final_list.append({\n",
    "            \"pgn\": pgn,\n",
    "            \"blocks\": extracted_blocks\n",
    "        })\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    return final_list\n",
    "  \n",
    "def get_clipped_data(input:str, bboxes:list[set], *args):\n",
    "    \n",
    "        document = fitz.open(input)\n",
    "        final_list = []\n",
    "        if args:\n",
    "            pages = list(args)\n",
    "        else:\n",
    "            pages = [i for i in document.page_count]\n",
    "        \n",
    "        for pgn in pages:\n",
    "            page = document[pgn]\n",
    "\n",
    "            blocks = []\n",
    "            for bbox in bboxes:\n",
    "                blocks.extend(page.get_text('dict', clip = bbox)['blocks']) #get all blocks\n",
    "            \n",
    "            filtered_blocks = [block for block in blocks if block['type']== 0 and 'lines' in block]\n",
    "            # sorted_blocks = sorted(filtered_blocks, key= lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "            \n",
    "             # Extract text from sorted blocks\n",
    "            extracted_text = []\n",
    "            for block in filtered_blocks:\n",
    "                block_text = []\n",
    "                for line in block['lines']:\n",
    "                    line_text = \" \".join(span['text'] for span in line['spans'])\n",
    "                    block_text.append(line_text)\n",
    "                extracted_text.append(\"\\n\".join(block_text))\n",
    "            \n",
    "            final_list.append({\n",
    "            \"pgn\": pgn,\n",
    "            \"block\": filtered_blocks,\n",
    "            \"text\": extracted_text\n",
    "            })\n",
    "            \n",
    "            \n",
    "        document.close()\n",
    "        return final_list\n",
    "    \n",
    "def get_clipped_text(input:str, bboxes:list[set],*args):\n",
    "\n",
    "    document = fitz.open(input)\n",
    "    final_list = []\n",
    "    \n",
    "    if args:\n",
    "        pages = list(args)\n",
    "    else:\n",
    "        pages = [i for i in document.page_count]\n",
    "    \n",
    "    for pgn in pages:\n",
    "        page = document[pgn]\n",
    "        blocks = []\n",
    "        for bbox in bboxes:\n",
    "            blocks = page.get_text('text', clip = bbox).split('\\n') #get all blocks\n",
    "        final_list.append({\n",
    "        \"pgn\": pgn,\n",
    "        \"block\": blocks\n",
    "        })   \n",
    "    document.close()\n",
    "    return final_list\n",
    "\n",
    "def get_proper_fund_names(path: str, pages: list):\n",
    "    doc = fitz.open(path)\n",
    "    title = {}\n",
    "\n",
    "    for pgn in pages:\n",
    "        page = doc[pgn]\n",
    "        blocks = page.get_text(\"dict\")['blocks']\n",
    "        text_all = \" \".join(\n",
    "            span[\"text\"].strip()\n",
    "            for block in blocks[:4]\n",
    "            for line in block.get(\"lines\", [])\n",
    "            for span in line.get(\"spans\", [])\n",
    "            if span[\"text\"].strip()\n",
    "        )\n",
    "\n",
    "        text_all = re.sub(r'[^A-Za-z0-9\\s]+', '', text_all).strip()\n",
    "        matches = re.findall(r\"((?:LIC\\s*MF|BLNCED|LOW)\\s+.*?(?:FUND|ETF|FTF|FOF|PLAN|SAVER))\", text_all, re.IGNORECASE)\n",
    "\n",
    "        title[pgn] = matches[0] if matches else \"\"\n",
    "\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path  = mutual_fund[\"Union Mutual Fund\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified PDF saved to: C:\\Users\\Kaustubh.keny\\Projects\\office-work\\mywork-repo\\data\\output\\DryRun.pdf\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "    ((255, 0), (255, 812)),# Vertical line\n",
    "    ((0, 150), (812, 150))\n",
    "]\n",
    "pages = [12, 14,16]\n",
    "bboxes = [(0, 0, 180, 80)] #[(0, 85, 180, 812),(180, 85, 360, 812),(0,100,270,812),(0,100,350,812)]\n",
    "pages = [i for i in range(1,110)]\n",
    "Helper.draw_lines_on_pdf(sample_path, lines, bboxes, pages, dir_path +dry_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proper_fund_names(path: str):\n",
    "    pattern = r\"(Union\\s*[A-Za-z\\s]+?(?:FUND|PATH|ETF|FOF))\"\n",
    "    title = {}\n",
    "    \n",
    "    with fitz.open(path) as doc:\n",
    "        for pgn, page in enumerate(doc):\n",
    "            text = \" \".join(page.get_text(\"text\", clip=(0, 0, 180, 150)).split(\"\\n\"))\n",
    "            text = re.sub(\"[^A-Za-z0-9\\\\s\\\\-\\\\(\\\\).,]+\", \"\", text).strip()\n",
    "            print(pgn,text)\n",
    "            if matches := re.findall(pattern, text, re.DOTALL):\n",
    "                title[pgn] = matches[0]\n",
    "                print(matches[0])\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 January 2025\n",
      "1 INDEX MARKET REVIEW EQUITY SCHEME\n",
      "2 Market Review Macro variables like Trump policy  sentiments during the month. Indian  in small cap index and 6 in midcap\n",
      "3 The Fair Va Market Review\n",
      "4 Union FLEXI CAP FUND (An open-ended dynamic equity scheme  investing across large cap, mid cap,  small cap stocks) Factsheet as on January 31, 2025\n",
      "Union FLEXI CAP FUND\n",
      "5 Union MULTICAP FUND (Multi Cap Fund - An open ended equity  scheme investing across large cap,  mid cap, small cap stocks) Factsheet as on January 31, 2025\n",
      "Union MULTICAP FUND\n",
      "6 Union BUSINESS CYCLE FUND (An open-ended equity scheme  following business cycles  based investing theme) Factsheet as on January 31, 2025\n",
      "Union BUSINESS CYCLE FUND\n",
      "7 (An open ended equity scheme investing in  maximum 30 stocks across  market caps (i.e. Multi Cap)) Factsheet as on January 31, 2025 Union FOCUSED FUND\n",
      "Union FOCUSED FUND\n",
      "8 (Mid Cap Fund - An open-ended equity  scheme predominantly investing in  mid cap stocks) Factsheet as on January 31, 2025 Union MIDCAP FUND\n",
      "Union MIDCAP FUND\n",
      "9 (Large  Mid Cap Fund - An open ended  equity scheme investing in  both large cap and mid cap stocks) Factsheet as on January 31, 2025 Union LARGE  MIDCAP FUND\n",
      "Union LARGE  MIDCAP FUND\n",
      "10 (Small Cap Fund - An Open Ended Equity  Scheme predominantly investing in  Small Cap stocks) Factsheet as on January 31, 2025 Union SMALL CAP FUND\n",
      "Union SMALL CAP FUND\n",
      "11 (An open-ended equity scheme  following innovation theme) Factsheet as on January 31, 2025 Union INNOVATION   OPPORTUNITIES FUND\n",
      "Union INNOVATION   OPPORTUNITIES FUND\n",
      "12 (formerly Union Tax Saver (ELSS) Fund) (An open ended equity linked saving  scheme with a statutory lock in of  3 years and tax benefit.) Factsheet as on January 31, 2025 Union ELSS TAX SAVER FUND\n",
      "Union ELSS TAX SAVER FUND\n",
      "13 (formerly Union Value Discovery Fund) (An Open-ended equity scheme following  a value investment strategy) Factsheet as on January 31, 2025 Union VALUE FUND\n",
      "Union VALUE FUND\n",
      "14 (Large Cap Fund - An open ended equity  scheme predominantly investing in  large cap stocks) Factsheet as on January 31, 2025 Union LARGECAP FUND\n",
      "Union LARGECAP FUND\n",
      "15 (An open-ended equity scheme following  momentum theme) Factsheet as on January 31, 2025 Union ACTIVE MOMENTUM  FUND\n",
      "Union ACTIVE MOMENTUM  FUND\n",
      "16 (formerly Union Hybrid Equity Fund) (An open-ended hybrid scheme investing  predominantly in equity and  equity related instruments) Factsheet as on January 31, 2025 Union AGGRESSIVE HYBRID FUND\n",
      "Union AGGRESSIVE HYBRID FUND\n",
      "17 (An open-ended scheme investing in  Equity, Debt, Gold and or Silver) Factsheet as on January 31, 2025 Union MULTI ASSET  ALLOCATION FUND\n",
      "Union MULTI ASSET  ALLOCATION FUND\n",
      "18 (An Open-ended Dynamic Asset  Allocation Fund) Factsheet as on January 31, 2025 Union BALANCED  ADVANTAGE FUND\n",
      "Union BALANCED  ADVANTAGE FUND\n",
      "19 (An Open Ended Scheme investing in Equity, Arbitrage and Debt) Factsheet as on January 31, 2025 Union EQUITY SAVINGS FUND\n",
      "Union EQUITY SAVINGS FUND\n",
      "20 (An Open Ended Scheme investing in  Arbitrage Opportunities) Factsheet as on January 31, 2025 Union ARBITRAGE FUND\n",
      "Union ARBITRAGE FUND\n",
      "21 Union RETIREMENT FUND (An open ended retirement solution oriented scheme having a lockin of 5 years or till  retirement age (whichever is earlier)) Factsheet as on January 31, 2025\n",
      "Union RETIREMENT FUND\n",
      "22 Union CHILDRENS FUND (An open-ended fund for investment for  children, having a lock-in for at least 5 years or till the child attains age of majority  (whichever is earlier)). Factsheet as on January 31, 2025\n",
      "Union CHILDRENS FUND\n",
      "23 (An open ended debt scheme predominantly investing in AA and above rated corporate bonds. A relatively high interest rate risk and moderate credit risk.) Factsheet as on January 31, 2025 Union CORPORATE BOND FUND\n",
      "Union CORPORATE BOND FUND\n",
      "24 (An open-ended dynamic debt Scheme  investing across duration. A relatively high  interest rate risk and moderate credit risk.) Factsheet as on January 31, 2025 Union DYNAMIC BOND FUND\n",
      "Union DYNAMIC BOND FUND\n",
      "25 (An open ended debt scheme investing in  government securities across maturity.  A relatively high interest rate risk and  relatively low credit risk.) Factsheet as on January 31, 2025 Union GILT FUND\n",
      "Union GILT FUND\n",
      "26 (An open ended debt scheme investing in  money market instruments. A relatively low  interest rate risk and moderate credit risk.) Factsheet as on January 31, 2025 Union MONEY MARKET FUND\n",
      "Union MONEY MARKET FUND\n",
      "27 (An Open Ended Liquid Scheme.  A relatively low interest rate risk and  moderate credit risk.) Factsheet as on January 31, 2025 Union LIQUID FUND\n",
      "Union LIQUID FUND\n",
      "28 (An open ended debt scheme investing in  overnight securities. A relatively low interest rate risk and relatively low credit risk.) Factsheet as on January 31, 2025 Union OVERNIGHT FUND\n",
      "Union OVERNIGHT FUND\n",
      "29 Union Flexi Cap Fund Net Asset Value (N (as on 31st January 2025)\n",
      "30 Union Dynamic Bond Fund Net Asset Value (N (as on 31st January 2025)\n",
      "31 Funds at a Glance Scheme Name Unio Flex Cap Fun\n",
      "32 Scheme Name Scheme Category Aggr U Funds at a Glance\n",
      "33 Lumpsum Performanc Co-managed by Mr. Sanjay  Fund Manager Plan Option Date of  Inception (as on 31st January 2025)\n",
      "34 Lumpsum Performanc Co managed by Gaurav Chopra Fund Manager Plan Option Date of  Inception (as on 31st January 2025)\n",
      "35 Lumpsum Performanc Co-managed by Mr. Parijat Agrawal  Fund Manager Plan Option Date of  Inception (as on 31st January 2025)\n",
      "36 Past performance may or may not be sustained in the futur investment objectives and fundamental differences in asse Funds dated June 27, 2024 pertaining to Regulation 24(b) of  For calculation of Permitted Category FPI Portfolio, NAV is co The performance of Permitted Category FPI Portfoio is bench Lumpsum Performanc (as on 31st January 2025)\n",
      "37 \n",
      "38 SIP Performance  (SIP Returns as on January 31, 2 1 Year  Period Investmen   120,000\n",
      "39 SIP Performance  Investmen  Period (SIP Returns as on January 31, 2\n",
      "40 Scheme Details - E Attribute Union  Flexi Cap  Fund Un Mult Fu\n",
      "41 Scheme Details - D Attribute Minimum Application Switch-in  Amount Union Corp Bond Fu\n",
      "42 Scheme Details - H Schemes Minimum Application Switch-in  Amount Union Aggres Hybrid Fun Attribute\n",
      "43 Income Distributio Withdrawal (IDCW Union Flexi Cap F Record Date  Face Value  ()  unit NA IDCW History - Other than Dir 28 September 2017 10.00\n",
      "44 Mutual Fund relate Fund Manager An employee of the asset manage mutual fund or life insurer, who ma sche e He is s all pa t of a la g\n",
      "45 Our Presence Ahmedabad  Bangalore\n",
      "46 \n",
      "47 \n"
     ]
    }
   ],
   "source": [
    "title = get_proper_fund_names(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Helper.get_all_pdf_data(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_highlight(path: str):\n",
    "        output_path = path.replace(\".pdf\", \"_hltd.pdf\")\n",
    "        \n",
    "        with fitz.open(path) as doc:\n",
    "            page_count = doc.page_count\n",
    "            indices = Helper._get_financial_indices(r\"C:\\Users\\Kaustubh.keny\\Projects\\office-work\\mywork-repo\\data\\input\\financial_indices.xlsx\")\n",
    "            data = [{\"title\": \"\", \"highlights\": 0, \"detect_idx\": []} for _ in range(page_count)]\n",
    "\n",
    "            for dpgn, page in enumerate(doc):\n",
    "                page_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "                sorted_blocks = sorted(page_blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "\n",
    "                for block_count, block in enumerate(sorted_blocks):\n",
    "                    if \"lines\" not in block:\n",
    "                        continue\n",
    "                    for line in block[\"lines\"]:\n",
    "                        for span in line[\"spans\"]:\n",
    "                            text = span[\"text\"].strip().lower()\n",
    "                            \n",
    "                            for indice in indices:\n",
    "                                pattern = rf\"\\b{re.escape(indice)}\\b\"\n",
    "                                if re.search(pattern, text):\n",
    "                                    if indice not in data[dpgn]['detect_idx']:\n",
    "                                        data[dpgn]['detect_idx'].append(indice)\n",
    "                                        data[dpgn]['highlights'] += 1\n",
    "                                    page.add_highlight_annot(fitz.Rect(span[\"bbox\"]))\n",
    "                                    break\n",
    "\n",
    "            doc.save(output_path)\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = check_and_highlight(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "def get_something(path: str):\n",
    "    pattern = r\"^(REDEMPTION PROCEEDS|FEATURES|ASSET ALLOCATION|FUND MANAGER|SCHEME|Sr\\. No\\.)$\"\n",
    "\n",
    "    with fitz.open(path) as doc:\n",
    "        exists = defaultdict(int)\n",
    "        for pgn, page in enumerate(doc):\n",
    "            page_text = [t.strip() for t in page.get_text().split(\"\\n\")]\n",
    "            for text in page_text:\n",
    "                if re.match(pattern,text):\n",
    "                    exists[pgn]+=1\n",
    "                    \n",
    "    \n",
    "    return [str(pgn+1) for pgn, count in exists.items() if count > 4] #camelot starts pages from 1\n",
    "\n",
    "pages = get_something(sample_path)\n",
    "\n",
    "imp_pages = \",\".join(pages)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = camelot.read_pdf(sample_path,pages=imp_pages, flavor=\"stream\", table_areas= [\"30,50,612,812\"],column_tol = 4, split_text = True) #[\"30,50,612,812\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_column_name(x):\n",
    "    cleaned = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", str(x), flags=re.IGNORECASE) #Corrected re.sub.\n",
    "    cleaned = \"_\".join(cleaned.split())\n",
    "    return cleaned\n",
    "\n",
    "with pd.ExcelWriter(\"cleaned_tables.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    for i, table in enumerate(tables):\n",
    "        df = table.df\n",
    "        df = df.map(lambda x: \" \".join(str(x).split(\"\\n\")).strip())\n",
    "        df.replace(\"\", np.nan, inplace=True)\n",
    "        df.iloc[2:, 0] = df.iloc[2:, 0].ffill()\n",
    "        df = df.iloc[1:, :]\n",
    "        df.columns = df.iloc[0, :].apply(clean_column_name)\n",
    "        # print(df.columns)\n",
    "        df = df.iloc[1:, :]\n",
    "        sheet_name = f\"Table_{i+1}\"\n",
    "\n",
    "        # workbook = writer.book\n",
    "        # worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "        # row = 1\n",
    "        # last_value = None\n",
    "        # start_row = None\n",
    "\n",
    "        # for j, value in enumerate(df.iloc[:, 0], start=1):\n",
    "        #     if pd.notna(value):  # New group found\n",
    "        #         if last_value is not None and start_row is not None:\n",
    "        #             worksheet.merge_range(start_row, 0, row - 1, 0, last_value)  # Merge previous block\n",
    "        #         last_value = value\n",
    "        #         start_row = row\n",
    "        #     row += 1\n",
    "\n",
    "        # # Merge last group\n",
    "        # if last_value is not None and start_row is not None:\n",
    "        #     worksheet.merge_range(start_row, 0, row - 1, 0, last_value)\n",
    "    \n",
    "        \n",
    "\n",
    "print(\"Cleaned tables saved with merged spanning rows!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{14: 'LIC MF LARGE CAP FUND',\n",
    " 15: 'LIC MF LARGE& MID CAPFUND',\n",
    " 17: 'LIC MF MULTICAP FUND',\n",
    " 18: \"LIC MF V't CAP FUND\",\n",
    " 19: 'SMALLCAP FUND',\n",
    " 21: 'LIC MF DIV_DEND YIELD FUND',\n",
    " 22: 'LIC MF VALUE FUND',\n",
    " 23: 'LIC MF FOCUSED FUND',\n",
    " 24: 'LIC MF INFRASTRUCTURE FUND',\n",
    " 25: 'LIC MF Poin MANGFACTURING FUND',\n",
    " 26: 'BANKING & FINANC-AL SERVICES FUND',\n",
    " 27: 'HEALTHCARE FUND',\n",
    " 28: 'LiC MF EL_SS TAX SAVER',\n",
    " 29: 'LIC MF AGGRESSIVE HYBRiD FUND',\n",
    " 30: 'LIC MF Bâ€™L*NCED ADVANTAGE FUND',\n",
    " 31: 'LIC MF EQUITY SAVINGS FUND',\n",
    " 32: 'LIC MF CONSERWATIVE nip?!) FUND',\n",
    " 33: 'LIC MF ARBITRAGE FUND',\n",
    " 36: 'LIC MF OVERNIGHT FUND',\n",
    " 37: 'LIC MF LIQUID FUND',\n",
    " 38: 'LIC MF ULTRA SHORT DURATION FUND',\n",
    " 40: 'LIC MF LOWâ€™ DURATION FUND',\n",
    " 41: 'LIC MF MEDIUM-F2Â°LONG DURATION FUND',\n",
    " 42: 'LIC MF BANK&ONG & PSU FUND',\n",
    " 43: 'LIC MF_. SHORT DURATION FUND',\n",
    " 45: 'LIC MGI FUND',\n",
    " 46: 'LIC MF l HILDRENS FUND',\n",
    " 47: 'BSE SENSEX ETF',\n",
    " 48: 'LIC MF NIFTY 50ETF',\n",
    " 49: 'LIC MF NIFTY 100 ETF',\n",
    " 50: 'LIC MF NIFTY MIDCAP 100 ETF',\n",
    " 51: 'LIC MF NIFTY 8-13 YR G-SECETF',\n",
    " 52: 'LIC MF BSE SENSEX INDEX FUND',\n",
    " 53: 'LIC MF NIFTY 50 INDEX FUND',\n",
    " 54: 'LIC MF NIFTY NEXT 50 INDEX FUND',\n",
    " 55: 'LIC MF G2LD EXCHANGE TRADED FUND',\n",
    " 56: 'LIC MF GSLD ETF',\n",
    " 57: 'LIC MF Large Cap Fund',\n",
    " 58: 'LIC MF Mid cap Fund',\n",
    " 59: 'LIC MF Focused Fund',\n",
    " 60: 'Lic MF ELSs Tax Saver',\n",
    " 61: 'LIC MF Arbitrage Fund',\n",
    " 63: 'LIC MF Nifty Midcap 100 ETF',\n",
    " 64: 'LIC MF Large Cap Fund',\n",
    " 65: 'LIC MF Dividend Yield Fund',\n",
    " 66: 'LIC MEF Healthcare Fund',\n",
    " 67: 'LIC MF Unit Linked Insurance Scheme __LIC MF Overnight Fund',\n",
    " 68: 'LIC MF Short Duration Fund',\n",
    " 69: 'LIC MF BSE Sensex ETF',\n",
    " 70: 'LIC MF BSE Sensex Index Fund',\n",
    " 73: 'LIC MF Healthcare Fund',\n",
    " 74: 'LIC MF Liquid Fund',\n",
    " 75: 'LIC MF Nifty 50 ETF',\n",
    " 76: 'LIC Mutual Fund'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NIPPON DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def via_block(path:str):\n",
    "    pattern = r\"FUNDS AT A GLANCE\"\n",
    "    amc_pattern = \"^(Nippon India|CPSE).*(?=Plan|Next 50|Sensex|Fund|Path|ETF|FOF|EOF|Funds|$)\"\n",
    "    imp_pages = []\n",
    "    with fitz.open(path) as doc:\n",
    "        for pgn, page in enumerate(doc):\n",
    "                page_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "                sorted_blocks = sorted(page_blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "                for block_count, block in enumerate(sorted_blocks[:10]):\n",
    "                    if \"lines\" not in block:\n",
    "                        continue\n",
    "                    for line in block[\"lines\"]:\n",
    "                        for span in line[\"spans\"]:\n",
    "                            text = span[\"text\"].strip()\n",
    "                            if re.match(pattern,text):\n",
    "                                imp_pages.append(pgn)\n",
    "                                \n",
    "        amc_fund = defaultdict(list)\n",
    "    \n",
    "        for pgn in imp_pages:\n",
    "            page = doc[pgn]\n",
    "            page_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "            sorted_blocks = sorted(page_blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "            for block_count, block in enumerate(sorted_blocks):\n",
    "                if \"lines\" not in block:\n",
    "                    continue\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        text = span[\"text\"].strip()\n",
    "                        color = span['color']\n",
    "                        if re.match(amc_pattern,text)and color == -1:\n",
    "                            # matches = re.findall(amc_pattern,text)\n",
    "                            amc_fund[pgn].append(text)\n",
    "                            \n",
    "    return imp_pages, dict(amc_fund)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages,amc = via_block(sample_path)\n",
    "pages = list(map(str,[x+1 for x in pages]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scheme = defaultdict(list)\n",
    "for key, value in amc.items():\n",
    "    # print(key)\n",
    "    set1 = ['Scheme Name']+value[:4]\n",
    "    set2 = ['Scheme Name']+value[4:]\n",
    "    final_scheme[key+1].append(set1)\n",
    "    final_scheme[key+1].append(set2)\n",
    "\n",
    "final_scheme = dict(final_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_pages = \",\".join(pages)\n",
    "tables = camelot.read_pdf(sample_path,pages=imp_pages, flavor=\"lattice\", line_scale = 40)  #table_areas = [\"0,0,580,690\"]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with pd.ExcelWriter(\"merged_tables.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    count = 0  # Toggle between 0 and 1\n",
    "    \n",
    "    for i, table in enumerate(tables):\n",
    "        df = table.df\n",
    "        if df.shape[1] < 3:\n",
    "            continue\n",
    "\n",
    "    \n",
    "        df = df.map(lambda x: \" \".join(x.split(\"\\n\")).strip())\n",
    "        df = df.map(lambda x: np.nan if not x.strip() else x)\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "        for check in [\"Scheme Name\", \"Market Capitalization\"]:\n",
    "            if check in df.index:\n",
    "                df.drop(check, inplace=True)\n",
    "                \n",
    "        df_cleaned = df[~df.index.isna()]\n",
    "        df_cleaned = df_cleaned[df_cleaned.index != \"\"]\n",
    "        df_cleaned = df_cleaned.reset_index()\n",
    "        df_fill = df_cleaned.ffill(axis=1)\n",
    "\n",
    "\n",
    "        sch_vals = final_scheme[table.page][count]\n",
    "        count = 1 - count  # Toggle between 0 and 1\n",
    "\n",
    "        if len(sch_vals) == 5:\n",
    "            df_fill.loc[-1] = sch_vals \n",
    "            df_fill = df_fill.sort_index().reset_index(drop=True)\n",
    "\n",
    "        # Write to a new sheet\n",
    "        df_fill.to_excel(writer, sheet_name=f\"Table_{i+1}\", index=False)\n",
    "\n",
    "print(\"All tables saved in separate sheets in 'merged_tables.xlsx' ðŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello =  {\n",
    "    \"number\": 0,\n",
    "    \"type\": 0,\n",
    "    \"bbox\": (0,0,0,0), #406.72119140625, 439.4930419921875, 565.697265625, 484.5830383300781\n",
    "    \"lines\": [\n",
    "        {\n",
    "            \"spans\": [\n",
    "                {\n",
    "                    \"size\": 30.0,\n",
    "                    \"flags\": 20,\n",
    "                    \"font\": \"Montserrat-Regular\", #set this\n",
    "                    \"color\": -1, #set this\n",
    "                    \"ascender\": 1.0429999828338623,\n",
    "                    \"descender\": -0.2619999945163727,\n",
    "                    \"text\": \"DUMMYDUMMYDUMMYDUMMY\",\n",
    "                    \"origin\": (406.72119140625, 458.26702880859375),\n",
    "                    \"bbox\": (0,0,0,0), #406.72119140625,439.4930419921875,565.697265625,462.9830322265625,\n",
    "                }\n",
    "            ],\n",
    "            \"wmode\": 0,\n",
    "            \"dir\": (1.0, 0.0),\n",
    "            \"bbox\": (0,0,0,0), #406.72119140625,439.4930419921875,565.697265625,462.9830322265625,\n",
    "        },\n",
    "        \n",
    "    ],\n",
    "},\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envPDF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

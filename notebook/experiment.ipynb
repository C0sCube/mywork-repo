{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint, json, math, os, sys\n",
    "import fitz, pdfplumber, ocrmypdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "dir_path = \"C:\\\\Users\\\\Kaustubh.keny\\\\Projects\\\\office-work\\\\mywork-repo\"\n",
    "fund_path = \"C:\\\\Users\\\\Kaustubh.keny\\\\Projects\\\\Mar 25\"\n",
    "\n",
    "# dir_path = \"C:\\\\Users\\\\rando\\\\OneDrive\\\\Documents\\\\mywork-repo\"\n",
    "# fund_path =  \"C:\\\\Users\\\\rando\\\\OneDrive\\\\Documents\\\\Mar25\"\n",
    "sys.path.append(os.path.abspath(dir_path))\n",
    "\n",
    "from app.utils import Helper\n",
    "from app.parse_regex import *\n",
    "\n",
    "dry_path = r'\\data\\output\\DryRun.pdf'\n",
    "fin_path = r'\\data\\input\\financial_indices.xlsx'\n",
    "mutual_fund = Helper.get_fund_paths(fund_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clipped_data(input:str, pages:list, bboxes:list):\n",
    "        \n",
    "        document = fitz.open(input)\n",
    "        final_list = []\n",
    "    \n",
    "        for pgn in pages:\n",
    "            page = document[pgn]\n",
    "            \n",
    "            all_blocks = [] #store every data from bboxes\n",
    "            \n",
    "            for bbox in bboxes:\n",
    "                blocks, seen_blocks = [], set()  #store unique blocks based on content and bbox\n",
    "                \n",
    "                page_blocks = page.get_text('dict', clip=bbox)['blocks']\n",
    "                for block in page_blocks:\n",
    "                    if block['type'] == 0 and 'lines' in block: #type 0 means text block\n",
    "                        #hash_key\n",
    "                        block_key = (tuple(block['bbox']), tuple(tuple(line['spans'][0]['text'] for line in block['lines'])))\n",
    "                        if block_key not in seen_blocks:\n",
    "                            seen_blocks.add(block_key)\n",
    "                            blocks.append(block)\n",
    "\n",
    "                sorted_blocks = sorted(blocks, key=lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "                all_blocks.append(sorted_blocks)\n",
    "\n",
    "            final_list.append({\n",
    "                \"pgn\": pgn,\n",
    "                \"block\": all_blocks #will be list[list,list,..]\n",
    "            })\n",
    "\n",
    "        document.close()\n",
    "        return final_list\n",
    "    \n",
    "def extract_data_relative_line(path: str, line_x: float, side: str):\n",
    "    doc = fitz.open(path)\n",
    "    pages = doc.page_count\n",
    "\n",
    "    final_list = []\n",
    "\n",
    "    for pgn in range(pages):\n",
    "        page = doc[pgn]\n",
    "\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        sorted_blocks = sorted(blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "        extracted_blocks = []\n",
    "\n",
    "        # Keep track of blocks to avoid duplicates\n",
    "        added_blocks = set()\n",
    "\n",
    "        for block in sorted_blocks:\n",
    "            block_id = id(block)  # Unique identifier for the block\n",
    "\n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line.get(\"spans\", []):\n",
    "                    origin = span[\"origin\"]\n",
    "                    x0, _ = origin\n",
    "\n",
    "                    # Check the side condition\n",
    "                    if side == \"left\" and x0 < line_x and block_id not in added_blocks:\n",
    "                        extracted_blocks.append(block)\n",
    "                        added_blocks.add(block_id)  # Mark block as added\n",
    "                    elif side == \"right\" and x0 > line_x and block_id not in added_blocks:\n",
    "                        extracted_blocks.append(block)\n",
    "                        added_blocks.add(block_id)  # Mark block as added\n",
    "\n",
    "      \n",
    "        final_list.append({\n",
    "            \"pgn\": pgn,\n",
    "            \"blocks\": extracted_blocks\n",
    "        })\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    return final_list\n",
    "  \n",
    "def get_clipped_data(input:str, bboxes:list[set], *args):\n",
    "    \n",
    "        document = fitz.open(input)\n",
    "        final_list = []\n",
    "        if args:\n",
    "            pages = list(args)\n",
    "        else:\n",
    "            pages = [i for i in document.page_count]\n",
    "        \n",
    "        for pgn in pages:\n",
    "            page = document[pgn]\n",
    "\n",
    "            blocks = []\n",
    "            for bbox in bboxes:\n",
    "                blocks.extend(page.get_text('dict', clip = bbox)['blocks']) #get all blocks\n",
    "            \n",
    "            filtered_blocks = [block for block in blocks if block['type']== 0 and 'lines' in block]\n",
    "            # sorted_blocks = sorted(filtered_blocks, key= lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "            \n",
    "             # Extract text from sorted blocks\n",
    "            extracted_text = []\n",
    "            for block in filtered_blocks:\n",
    "                block_text = []\n",
    "                for line in block['lines']:\n",
    "                    line_text = \" \".join(span['text'] for span in line['spans'])\n",
    "                    block_text.append(line_text)\n",
    "                extracted_text.append(\"\\n\".join(block_text))\n",
    "            \n",
    "            final_list.append({\n",
    "            \"pgn\": pgn,\n",
    "            \"block\": filtered_blocks,\n",
    "            \"text\": extracted_text\n",
    "            })\n",
    "            \n",
    "            \n",
    "        document.close()\n",
    "        return final_list\n",
    "    \n",
    "def get_clipped_text(input:str, bboxes:list[set],*args):\n",
    "\n",
    "    document = fitz.open(input)\n",
    "    final_list = []\n",
    "    \n",
    "    if args:\n",
    "        pages = list(args)\n",
    "    else:\n",
    "        pages = [i for i in document.page_count]\n",
    "    \n",
    "    for pgn in pages:\n",
    "        page = document[pgn]\n",
    "        blocks = []\n",
    "        for bbox in bboxes:\n",
    "            blocks = page.get_text('text', clip = bbox).split('\\n') #get all blocks\n",
    "        final_list.append({\n",
    "        \"pgn\": pgn,\n",
    "        \"block\": blocks\n",
    "        })   \n",
    "    document.close()\n",
    "    return final_list\n",
    "\n",
    "def get_proper_fund_names(path: str, pages: list):\n",
    "    doc = fitz.open(path)\n",
    "    title = {}\n",
    "\n",
    "    for pgn in pages:\n",
    "        page = doc[pgn]\n",
    "        blocks = page.get_text(\"dict\")['blocks']\n",
    "        text_all = \" \".join(\n",
    "            span[\"text\"].strip()\n",
    "            for block in blocks[:4]\n",
    "            for line in block.get(\"lines\", [])\n",
    "            for span in line.get(\"spans\", [])\n",
    "            if span[\"text\"].strip()\n",
    "        )\n",
    "\n",
    "        text_all = re.sub(r'[^A-Za-z0-9\\s]+', '', text_all).strip()\n",
    "        matches = re.findall(r\"((?:LIC\\s*MF|BLNCED|LOW)\\s+.*?(?:FUND|ETF|FTF|FOF|PLAN|SAVER))\", text_all, re.IGNORECASE)\n",
    "\n",
    "        title[pgn] = matches[0] if matches else \"\"\n",
    "\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = mutual_fund[\"Union Mutual Fund\"]\n",
    "# sample_path = r\"C:\\Users\\rando\\OneDrive\\Documents\\Feb25\\LIC Mutual Fund\\25_28-Feb-25_FS_ocr.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified PDF saved to: C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "    ((200, 0), (200, 812)),# Vertical line\n",
    "    ((360, 0), (360, 812)),\n",
    "    # ((0, 145), (812, 145))\n",
    "]\n",
    "pages = [12, 14,16]\n",
    "bboxes = [[435, 17, 610, 103],] #[(0, 85, 180, 812),(180, 85, 360, 812),(0,100,270,812),(0,100,350,812)]\n",
    "pages = [i for i in range(1,110)]\n",
    "Helper.draw_lines_on_pdf(sample_path, lines, bboxes, pages, dir_path +dry_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clipped_text_all_pages(pdf_path, clip_coords):\n",
    "    results = {}\n",
    "    doc = fitz.open(pdf_path)\n",
    "    clip_rect = fitz.Rect(*clip_coords)\n",
    "    try:\n",
    "        for page_number, page in enumerate(doc):\n",
    "            text = page.get_text(\"text\", clip=clip_rect).strip()\n",
    "            results[page_number] = text\n",
    "    finally:\n",
    "        doc.close()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clip_coords = (484, 50,600, 100)  # (x0, y0, x1, y1)\n",
    "\n",
    "clipped_texts = extract_clipped_text_all_pages(sample_path, clip_coords)\n",
    "\n",
    "for page_num, text in clipped_texts.items():\n",
    "    print(f\"Page {page_num}:\\n{text}\\n{'-'*40}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 2025\n",
      "INDEX MARKET REVIEW EQUITY SCHEME\n",
      "Market Review During the month of March 2025 Ind returned 7, midcaps and small ca was sharp sell-off in the early part of A\n",
      "The Fair Va Market Review\n",
      "Union FLEXI CAP FUND (An open-ended dynamic equity scheme  investing across large cap, mid cap,  small cap stocks) Factsheet as on March 31, 2025\n",
      "4 Union FLEXI CAP FUND \n",
      "Union MULTICAP FUND (Multi Cap Fund - An open ended equity  scheme investing across large cap,  mid cap, small cap stocks) Factsheet as on March 31, 2025\n",
      "5 Union MULTICAP FUND \n",
      "Union BUSINESS CYCLE FUND (An open-ended equity scheme  following business cycles  based investing theme) Factsheet as on March 31, 2025\n",
      "6 Union BUSINESS CYCLE FUND \n",
      "(An open ended equity scheme investing in  maximum 30 stocks across  market caps (i.e. Multi Cap)) Factsheet as on March 31, 2025 Union FOCUSED FUND\n",
      "7 Union FOCUSED FUND\n",
      "(Mid Cap Fund - An open-ended equity  scheme predominantly investing in  mid cap stocks) Factsheet as on March 31, 2025 Union MIDCAP FUND\n",
      "8 Union MIDCAP FUND\n",
      "(Large  Mid Cap Fund - An open ended  equity scheme investing in  both large cap and mid cap stocks) Factsheet as on March 31, 2025 Union LARGE  MIDCAP FUND\n",
      "9 Union LARGE  MIDCAP FUND\n",
      "(Small Cap Fund - An Open Ended Equity  Scheme predominantly investing in  Small Cap stocks) Factsheet as on March 31, 2025 Union SMALL CAP FUND\n",
      "10 Union SMALL CAP FUND\n",
      "(An open-ended equity scheme  following innovation theme) Factsheet as on March 31, 2025 Union INNOVATION   OPPORTUNITIES FUND\n",
      "11 Union INNOVATION   OPPORTUNITIES FUND\n",
      "(formerly Union Tax Saver (ELSS) Fund) (An open ended equity linked saving  scheme with a statutory lock in of  3 years and tax benefit.) Factsheet as on March 31, 2025 Union ELSS TAX SAVER FUND\n",
      "12 Union ELSS TAX SAVER FUND\n",
      "(formerly Union Value Discovery Fund) (An Open-ended equity scheme following  a value investment strategy) Factsheet as on March 31, 2025 Union VALUE FUND\n",
      "13 Union VALUE FUND\n",
      "(Large Cap Fund - An open ended equity  scheme predominantly investing in  large cap stocks) Factsheet as on March 31, 2025 Union LARGECAP FUND\n",
      "14 Union LARGECAP FUND\n",
      "(An open-ended equity scheme following  momentum theme) Factsheet as on March 31, 2025 Union ACTIVE MOMENTUM  FUND\n",
      "15 Union ACTIVE MOMENTUM  FUND\n",
      "(formerly Union Hybrid Equity Fund) (An open-ended hybrid scheme investing  predominantly in equity and  equity related instruments) Factsheet as on March 31, 2025 Union AGGRESSIVE HYBRID FUND\n",
      "16 Union AGGRESSIVE HYBRID FUND\n",
      "(An open-ended scheme investing in  Equity, Debt, Gold and or Silver) Factsheet as on March 31, 2025 Union MULTI ASSET  ALLOCATION FUND\n",
      "17 Union MULTI ASSET  ALLOCATION FUND\n",
      "(An Open-ended Dynamic Asset  Allocation Fund) Factsheet as on March 31, 2025 Union BALANCED  ADVANTAGE FUND\n",
      "18 Union BALANCED  ADVANTAGE FUND\n",
      "(An Open Ended Scheme investing in Equity, Arbitrage and Debt) Factsheet as on March 31, 2025 Union EQUITY SAVINGS FUND\n",
      "19 Union EQUITY SAVINGS FUND\n",
      "(An Open Ended Scheme investing in  Arbitrage Opportunities) Factsheet as on March 31, 2025 Union ARBITRAGE FUND\n",
      "20 Union ARBITRAGE FUND\n",
      "(An open-ended scheme  replicatingtracking domestic  price of Gold) Factsheet as on March 31, 2025 Union GOLD ETF\n",
      "21 Union GOLD ETF\n",
      "(An open-ended Fund of Fund  Scheme investing in units of  Union Gold ETF.) Factsheet as on March 31, 2025 Union GOLD ETF FUND OF FUND\n",
      "22 Union GOLD ETF FUND OF FUND\n",
      "Union RETIREMENT FUND (An open ended retirement solution oriented scheme having a lockin of 5 years or till  retirement age (whichever is earlier)) Factsheet as on March 31, 2025\n",
      "23 Union RETIREMENT FUND \n",
      "Union CHILDRENS FUND (An open-ended fund for investment for  children, having a lock-in for at least 5 years or till the child attains age of majority  (whichever is earlier)). Factsheet as on March 31, 2025\n",
      "24 Union CHILDRENS FUND \n",
      "(An open ended debt scheme predominantly investing in AA and above rated corporate bonds. A relatively high interest rate risk and moderate credit risk.) Factsheet as on March 31, 2025 Union CORPORATE BOND FUND\n",
      "25 Union CORPORATE BOND FUND\n",
      "(An open-ended dynamic debt Scheme  investing across duration. A relatively high  interest rate risk and moderate credit risk.) Factsheet as on March 31, 2025 Union DYNAMIC BOND FUND\n",
      "26 Union DYNAMIC BOND FUND\n",
      "(An open ended debt scheme investing in  government securities across maturity.  A relatively high interest rate risk and  relatively low credit risk.) Factsheet as on March 31, 2025 Union GILT FUND\n",
      "27 Union GILT FUND\n",
      "(An open-ended short-term debt scheme  investing in instruments such that the Macaulay duration of the portfolio is between 1 Year to  3 Years. Please refer Page No. 20 of the SID   for concept of Macaulay Duration . A high  interest rate risk and moderate credit risk.) Factsheet as on March 31, 2025 Union SHORT DURATION FUND\n",
      "28 Union SHORT DURATION FUND\n",
      "(An open ended debt scheme investing in  money market instruments. A relatively low  interest rate risk and moderate credit risk.) Factsheet as on March 31, 2025 Union MONEY MARKET FUND\n",
      "29 Union MONEY MARKET FUND\n",
      "(An Open Ended Liquid Scheme.  A relatively low interest rate risk and  moderate credit risk.) Factsheet as on March 31, 2025 Union LIQUID FUND\n",
      "30 Union LIQUID FUND\n",
      "(An open ended debt scheme investing in  overnight securities. A relatively low interest rate risk and relatively low credit risk.) Factsheet as on March 31, 2025 Union OVERNIGHT FUND\n",
      "31 Union OVERNIGHT FUND\n",
      "Union Flexi Cap Fund Net Asset Value (N (as on 31st March 2025)\n",
      "Union Dynamic Bond Fund Net Asset Value (N (as on 31st March 2025)\n",
      "Funds at a Glance Scheme Name Unio Flex Cap Fun\n",
      "Scheme Name Scheme Category Aggr U Funds at a Glance\n",
      "Funds at a Glance Scheme Name Fund Category\n",
      "Lumpsum Performanc Co-managed by Mr. Sanjay  Fund Manager Plan Option Date of  Inception (as on 31st March 2025)\n",
      "Lumpsum Performanc Co managed by Gaurav Chopra Fund Manager Plan Option Date of  Inception (as on 31st March 2025)\n",
      "Lumpsum Performanc (as on 31st March 2025) Fund Manager Plan Option Date of  Inception\n",
      "Past performance may or may not be sustained in the futur investment objectives and fundamental differences in asse Funds dated June 27, 2024 pertaining to Regulation 24(b) of  For calculation of Permitted Category FPI Portfolio, NAV is co The performance of Permitted Category FPI Portfoio is bench Lumpsum Performanc (as on 31st March 2025)\n",
      "\n",
      "SIP Performance  (SIP Returns as on March 31, 202 1 Year  Period Investmen   120,000\n",
      "SIP Performance  Investmen  Period (SIP Returns as on March 31, 202\n",
      "Scheme Details - E Attribute Union  Flexi Cap  Fund Un Mult Fu\n",
      "Scheme Details - D Attribute Minimum Application Switch-in  Amount Union Corpora Bond Fund\n",
      "Scheme Details - H  Other Schemes Minimum Application Switch-in  Amount Attribute Union Aggress Hybrid Fund\n",
      "Income Distributio Withdrawal (IDCW Union Flexi Cap F Record Date  Face Value  ()  unit NA IDCW History - Other than Dir 28 September 2017 10.00\n",
      "Mutual Fund relate Fund Manager An employee of the asset manage mutual fund or life insurer, who ma sche e He is s all pa t of a la g\n",
      "Our Presence Ahmedabad  Bangalore\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_proper_fund_names(path: str):\n",
    "    pattern = \"(Union\\\\s*[A-Z\\\\s]*?(?:FUND|PATH|ETF|FOF)\\\\s*(?:FUND\\\\s*OF\\\\s*FUND|FOF|OF\\\\s*FUND)?)\"\n",
    "    title = {}   \n",
    "    with fitz.open(path) as doc:\n",
    "        for pgn, page in enumerate(doc):\n",
    "            text = \" \".join(page.get_text(\"text\", clip=(0, 0, 180, 150)).split(\"\\n\"))\n",
    "            text = re.sub(\"[^A-Za-z0-9\\\\s\\\\-\\\\(\\\\).,]+|\\u2028\", \"\", text).strip()\n",
    "            print(text)\n",
    "            if matches := re.findall(pattern, text, re.DOTALL):\n",
    "                title[pgn] = \" \".join([_ for _ in matches[0].strip().split(\" \") if _])\n",
    "                print(pgn,matches[0])\n",
    "    return title\n",
    "title = get_proper_fund_names(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Union ACTIVE MOMENTUM FUND',\n",
       " 'Union AGGRESSIVE HYBRID FUND',\n",
       " 'Union ARBITRAGE FUND',\n",
       " 'Union BALANCED ADVANTAGE FUND',\n",
       " 'Union BUSINESS CYCLE FUND',\n",
       " 'Union CHILDRENS FUND',\n",
       " 'Union CORPORATE BOND FUND',\n",
       " 'Union DYNAMIC BOND FUND',\n",
       " 'Union ELSS TAX SAVER FUND',\n",
       " 'Union EQUITY SAVINGS FUND',\n",
       " 'Union FLEXI CAP FUND',\n",
       " 'Union FOCUSED FUND',\n",
       " 'Union GILT FUND',\n",
       " 'Union GOLD ETF',\n",
       " 'Union Gold ETF',\n",
       " 'Union INNOVATION OPPORTUNITIES FUND',\n",
       " 'Union LARGE MIDCAP FUND',\n",
       " 'Union LARGECAP FUND',\n",
       " 'Union LIQUID FUND',\n",
       " 'Union MIDCAP FUND',\n",
       " 'Union MONEY MARKET FUND',\n",
       " 'Union MULTI ASSET ALLOCATION FUND',\n",
       " 'Union MULTICAP FUND',\n",
       " 'Union OVERNIGHT FUND',\n",
       " 'Union RETIREMENT FUND',\n",
       " 'Union SHORT DURATION FUND',\n",
       " 'Union SMALL CAP FUND',\n",
       " 'Union VALUE FUND']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(title.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r\"(360 ONE.*)$\" 0,0,520,50\n",
    "# \"(Aditya Birla.*(?:Plan\\\\*?\\\\#?\\\\'?|Sensex|Fund|Path|ETF|FOF\\\\*?|Scheme|EOF|Funds\\\\*?|Yojna)?)$\" 0,0,470,25\n",
    "# \"(Bajaj.*(?:Fund|Path|ETF|FOF|EOF|Growth))$\" 0,0,470,50\n",
    "# \"(Bank of India.*?(?:Plan|Funds?|ETF|FOF|FTF))\"  0,55,280,105\n",
    "# \"(Baroda BNP.*?(?:Fund|Path|ETF|FTF|FOF|Index|Fund of Fund))\" 0,0,220,120\n",
    "# \"CANARA.*?\\\\)\" 0,0,400,55\n",
    "# \"((?:DSP|Bharat).*?(?:Fund\\\\s*(?:of Fund)?|FUND|ETF|FTF|FOF))\" 0,0,500,40\n",
    "# \"(Edelweiss\\s*.+?(?:Fund|Path|ETF|FOF|Path))\" 0,0,150,100\n",
    "# \"((?:Franklin|Templeton).*?(?:Fund\\\\s*(?:of Funds)?|Plan))\" 0,0,470,80\n",
    "# \"(GROWW.*?FUND)\" 0,0,470,60\n",
    "# \"(HDFC.*?(?:FUND|Fund\\\\s*(?:of Funds?)?|ETF\\\\s*(?:Fund of Funds?)?))\" 0,0,400,60\n",
    "# \"(HSBC.*?(?:FUND|Fund\\\\s*(?:of Funds?)?|ETF\\\\s*(?:Fund of Funds?)?))\" 0,0,600,45\n",
    "# \"(Helios.*)\" 0,0,600,40\n",
    "# \"((?:ICICI|BHARAT).*)\" 0,0,490,30\n",
    "# \"(Invesco India.*?(?:Fund(?:of Funds?)?|ETF|FOF|Path))\" 180,0,590,40\n",
    "# \"(ITI.*?(?:Fund(?:of Funds?)?|ETF|FOF|Path))\" 0,30,300,100\n",
    "# \"(JM.*?(?:Fund(?:of Funds?)?|ETF|FOF|Path))\" 0,0,400,50\n",
    "# \"(KOTAK.*?(?:FUND\\\\s*(?:OF FUNDS?\\\\s*|-\\\\s*\\\\w+)?|ETF|FOF|PATH|FTF))\" 0,0,450,70\n",
    "# \"((?:LI?i?C|BSE|BANK|SMALL|HEALTH).*?(?:FUND|Path|ETF|FTF|EOF|FOF|PLAN|SAVER|FUND\\s*OF\\s*FUND))\" 0,0,400,100\n",
    "# \"\\\\b(Mahindra.*?(?:Fund|ETF|EOF|FOF|FTF|Path|FO))\\\\b\" 170,50,450,80\n",
    "# r'MIRAE ASSET .*?\\b(?:ETF|EOF|FOF|FTF|FUND|FUND OF FUND|INDEX FUND)\\b' 0,0,560,140\n",
    "# \"(NJ.*?(?:FUND\\\\s*(?:OF FUNDS?\\\\s*|-\\\\s*\\\\w+)?|ETF|FOF|PATH|FTF))\" 0,30,480,70\n",
    "# \"([A-Z0-9\\\\s\\\\-]+\\\\s*PGIM INDIA)\" 0,0,300,80\n",
    "# \"(Samco.*?Fund)\" 0,30,600,100\n",
    "# SBI PASSIVE r\"((?:SBI|i\\s*_|S35).*$)\" 0, 0, 400, 50 \n",
    "# SBI NORMAL \"(SBI.*?(?:Fund\\\\s*(?:of funds?|.*?Plan)?|ETF|FTF|FOF))\" 160, 640, 550, 812\n",
    "# r\"(Union\\s*[A-Za-z\\s]+?(?:FUND|PATH|ETF|FOF))\" 0,0,180,150 \n",
    "# \"(Sundaram.*?(?:Fund\\\\s*(?:of funds?|.*?Plan|Series)?|ETF|FTF|FOF))\" 0,0,400,40\n",
    "# \"((?:Tata|Treasury|TATA).*?(?:Funds?(?:.*?Plan)?|ETF|FOF|EOF|Plan.*?(?:days)?))\" 0,0,540,40\n",
    "# \"((?:TAURUS|Taurus).*?(?:FUND|Fund))\" 0,0,480,40\n",
    "# \"(TRUSTMF.*?(?:FUND|Fund))\" 0,0,340,45\n",
    "# \"(quant.*?(?:FUND|Fund))\" 0,0,480,80\n",
    "# \"(UTI.*?(?:FUND(?:\\\\s*OF FUND|.+?DURATION)?|PLAN|ETF|FTF|FOF|Fund|ETF(?: FUND OF FUND)?)(?:\\\\s*\\\\(\\\\s*Erst.+?\\\\))?)\" 0,0,460,35\n",
    "# \"(WhiteOak.*?(?:Fund))\" 0,0,410,60\n",
    "# \"(Zerodha.*?(?:Fund|ETF(?:\\\\s*FoF)?|FoF))\" 0,60,500,180\n",
    "# \"(Motilal.*?(?:Fund\\\\s*(?:o?O?f Funds?(?:.+?Aggressive|.+?Conservative)?)?|ETF(?:.+? of Funds?)?|FoF))\" 0,0,600,60\n",
    "\n",
    "# \"(SHRIRAM.*?(?:FUNDS?|ETF|Fo?O?F|PLANS?))\" 0,0,480,70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Helper.get_all_pdf_data(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fitz.open(sample_path) as doc:\n",
    "    indices = [\"Fund Manager\", \"Co-Fund Manager\", \"Date of Allotment\", \"Benchmark Index\", \"Minimum Application\", \"Additional Purchase\", \"Entry Load\", \"Exit Load\", \"Portfolio Turnover\", \"Net AUM\", \"Monthly Average AUM\", \"Std Dev\", \"Sharpe Ratio\", \"Portfolio Beta\", \"R Squared\", \"Treynor\", \"YTM\", \"Macaulay\", \"Residual Maturity\", \"NAV\"]\n",
    "    output_path = sample_path.replace(\".pdf\", \"_hltd.pdf\")\n",
    "    highlight_count,found_indices = 0,[]\n",
    "    for pgn, page in enumerate(doc):\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" not in block:\n",
    "                continue\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    text = span[\"text\"].strip().lower()\n",
    "                    text =  re.sub(\"[^\\\\w\\\\s]\", \"\", text)\n",
    "                    for indice in indices:\n",
    "                        if re.search(rf\"\\b{re.escape(indice)}\\b\", text,re.IGNORECASE):\n",
    "                            if indice not in found_indices:\n",
    "                                found_indices.append(indice)\n",
    "                                highlight_count += 1\n",
    "                            page.add_highlight_annot(fitz.Rect(span[\"bbox\"]))\n",
    "                            break\n",
    "\n",
    "    doc.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#canara\n",
    "# def _update_manager_data(self,main_key:str,manager_data):\n",
    "#     name = r\"(?:Mr\\.?|Mrs\\.?|Ms\\.?)\\s+([A-Z][a-z]+\\s[A-Z][a-z]+)\"\n",
    "#     exp = r\"\\b\\d+\\s*Years?\\b\"\n",
    "#     since = r\"\\bSince\\s*([0-9]+\\s*-\\s*[A-Za-z]+\\.?\\s*-\\s*[0-9]+)\\b\"\n",
    "#     nsample, msample, esample = [], [], []\n",
    "#     nlength = 0\n",
    "#     value = \" \".join(manager_data.values())\n",
    "#     nsample = re.findall(name, value, re.IGNORECASE)\n",
    "#     esample = re.findall(exp, value, re.IGNORECASE)\n",
    "#     msample = re.findall(since, value, re.IGNORECASE)\n",
    "    \n",
    "#     nlength = len(nsample)\n",
    "#     msample += [\"\"] * (nlength - len(msample))\n",
    "#     esample += [\"\"] * (nlength - len(esample))\n",
    "    \n",
    "#     final_list = [self._return_manager_data(since=m,name=n,exp=e)for n, m, e in zip(nsample, msample, esample)]\n",
    "#     return {main_key:final_list}\n",
    "\n",
    "# # hdfc\n",
    "# def _extract_manager_data(self, main_key: str, data, pattern:str):\n",
    "#     DATE_PATTERN = r\"([A-Za-z]+\\s*\\d+),\"\n",
    "#     NAME_PATTERN = r\"([A-Za-z]+\\s[A-Za-z]+)\"\n",
    "#     EXP_PATTERN = r\"over (\\d+ years)\"\n",
    "#     YEAR_PATTERN = r\"(\\d{4})\"\n",
    "\n",
    "#     manager_data = \" \".join(data)\n",
    "#     manager_data = re.sub(r\"[^A-Za-z0-9\\s\\-\\(\\).,]+\", \"\", manager_data).strip()\n",
    "\n",
    "#     experience_years = re.findall(EXP_PATTERN, manager_data, re.IGNORECASE)\n",
    "#     dates = re.findall(DATE_PATTERN, manager_data, re.IGNORECASE)[:len(experience_years)]\n",
    "#     years = re.findall(YEAR_PATTERN, manager_data, re.IGNORECASE)[:len(experience_years)]\n",
    "#     names = re.findall(NAME_PATTERN, manager_data, re.IGNORECASE)[:len(experience_years)]\n",
    "    \n",
    "#     managing_since = [f\"{date}, {year}\" for date, year in zip(dates, years)]\n",
    "#     experience_list = [f\"{exp} years\" for exp in experience_years]\n",
    "#     final_list = [\n",
    "#         self._return_manager_data(name=name,since=since,exp=exp)\n",
    "#         for since, exp, name in zip(managing_since, experience_list, names)\n",
    "#     ]\n",
    "    \n",
    "#     return {main_key:final_list}\n",
    "\n",
    "\n",
    "# #NJMF\n",
    "# def _update_manager_data(self,main_key:str,manager_data):\n",
    "#     exp =\"\\\\d{1,2} years\"\n",
    "#     name = \"(?:Mr\\\\.?|Mrs\\\\.?|Ms\\\\.?)\\\\s*([A-Za-z]+\\\\s*[A-Za-z]+)\"\n",
    "#     since = \"(?:since|from)\\\\s*([A-Za-z]+\\\\s*\\\\d{1,2},\\\\s*\\\\d{3,4}|inception)\"\n",
    "    \n",
    "#     manager_data = \" \".join(manager_data) if isinstance(manager_data,list) else manager_data\n",
    "#     manager_data =re.sub(self.REGEX[\"escape\"], \"\", manager_data).strip()\n",
    "#     nsample = re.findall(name, manager_data, re.IGNORECASE)\n",
    "#     esample = re.findall(exp, manager_data, re.IGNORECASE)\n",
    "#     msample = re.findall(since, manager_data, re.IGNORECASE)\n",
    "#     final_list = [self._return_manager_data(since=m,name=n,exp=e)for n, m, e in zip(nsample, msample, esample)]\n",
    "#     return {main_key:final_list}\n",
    "\n",
    "# #sbi\n",
    "# def _extract_manager_data(self, main_key: str, data, pattern: str):\n",
    "#     name = \"(?:Mr\\\\.?|Mrs\\\\.?|Ms\\\\.?)\\\\s*([A-Za-z.]+\\\\s*[A-Za-z]+)\"\n",
    "#     since = \"((?:\\\\(w.e.f\\\\.?)?[A-Za-z]+\\\\s*\\\\d{4}\\\\s*(?:\\\\()?)\"\n",
    "#     exp = \"([0-9]+ years)\"\n",
    "\n",
    "#     final_list = []\n",
    "#     manager_data = \" \".join(data) if isinstance(data,list) else data\n",
    "#     manager_data =re.sub(self.REGEX[\"escape\"], \"\", manager_data).strip()\n",
    "#     n = re.findall(name,manager_data, re.IGNORECASE)\n",
    "#     s = re.findall(since,manager_data, re.IGNORECASE)\n",
    "#     e = re.findall(exp,manager_data, re.IGNORECASE)\n",
    "    \n",
    "#     adjust = lambda target, lst: target[:len(lst)] + ([target[-1]] * abs(len(target) - len(lst)) if lst else [\"\"])\n",
    "#     n,s = adjust(n,e),adjust(s,e)\n",
    "#     for name,since,exp in zip(n,s,e):\n",
    "#         final_list.append(self._return_manager_data(name=name,since=since,exp=exp))\n",
    "#     return {main_key: final_list}\n",
    "\n",
    "# #sbI PASSIVE\n",
    "# def _update_manager_data(self,main_key:str,data):\n",
    "#     final_list = []\n",
    "#     manager_data = \" \".join(data) if isinstance(data, list) else data\n",
    "#     manager_data = re.sub(self.REGEX['escape'], \"\", manager_data).strip()\n",
    "#     pattern_info = self.REGEX[\"manager\"]\n",
    "#     regex_pattern = pattern_info['pattern']\n",
    "#     field_names = pattern_info['fields']\n",
    "#     if matches := re.findall(regex_pattern, manager_data, re.IGNORECASE):\n",
    "#         for match in matches:\n",
    "#             if isinstance(match, str):\n",
    "#                 match = (match,)\n",
    "#             record = {field_names[i]: match[i] if i < len(match) else \"\" for i in range(len(field_names))} #kwargs\n",
    "#             final_list.append(self._return_manager_data(**record))\n",
    "\n",
    "#     return {main_key: final_list}\n",
    "    \n",
    "# # ADITYA\n",
    "# def _update_manager_data(self,main_key:str,manager_data):\n",
    "#     nsample, msample, esample = [], [], []\n",
    "#     nlength = 0\n",
    "#     for key, value in manager_data.items():\n",
    "#         if re.search(r\"\\bfund_manager\\b\", key, re.IGNORECASE):\n",
    "#             nsample = re.findall(self.REGEX[\"manager\"][\"name\"], value, re.IGNORECASE)\n",
    "#             nlength = len(nsample)\n",
    "\n",
    "#         elif re.search(r\"^managing\", key, re.IGNORECASE):\n",
    "#             msample = re.findall(self.REGEX[\"manager\"][\"since\"], value, re.IGNORECASE)\n",
    "            \n",
    "#         elif re.search(r\"^experience\", key, re.IGNORECASE):\n",
    "#             esample = re.findall(self.REGEX[\"manager\"][\"exp\"], value, re.IGNORECASE)\n",
    "#     nlength = len(nsample)\n",
    "#     msample += [\"\"] * (nlength - len(msample))\n",
    "#     esample += [\"\"] * (nlength - len(esample))\n",
    "\n",
    "#     final_list = [\n",
    "#         self._return_manager_data(since=m,name=n,exp=e)\n",
    "#         for n, m, e in zip(nsample, msample, esample)\n",
    "#     ]\n",
    "\n",
    "#     return {main_key:final_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "def get_something(path: str):\n",
    "    pattern = r\"^(REDEMPTION PROCEEDS|FEATURES|ASSET ALLOCATION|FUND MANAGER|SCHEME|Sr\\. No\\.)$\"\n",
    "\n",
    "    with fitz.open(path) as doc:\n",
    "        exists = defaultdict(int)\n",
    "        for pgn, page in enumerate(doc):\n",
    "            page_text = [t.strip() for t in page.get_text().split(\"\\n\")]\n",
    "            for text in page_text:\n",
    "                if re.match(pattern,text):\n",
    "                    exists[pgn]+=1\n",
    "                    \n",
    "    \n",
    "    return [str(pgn+1) for pgn, count in exists.items() if count > 4] #camelot starts pages from 1\n",
    "\n",
    "pages = get_something(sample_path)\n",
    "\n",
    "imp_pages = \",\".join(pages)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = camelot.read_pdf(sample_path,pages=imp_pages, flavor=\"stream\", table_areas= [\"30,50,612,812\"],column_tol = 4, split_text = True) #[\"30,50,612,812\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_column_name(x):\n",
    "    cleaned = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", str(x), flags=re.IGNORECASE) #Corrected re.sub.\n",
    "    cleaned = \"_\".join(cleaned.split())\n",
    "    return cleaned\n",
    "\n",
    "with pd.ExcelWriter(\"cleaned_tables.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    for i, table in enumerate(tables):\n",
    "        df = table.df\n",
    "        df = df.map(lambda x: \" \".join(str(x).split(\"\\n\")).strip())\n",
    "        df.replace(\"\", np.nan, inplace=True)\n",
    "        df.iloc[2:, 0] = df.iloc[2:, 0].ffill()\n",
    "        df = df.iloc[1:, :]\n",
    "        df.columns = df.iloc[0, :].apply(clean_column_name)\n",
    "        # print(df.columns)\n",
    "        df = df.iloc[1:, :]\n",
    "        sheet_name = f\"Table_{i+1}\"\n",
    "\n",
    "        # workbook = writer.book\n",
    "        # worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "        # row = 1\n",
    "        # last_value = None\n",
    "        # start_row = None\n",
    "\n",
    "        # for j, value in enumerate(df.iloc[:, 0], start=1):\n",
    "        #     if pd.notna(value):  # New group found\n",
    "        #         if last_value is not None and start_row is not None:\n",
    "        #             worksheet.merge_range(start_row, 0, row - 1, 0, last_value)  # Merge previous block\n",
    "        #         last_value = value\n",
    "        #         start_row = row\n",
    "        #     row += 1\n",
    "\n",
    "        # # Merge last group\n",
    "        # if last_value is not None and start_row is not None:\n",
    "        #     worksheet.merge_range(start_row, 0, row - 1, 0, last_value)\n",
    "    \n",
    "        \n",
    "\n",
    "print(\"Cleaned tables saved with merged spanning rows!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_dict_cleaned = {\n",
    "#     'LIC MF LARGE CAP FUND': 'LARGE CAP',\n",
    "#     'LIC MF LARGE & MID CAP FUND': 'LARGE& MID CAP',\n",
    "#     'LIC MF MULTICAP FUND': 'MULTICAP',\n",
    "#     'LIC MF MID CAP FUND': \"V't CAP\",\n",
    "#     'LIC MF SMALLCAP FUND': 'SMALLCAP',\n",
    "#     'LIC MF DIVIDEND YIELD FUND': 'DIV_DEND YIELD',\n",
    "#     'LIC MF VALUE FUND': 'VALUE',\n",
    "#     'LIC MF FOCUSED FUND': 'FOCUSED',\n",
    "#     'LIC MF INFRASTRUCTURE FUND': 'INFRASTRUCTURE',\n",
    "#     'LIC MF MANUFACTURING FUND': 'Poin MANGFACTURING',\n",
    "#     'LIC MF BANKING & FINANCIAL SERVICES FUND': 'BANKING & FINANC-AL SERVICES',\n",
    "#     'LIC MF HEALTHCARE FUND': 'HEALTHCARE',\n",
    "#     'LIC MF ELSS TAX SAVER': 'EL_SS TAX SAVER',\n",
    "#     'LIC MF AGGRESSIVE HYBID FUND': 'AGGRESSIVE HYBRiD',\n",
    "#     'LIC MF BALANCED ADVANTAGE FUND': 'Bâ€™L*NCED ADVANTAGE',\n",
    "#     'LIC MF EQUITY SAVINGS FUND': 'EQUITY SAVINGS',\n",
    "#     'LIC MF CONSERVATIVE HYBRID FUND': 'CONSERWATIVE nip?!)',\n",
    "#     'LIC MF ARBITRAGE FUND': 'ARBITRAGE',\n",
    "#     'LIC MF OVERNIGHT FUND': 'OVERNIGHT',\n",
    "#     'LIC MF LIQUID FUND': 'LIQUID',\n",
    "#     'LIC MF ULTRA SHORT DURATION FUND': 'ULTRA SHORT DURATION',\n",
    "#     'LIC MF LOW DURATION FUND': \"LOWâ€™ DURATION\",\n",
    "#     'LIC MF MEDIUM TO LONG DURATION FUND': 'MEDIUM-F2Â°LONG DURATION',\n",
    "#     'LIC MF BANKING & PSU FUND': 'BANK&ONG & PSU',\n",
    "#     'LIC MF SHORT DURATION FUND': '_. SHORT DURATION',\n",
    "#     'LIC MF GILT FUND': 'MGI',\n",
    "#     'LIC MF CHILDRENS FUND': 'l HILDRENS',\n",
    "#     'LIC MF BSE SENSEX ETF': 'BSE SENSEX ETF',\n",
    "#     'LIC MF NIFTY 50 ETF': 'NIFTY 50ETF',\n",
    "#     'LIC MF NIFTY 100 ETF': 'NIFTY 100 ETF',\n",
    "#     'LIC MF NIFTY MIDCAP 100 ETF': 'NIFTY MIDCAP 100 ETF',\n",
    "#     'LIC MF NIFTY 8-13 YR G-SEC ETF': 'NIFTY 8-13 YR G-SECETF',\n",
    "#     'LIC MF BSE SENSEX INDEX FUND': 'BSE SENSEX INDEX',\n",
    "#     'LIC MF NIFTY 50 INDEX FUND': 'NIFTY 50 INDEX',\n",
    "#     'LIC MF NIFTY NEXT 50 INDEX FUND': 'NIFTY NEXT 50 INDEX',\n",
    "#     'LIC MF GOLD EXCHANGE TRADED FUND': 'G2LD EXCHANGE TRADED',\n",
    "#     'LIC MF GOLD ETF FUND OF FUND': 'GSLD ETF',\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_dict_cleaned = {\n",
    "    'LIC MF LARGE CAP FUND': 'LARGE CAP',\n",
    "    'LIC MF LARGE & MID CAP FUND': 'LARGE.*?MID CAP',\n",
    "    'LIC MF MULTICAP FUND': 'MULTICAP',\n",
    "    'LIC MF MID CAP FUND': \"V't CAP\",\n",
    "    'LIC MF SMALLCAP FUND': 'SMALLCAP',\n",
    "    'LIC MF DIVIDEND YIELD FUND': 'DI.*?END YIELD',\n",
    "    'LIC MF VALUE FUND': 'VALUE FUND',\n",
    "    'LIC MF FOCUSED FUND': 'FOCUSED FUND',\n",
    "    'LIC MF INFRASTRUCTURE FUND': 'INFRASTRUCTURE',\n",
    "    'LIC MF MANUFACTURING FUND': 'MANGFACTURING',\n",
    "    'LIC MF BANKING & FINANCIAL SERVICES FUND': 'BANKING.*?FINAN.*?SERVICES',\n",
    "    'LIC MF HEALTHCARE FUND': 'HEALTHCARE',\n",
    "    'LIC MF ELSS TAX SAVER': 'EL.*?TAX SAVER',\n",
    "    'LIC MF AGGRESSIVE HYBID FUND': 'AGGRESSIVE HYBRiD',\n",
    "    'LIC MF BALANCED ADVANTAGE FUND': 'B.*?NCED ADVANTAGE',\n",
    "    'LIC MF EQUITY SAVINGS FUND': 'EQUITY SAVINGS',\n",
    "    'LIC MF CONSERVATIVE HYBRID FUND': 'CONSERWATIVE.*nip?!)',\n",
    "    'LIC MF ARBITRAGE FUND': 'ARBITRAGE FUND',\n",
    "    'LIC MF OVERNIGHT FUND': 'OVERNIGHT',\n",
    "    '':'LIC MF MULTI.*?CATION FUND',\n",
    "    'LIC MF LIQUID FUND': 'LIQUID FUND',\n",
    "    'LIC MF ULTRA SHORT DURATION FUND': 'ULTRA SHORT DURATION',\n",
    "    'LIC MF LOW DURATION FUND': \"LO.*?DURATION\",\n",
    "    'LIC MF MEDIUM TO LONG DURATION FUND': 'MEDIUM.*?LONG DURATION',\n",
    "    'LIC MF BANKING & PSU FUND': 'BANK.*?PSU',\n",
    "    'LIC MF SHORT DURATION FUND': 'SHORT DURATION',\n",
    "    'LIC MF GILT FUND': 'MGI',\n",
    "    'LIC MF CHILDRENS FUND': '.*?HILDRE.*?FUND',\n",
    "    'LIC MF BSE SENSEX ETF': 'BSE SENSEX ETF',\n",
    "    'LIC MF NIFTY 50 ETF': 'NIFTY\\\\s*50\\\\s*ETF',\n",
    "    'LIC MF NIFTY 100 ETF': 'NIFTY 100 ETF',\n",
    "    'LIC MF NIFTY MIDCAP 100 ETF': 'NIFTY MIDCAP 100 ETF',\n",
    "    'LIC MF NIFTY 8-13 YR G-SEC ETF': 'NIFTY 8-13 YR G-SEC\\\\s*ETF',\n",
    "    'LIC MF BSE SENSEX INDEX FUND': 'BSE SENSEX INDEX',\n",
    "    'LIC MF NIFTY 50 INDEX FUND': 'NIFTY 50 INDEX',\n",
    "    'LIC MF NIFTY NEXT 50 INDEX FUND': 'NIFTY NEXT 50 INDEX',\n",
    "    'LIC MF GOLD EXCHANGE TRADED FUND': 'G2LD\\\\s*EXCHANGE\\\\s*TRADED',\n",
    "    'LIC MF GOLD ETF FUND OF FUND': 'GSLD\\s*ETF',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NIPPON DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def via_block(path:str):\n",
    "    pattern = r\"FUNDS AT A GLANCE\"\n",
    "    amc_pattern = \"^(Nippon India|CPSE).*(?=Plan|Next 50|Sensex|Fund|Path|ETF|FOF|EOF|Funds|$)\"\n",
    "    imp_pages = []\n",
    "    with fitz.open(path) as doc:\n",
    "        for pgn, page in enumerate(doc):\n",
    "                page_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "                sorted_blocks = sorted(page_blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "                for block_count, block in enumerate(sorted_blocks[:10]):\n",
    "                    if \"lines\" not in block:\n",
    "                        continue\n",
    "                    for line in block[\"lines\"]:\n",
    "                        for span in line[\"spans\"]:\n",
    "                            text = span[\"text\"].strip()\n",
    "                            if re.match(pattern,text):\n",
    "                                imp_pages.append(pgn)\n",
    "                                \n",
    "        amc_fund = defaultdict(list)\n",
    "    \n",
    "        for pgn in imp_pages:\n",
    "            page = doc[pgn]\n",
    "            page_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "            sorted_blocks = sorted(page_blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "            for block_count, block in enumerate(sorted_blocks):\n",
    "                if \"lines\" not in block:\n",
    "                    continue\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        text = span[\"text\"].strip()\n",
    "                        color = span['color']\n",
    "                        if re.match(amc_pattern,text)and color == -1:\n",
    "                            # matches = re.findall(amc_pattern,text)\n",
    "                            amc_fund[pgn].append(text)\n",
    "                            \n",
    "    return imp_pages, dict(amc_fund)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages,amc = via_block(sample_path)\n",
    "pages = list(map(str,[x+1 for x in pages]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scheme = defaultdict(list)\n",
    "for key, value in amc.items():\n",
    "    # print(key)\n",
    "    set1 = ['Scheme Name']+value[:4]\n",
    "    set2 = ['Scheme Name']+value[4:]\n",
    "    final_scheme[key+1].append(set1)\n",
    "    final_scheme[key+1].append(set2)\n",
    "\n",
    "final_scheme = dict(final_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_pages = \",\".join(pages)\n",
    "tables = camelot.read_pdf(sample_path,pages=imp_pages, flavor=\"lattice\", line_scale = 40)  #table_areas = [\"0,0,580,690\"]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with pd.ExcelWriter(\"merged_tables.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    count = 0  # Toggle between 0 and 1\n",
    "    \n",
    "    for i, table in enumerate(tables):\n",
    "        df = table.df\n",
    "        if df.shape[1] < 3:\n",
    "            continue\n",
    "\n",
    "    \n",
    "        df = df.map(lambda x: \" \".join(x.split(\"\\n\")).strip())\n",
    "        df = df.map(lambda x: np.nan if not x.strip() else x)\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "        for check in [\"Scheme Name\", \"Market Capitalization\"]:\n",
    "            if check in df.index:\n",
    "                df.drop(check, inplace=True)\n",
    "                \n",
    "        df_cleaned = df[~df.index.isna()]\n",
    "        df_cleaned = df_cleaned[df_cleaned.index != \"\"]\n",
    "        df_cleaned = df_cleaned.reset_index()\n",
    "        df_fill = df_cleaned.ffill(axis=1)\n",
    "\n",
    "\n",
    "        sch_vals = final_scheme[table.page][count]\n",
    "        count = 1 - count  # Toggle between 0 and 1\n",
    "\n",
    "        if len(sch_vals) == 5:\n",
    "            df_fill.loc[-1] = sch_vals \n",
    "            df_fill = df_fill.sort_index().reset_index(drop=True)\n",
    "\n",
    "        # Write to a new sheet\n",
    "        df_fill.to_excel(writer, sheet_name=f\"Table_{i+1}\", index=False)\n",
    "\n",
    "print(\"All tables saved in separate sheets in 'merged_tables.xlsx' ðŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello =  {\n",
    "    \"number\": 0,\n",
    "    \"type\": 0,\n",
    "    \"bbox\": (0,0,0,0), #406.72119140625, 439.4930419921875, 565.697265625, 484.5830383300781\n",
    "    \"lines\": [\n",
    "        {\n",
    "            \"spans\": [\n",
    "                {\n",
    "                    \"size\": 30.0,\n",
    "                    \"flags\": 20,\n",
    "                    \"font\": \"Montserrat-Regular\", #set this\n",
    "                    \"color\": -1, #set this\n",
    "                    \"ascender\": 1.0429999828338623,\n",
    "                    \"descender\": -0.2619999945163727,\n",
    "                    \"text\": \"DUMMYDUMMYDUMMYDUMMY\",\n",
    "                    \"origin\": (406.72119140625, 458.26702880859375),\n",
    "                    \"bbox\": (0,0,0,0), #406.72119140625,439.4930419921875,565.697265625,462.9830322265625,\n",
    "                }\n",
    "            ],\n",
    "            \"wmode\": 0,\n",
    "            \"dir\": (1.0, 0.0),\n",
    "            \"bbox\": (0,0,0,0), #406.72119140625,439.4930419921875,565.697265625,462.9830322265625,\n",
    "        },\n",
    "        \n",
    "    ],\n",
    "},  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

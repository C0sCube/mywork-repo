{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint, json, math, os, sys, camelot\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "dir_path = \"C:\\\\Users\\\\Kaustubh.keny\\\\OneDrive - Cogencis Information Services Ltd\\\\Documents\\\\mywork-repo\\\\\"\n",
    "fund_path = \"C:\\\\Users\\\\Kaustubh.keny\\\\OneDrive - Cogencis Information Services Ltd\\\\Documents\\\\Dec 24\\\\\"\n",
    "\n",
    "# dir_path = \"C:\\\\Users\\\\rando\\\\OneDrive\\\\Documents\\\\mywork-repo\"\n",
    "# fund_path =  \"C:\\\\Users\\\\rando\\\\OneDrive\\\\Documents\\\\Dec 24\"\n",
    "sys.path.append(os.path.abspath(dir_path))\n",
    "\n",
    "from app.utils import Helper\n",
    "from app.fund_regex import *\n",
    "\n",
    "dry_path = r'\\data\\output\\DryRun.pdf'\n",
    "fin_path = r'\\data\\input\\financial_indices.xlsx'\n",
    "mutual_fund = Helper.get_fund_paths(fund_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clipped_data(input:str, pages:list, bboxes:list):\n",
    "        \n",
    "        document = fitz.open(input)\n",
    "        final_list = []\n",
    "    \n",
    "        for pgn in pages:\n",
    "            page = document[pgn]\n",
    "            \n",
    "            all_blocks = [] #store every data from bboxes\n",
    "            \n",
    "            for bbox in bboxes:\n",
    "                blocks, seen_blocks = [], set()  #store unique blocks based on content and bbox\n",
    "                \n",
    "                page_blocks = page.get_text('dict', clip=bbox)['blocks']\n",
    "                for block in page_blocks:\n",
    "                    if block['type'] == 0 and 'lines' in block: #type 0 means text block\n",
    "                        #hash_key\n",
    "                        block_key = (tuple(block['bbox']), tuple(tuple(line['spans'][0]['text'] for line in block['lines'])))\n",
    "                        if block_key not in seen_blocks:\n",
    "                            seen_blocks.add(block_key)\n",
    "                            blocks.append(block)\n",
    "\n",
    "                sorted_blocks = sorted(blocks, key=lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "                all_blocks.append(sorted_blocks)\n",
    "\n",
    "            final_list.append({\n",
    "                \"pgn\": pgn,\n",
    "                \"block\": all_blocks #will be list[list,list,..]\n",
    "            })\n",
    "\n",
    "        document.close()\n",
    "        return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_relative_line(path: str, line_x: float, side: str):\n",
    "    doc = fitz.open(path)\n",
    "    pages = doc.page_count\n",
    "\n",
    "    final_list = []\n",
    "\n",
    "    for pgn in range(pages):\n",
    "        page = doc[pgn]\n",
    "\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        sorted_blocks = sorted(blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "        extracted_blocks = []\n",
    "\n",
    "        # Keep track of blocks to avoid duplicates\n",
    "        added_blocks = set()\n",
    "\n",
    "        for block in sorted_blocks:\n",
    "            block_id = id(block)  # Unique identifier for the block\n",
    "\n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line.get(\"spans\", []):\n",
    "                    origin = span[\"origin\"]\n",
    "                    x0, _ = origin\n",
    "\n",
    "                    # Check the side condition\n",
    "                    if side == \"left\" and x0 < line_x and block_id not in added_blocks:\n",
    "                        extracted_blocks.append(block)\n",
    "                        added_blocks.add(block_id)  # Mark block as added\n",
    "                    elif side == \"right\" and x0 > line_x and block_id not in added_blocks:\n",
    "                        extracted_blocks.append(block)\n",
    "                        added_blocks.add(block_id)  # Mark block as added\n",
    "\n",
    "      \n",
    "        final_list.append({\n",
    "            \"pgn\": pgn,\n",
    "            \"blocks\": extracted_blocks\n",
    "        })\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    return final_list\n",
    "\n",
    "def extract_spans(data):\n",
    "    final_span = []\n",
    "    for pgn,blocks in enumerate(data):\n",
    "        spans = []\n",
    "        print(f\"___{pgn}___\")\n",
    "        for num,block in enumerate(blocks.get('blocks',[])):\n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line.get(\"spans\", []):\n",
    "                    if num in range(3,10):\n",
    "                        print(span['text'], span['size'])\n",
    "        final_span.append(spans)\n",
    "    return final_span\n",
    "\n",
    "def get_proper_fund_names(path:str,pages:list):\n",
    "        \n",
    "    doc = fitz.open(path)\n",
    "    final_fund_names = dict()\n",
    "    \n",
    "    for pgn in range(doc.page_count):\n",
    "        text_all = ''\n",
    "        if pgn in pages:\n",
    "            # print(pgn)\n",
    "            page = doc[pgn]            \n",
    "            blocks = page.get_text(\"dict\")['blocks']\n",
    "            \n",
    "            sorted_blocks = sorted(blocks,key=lambda k:(k['bbox'][1],k['bbox'][0]))\n",
    "            for count,block in enumerate(sorted_blocks):\n",
    "                for line in block.get(\"lines\", []):\n",
    "                    for span in line.get(\"spans\", []):\n",
    "                        text = span['text'].strip()\n",
    "                        if count in range(0,1):\n",
    "                            text_all+=f\" {text}\"\n",
    "            print(text_all)\n",
    "        pattern = r\"MIRAE ASSET.*?\\b(?:ETF|EOF|FOF|FTF|FUND)\\b\"\n",
    "        if matches := re.findall(pattern, text_all.strip(), re.DOTALL):\n",
    "            final_fund_names[pgn] = matches[0]\n",
    "        else:\n",
    "            final_fund_names[pgn] = \"\"\n",
    "    return final_fund_names\n",
    "  \n",
    "def get_clipped_data(input:str, bboxes:list[set]):\n",
    "    \n",
    "        document = fitz.open(input)\n",
    "        final_list = []\n",
    "        \n",
    "        for pgn in range(document.page_count):\n",
    "            page = document[pgn]\n",
    "\n",
    "            blocks = []\n",
    "            for bbox in bboxes:\n",
    "                blocks.extend(page.get_text('dict', clip = bbox)['blocks']) #get all blocks\n",
    "            \n",
    "            filtered_blocks = [block for block in blocks if block['type']== 0 and 'lines' in block]\n",
    "            # sorted_blocks = sorted(filtered_blocks, key= lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "            \n",
    "            final_list.append({\n",
    "            \"pgn\": pgn,\n",
    "            \"block\": filtered_blocks\n",
    "            })\n",
    "            \n",
    "            \n",
    "        document.close()\n",
    "        return final_list\n",
    "    \n",
    "def get_clipped_text(input:str, bboxes:list[set]):\n",
    "\n",
    "    document = fitz.open(input)\n",
    "    final_list = []\n",
    "    \n",
    "    for pgn in range(document.page_count):\n",
    "        page = document[pgn]\n",
    "        blocks = []\n",
    "        for bbox in bboxes:\n",
    "            blocks = page.get_text('text', clip = bbox).split('\\n') #get all blocks\n",
    "  \n",
    "        final_list.append({\n",
    "        \"pgn\": pgn,\n",
    "        \"block\": blocks\n",
    "        })   \n",
    "    document.close()\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path  = mutual_fund['Nippon India Mutual Fund']\n",
    "pages = [12, 14,16]\n",
    "bboxes = [(200, 50, 380, 812),(380, 50, 580, 812)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified PDF saved to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "    ((220, 0), (220, 812)),# Vertical line\n",
    "    #((420, 0), (420, 1000))\n",
    "]\n",
    "\n",
    "rectangles = [(0, 50, 200, 812),(200, 50, 380, 812),(380, 50, 580, 812)]\n",
    "pages = [i for i in range(1,110)]\n",
    "Helper.draw_lines_on_pdf(sample_path, lines, rectangles, pages, dir_path +dry_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Helper.get_all_pdf_data(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_someting(path:str):\n",
    "    pattern = r\"\\bFUNDS AT A GLANCE\\b\"\n",
    "    \n",
    "    with fitz.open(path) as doc:\n",
    "        for pgn,page in enumerate(doc):\n",
    "            page_text =\"\".join(page.get_text().split(\"\\n\"))\n",
    "            # print(page_text)\n",
    "            if re.match(pattern,page_text):\n",
    "                print(pgn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Kaustubh.keny\\\\OneDrive - Cogencis Information Services Ltd\\\\Documents\\\\Dec 24\\\\Nippon India Mutual Fund\\\\33_31-Dec-24_FS.pdf'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def via_block(path:str):\n",
    "    \n",
    "    pattern = r\"FUNDS AT A GLANCE\"\n",
    "    amc_pattern = \"^(Nippon India|CPSE).*(?=Plan|Sensex|Fund|Path|ETF|FOF|EOF|Funds|$)\"\n",
    "    imp_pages = []\n",
    "    with fitz.open(path) as doc:\n",
    "        for pgn, page in enumerate(doc):\n",
    "                page_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "                sorted_blocks = sorted(page_blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "                for block_count, block in enumerate(sorted_blocks[:10]):\n",
    "                    if \"lines\" not in block:\n",
    "                        continue\n",
    "                    for line in block[\"lines\"]:\n",
    "                        for span in line[\"spans\"]:\n",
    "                            text = span[\"text\"].strip()\n",
    "                            if re.match(pattern,text):\n",
    "                                imp_pages.append(pgn)\n",
    "                                \n",
    "        amc_fund = defaultdict(list)\n",
    "    \n",
    "        for pgn in imp_pages:\n",
    "            page = doc[pgn]\n",
    "            page_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "            sorted_blocks = sorted(page_blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "            for block_count, block in enumerate(sorted_blocks):\n",
    "                if \"lines\" not in block:\n",
    "                    continue\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        text = span[\"text\"].strip()\n",
    "                        if re.match(amc_pattern,text):\n",
    "                            amc_fund[pgn].append(text)\n",
    "                            \n",
    "    return imp_pages, dict(amc_fund)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages,amc = via_block(sample_path)\n",
    "pages = list(map(str,pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scheme = []\n",
    "for key, value in amc.items():\n",
    "    # print(key)\n",
    "    set1 = ['Type of Scheme']+value[:4]\n",
    "    set2 = ['Type of Scheme']+value[4:]\n",
    "    final_scheme.append(set1)\n",
    "    final_scheme.append(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imp_pages = \",\".join(pages)\n",
    "tables = camelot.read_pdf(sample_path,pages=imp_pages, flavor=\"lattice\", line_scale = 40)  #table_areas = [\"0,0,580,690\"]            \n",
    "# html_table = tables[0].df.to_html(index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tables = []\n",
    "for i,table in enumerate(tables):\n",
    "    df = table.df\n",
    "    if df.shape[1]<3:\n",
    "        continue\n",
    "    df= df.map(lambda x: \" \".join(x.split(\"\\n\")).strip())\n",
    "    df = df.map(lambda x: np.nan if not x.strip() else x)\n",
    "    \n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "    \n",
    "    check = \"Scheme Name\"\n",
    "    if check in df.index:\n",
    "        df.drop(check, inplace=True)\n",
    "    \n",
    "    check = \"Market Capitalization\"\n",
    "    if check in df.index:\n",
    "        df.drop(check, inplace=True)\n",
    "        \n",
    "    df_cleaned = df[~df.index.isna()]  # Remove NaN index\n",
    "    df_cleaned = df_cleaned[df_cleaned.index != \"\"]  # Remove empty string index\n",
    "\n",
    "    df_cleaned = df_cleaned.reset_index()\n",
    "    df_fill = df_cleaned.ffill(axis=1)\n",
    "    df_fill.to_excel(f\"sample{i}.xlsx\", index=False)\n",
    "    final_tables.append(df_fill)\n",
    "    # print(final_scheme[i-1])\n",
    "    # print(i,df_fill.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tables[2].df.set_index(df.columns[0])\n",
    "# if \"Scheme Name\" in data.index:\n",
    "#     data.drop(\"Scheme Name\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Scheme Name</th>\n",
       "      <td>Nippon India Focused Equity Fund</td>\n",
       "      <td>Nippon India Small Cap Fund</td>\n",
       "      <td>Nippon India Value Fund</td>\n",
       "      <td>Nippon India Multi Cap Fund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type of Scheme</th>\n",
       "      <td>An open ended Multi Cap Equity Scheme investin...</td>\n",
       "      <td>An\\nopen-ended\\nequity\\nscheme\\npredominantly\\...</td>\n",
       "      <td>An\\nopen\\nended\\nequity\\nscheme\\nfollowing\\na\\...</td>\n",
       "      <td>Multi Cap\\nFund\\n- An\\nopen\\nended\\nequity\\nsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allotment Date</th>\n",
       "      <td>April 28, 2018 (Date of Recategorisation)</td>\n",
       "      <td>September 16, 2010</td>\n",
       "      <td>June 08, 2005</td>\n",
       "      <td>March 28, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Investment Objective</th>\n",
       "      <td>The primary investment objective of\\nthe schem...</td>\n",
       "      <td>The primary investment objective of\\nthe schem...</td>\n",
       "      <td>The primary investment objective of\\nthis sche...</td>\n",
       "      <td>The primary investment objective of\\nthe schem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fund Manager</th>\n",
       "      <td>Vinay Sharma#\\nRishit Parikh (Assistant Fund M...</td>\n",
       "      <td>Samir Rachh#</td>\n",
       "      <td>Dhrumil Shah,\\nMeenakshi Dawar #</td>\n",
       "      <td>Sailesh Raj Bhan\\nAshutosh Bhargava (Co-Fund M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benchmark</th>\n",
       "      <td>BSE 500 TRI</td>\n",
       "      <td>Nifty Smallcap 250 TRI</td>\n",
       "      <td>Nifty 500 TRI</td>\n",
       "      <td>NIFTY 500 Multicap 50:25:25 TRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry Load</th>\n",
       "      <td>Not Applicable. The upfront commission on inve...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exit Load</th>\n",
       "      <td>10% of\\nthe units allotted shall be redeemed w...</td>\n",
       "      <td>1% if\\nredeemed\\nor\\nswitched\\nout\\non\\nor\\nbe...</td>\n",
       "      <td>10% of\\nthe units allotted shall be redeemed w...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Investment Plans/ Options</th>\n",
       "      <td>Under both Direct and other than Direct plan\\n...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minimum Application Amount</th>\n",
       "      <td>Purchase: ₹5000 &amp; in multiples of ₹1 thereafte...</td>\n",
       "      <td>Fresh/ additional subscriptions/switch-ins wil...</td>\n",
       "      <td>Purchase: ₹500 &amp; in multiples of ₹1 thereafter...</td>\n",
       "      <td>Purchase: ₹100 &amp; in multiples of ₹1 thereafter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market Capitalization</th>\n",
       "      <td>Large Cap: 58%\\nMid Cap: 21%\\nSmall Cap: 21%</td>\n",
       "      <td>Large Cap: 12%\\nMid Cap: 14%\\nSmall Cap: 74%</td>\n",
       "      <td>Large Cap: 60%\\nMid Cap: 17%\\nSmall Cap: 23%</td>\n",
       "      <td>Large Cap: 42%\\nMid Cap: 26%\\nSmall Cap: 32%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            1  \\\n",
       "0                                                                               \n",
       "Scheme Name                                  Nippon India Focused Equity Fund   \n",
       "Type of Scheme              An open ended Multi Cap Equity Scheme investin...   \n",
       "Allotment Date                      April 28, 2018 (Date of Recategorisation)   \n",
       "Investment Objective        The primary investment objective of\\nthe schem...   \n",
       "Fund Manager                Vinay Sharma#\\nRishit Parikh (Assistant Fund M...   \n",
       "Benchmark                                                         BSE 500 TRI   \n",
       "Entry Load                  Not Applicable. The upfront commission on inve...   \n",
       "Exit Load                   10% of\\nthe units allotted shall be redeemed w...   \n",
       "Investment Plans/ Options   Under both Direct and other than Direct plan\\n...   \n",
       "Minimum Application Amount  Purchase: ₹5000 & in multiples of ₹1 thereafte...   \n",
       "Market Capitalization            Large Cap: 58%\\nMid Cap: 21%\\nSmall Cap: 21%   \n",
       "\n",
       "                                                                            2  \\\n",
       "0                                                                               \n",
       "Scheme Name                                       Nippon India Small Cap Fund   \n",
       "Type of Scheme              An\\nopen-ended\\nequity\\nscheme\\npredominantly\\...   \n",
       "Allotment Date                                             September 16, 2010   \n",
       "Investment Objective        The primary investment objective of\\nthe schem...   \n",
       "Fund Manager                                                     Samir Rachh#   \n",
       "Benchmark                                              Nifty Smallcap 250 TRI   \n",
       "Entry Load                                                                      \n",
       "Exit Load                   1% if\\nredeemed\\nor\\nswitched\\nout\\non\\nor\\nbe...   \n",
       "Investment Plans/ Options                                                       \n",
       "Minimum Application Amount  Fresh/ additional subscriptions/switch-ins wil...   \n",
       "Market Capitalization            Large Cap: 12%\\nMid Cap: 14%\\nSmall Cap: 74%   \n",
       "\n",
       "                                                                            3  \\\n",
       "0                                                                               \n",
       "Scheme Name                                           Nippon India Value Fund   \n",
       "Type of Scheme              An\\nopen\\nended\\nequity\\nscheme\\nfollowing\\na\\...   \n",
       "Allotment Date                                                  June 08, 2005   \n",
       "Investment Objective        The primary investment objective of\\nthis sche...   \n",
       "Fund Manager                                 Dhrumil Shah,\\nMeenakshi Dawar #   \n",
       "Benchmark                                                       Nifty 500 TRI   \n",
       "Entry Load                                                                      \n",
       "Exit Load                   10% of\\nthe units allotted shall be redeemed w...   \n",
       "Investment Plans/ Options                                                       \n",
       "Minimum Application Amount  Purchase: ₹500 & in multiples of ₹1 thereafter...   \n",
       "Market Capitalization            Large Cap: 60%\\nMid Cap: 17%\\nSmall Cap: 23%   \n",
       "\n",
       "                                                                            4  \n",
       "0                                                                              \n",
       "Scheme Name                                       Nippon India Multi Cap Fund  \n",
       "Type of Scheme              Multi Cap\\nFund\\n- An\\nopen\\nended\\nequity\\nsc...  \n",
       "Allotment Date                                                 March 28, 2005  \n",
       "Investment Objective        The primary investment objective of\\nthe schem...  \n",
       "Fund Manager                Sailesh Raj Bhan\\nAshutosh Bhargava (Co-Fund M...  \n",
       "Benchmark                                     NIFTY 500 Multicap 50:25:25 TRI  \n",
       "Entry Load                                                                     \n",
       "Exit Load                                                                      \n",
       "Investment Plans/ Options                                                      \n",
       "Minimum Application Amount  Purchase: ₹100 & in multiples of ₹1 thereafter...  \n",
       "Market Capitalization            Large Cap: 42%\\nMid Cap: 26%\\nSmall Cap: 32%  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes =[\"Scheme Name\"] + tables[1].df.iloc[:,0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scheme Name',\n",
       " 'Type of Scheme',\n",
       " 'Allotment Date',\n",
       " 'Investment Objective',\n",
       " 'Fund Manager',\n",
       " 'Benchmark',\n",
       " 'Entry Load',\n",
       " 'Exit Load',\n",
       " 'Investment Plans/ Options',\n",
       " 'Minimum Application Amount',\n",
       " 'Market Capitalization']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

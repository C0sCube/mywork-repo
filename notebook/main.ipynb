{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import fitz\n",
    "import camelot\n",
    "import warnings , math, collections , os, re\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r\"C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\"\n",
    "path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\"\n",
    "\n",
    "#file data paths\n",
    "samco_path = r\"\\files\\SamcoFactSheet2024.pdf\"\n",
    "tata_path = r\"\\files\\TataFactSheet2024.pdf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT CLEANING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imp Funct\n",
    "\n",
    "removeContent =[\n",
    "    'Mutual fund investments are subject to market risks, read all scheme related documents carefully.',\n",
    "    '(An open-ended scheme investing across large cap, midcap and small cap stocks)',\n",
    "    \"(An open-ended Equity Linked Saving Scheme with a statutory lock-in of 3 years and tax benefit.)\",\n",
    "    \"(An open-ended dynamic equity scheme investing across large cap, mid cap, small cap stocks)\",\n",
    "    \"(An open-ended equity scheme following momentum theme)\",\n",
    "    \"(An open-ended equity scheme following special situations theme)\",\n",
    "    \".\",\n",
    "    \"st\",\n",
    "    \"Note:\",\n",
    "    \"Disclaimer\",\n",
    "    \"93.72\",\n",
    "    \"risk-o-meter\",\n",
    "    \"scheme risk-o-meter\",\n",
    "    \"*Investors should consult their financial advisers if in doubt about whether the product is suitable for them.\",\n",
    "    \"94.87\",\n",
    "    \"(An open-ended dynamic asset allocation fund)\",\n",
    "    \"97.11\",\n",
    "    \":\"\n",
    "]\n",
    "\n",
    "document = fitz.open(path +samco_path)\n",
    "total_pages = document.page_count\n",
    "document.close()\n",
    "for i in range(1,total_pages+1):\n",
    "    removeContent.append(str(i))\n",
    "\n",
    "\n",
    "removeContent = [content.lower() for content in removeContent]\n",
    "\n",
    "pagesToIgnore = []\n",
    "\n",
    "textDirection = [(1.0,0), (-1.0,0),(0,1.0),(0,-1.0)]\n",
    "\n",
    "#regarding colors\n",
    "\n",
    "def extract_rgb(color_int):\n",
    "    red = (color_int >> 16) & 0xFF\n",
    "    green = (color_int >> 8) & 0xFF\n",
    "    blue = color_int & 0xFF\n",
    "    return (int(red), int(green), int(blue))\n",
    "    \n",
    "def adjust_color_if_white(rgb):\n",
    "    # Define threshold for white detection\n",
    "    white_threshold = 230\n",
    "    if all(component >= white_threshold for component in rgb):\n",
    "        return (255, 165, 0)  # RGB for Orange\n",
    "    return rgb\n",
    "\n",
    "def is_white_or_shade(color):\n",
    "    \"\"\" Determine if the color is white or a shade close to white \"\"\"\n",
    "    threshold = 240  # Define how close to white the color must be\n",
    "    return all(c >= threshold for c in color)\n",
    "\n",
    "#regarding tables\n",
    "\n",
    "def adjust_bbox(bbox, direction, pixels):\n",
    "    \"\"\"\n",
    "    Adjusts the boundary of a bounding box in the specified direction by a given number of pixels.\n",
    "\n",
    "    Args:\n",
    "        bbox (tuple): The original bounding box (x0, y0, x1, y1).\n",
    "        direction (str): Direction to adjust ('top', 'bottom', 'left', 'right').\n",
    "        pixels (int): The number of pixels to adjust by. Use positive values to expand and negative to contract.\n",
    "\n",
    "    Returns:\n",
    "        fitz.Rect: A new fitz.Rect object with the adjusted bounding box.\n",
    "    \"\"\"\n",
    "    x0, y0, x1, y1 = bbox\n",
    "\n",
    "    if direction == 'top':\n",
    "        y0 -= pixels\n",
    "    elif direction == 'bottom':\n",
    "        y1 += pixels\n",
    "    elif direction == 'left':\n",
    "        x0 -= pixels\n",
    "    elif direction == 'right':\n",
    "        x1 += pixels\n",
    "    else:\n",
    "        raise ValueError(\"Invalid direction. Choose from 'top', 'bottom', 'left', 'right'.\")\n",
    "\n",
    "    adjusted_rect = fitz.Rect(x0, y0, x1, y1)\n",
    "    return adjusted_rect\n",
    "\n",
    "\n",
    "def is_table_large_enough(table_bbox, min_width, min_height):\n",
    "    x0, y0, x1, y1 = table_bbox\n",
    "    return (x1 - x0) > min_width and (y1 - y0) > min_height\n",
    "\n",
    "#other texts\n",
    "\n",
    "def create_new_file(file_name):\n",
    "    full_file_name = os.path.join(path,file_name)\n",
    "    \n",
    "    os.makedirs(os.path.dirname(full_file_name), exist_ok=True)\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(full_file_name):\n",
    "        return full_file_name\n",
    "\n",
    "    with open(full_file_name, 'w') as file:\n",
    "        file.write(\"\")  # Create an empty file\n",
    "    \n",
    "    return full_file_name\n",
    "\n",
    "def check_if_redundant_text(text, removeContent):\n",
    "    \n",
    "    for remove in removeContent:\n",
    "        if text == remove:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def normalize_rgb_color(color):\n",
    "    if isinstance(color, int):\n",
    "        color = (\n",
    "            (color >> 16) & 255,  # Red\n",
    "            (color >> 8) & 255,   # Green\n",
    "            color & 255           # Blue\n",
    "        )\n",
    "\n",
    "    normalized_color = tuple(c / 255 for c in color)\n",
    "\n",
    "    if all(channel > 0.9 for channel in normalized_color): #Check if white\n",
    "        return (1.0, 0.647, 0.0)  # Orange\n",
    "\n",
    "    return normalized_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF DATA SEGREGATION AND EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Open the PDF and extract all blocks of text, images, and other content, while collecting examples of text for each font size and color.\n",
    "Args:input_pdf_path (str): Path to the input PDF.\n",
    "pagesToIgnore (list): List of page numbers to ignore.\n",
    "Returns:list: A list of pages, where each page is a dictionary containing blocks of content and examples of text for each color and size.\"\"\"\n",
    "def extract_pdf_blocks(input_pdf_path, pagesToIgnore):\n",
    "    document_blocks_data = []\n",
    "    page_blocks_data = []\n",
    "    input_doc = fitz.open(input_pdf_path)\n",
    "\n",
    "    with pdfplumber.open(input_pdf_path) as pdf:\n",
    "        for page_number, pdf_page in enumerate(pdf.pages):\n",
    "            if page_number not in pagesToIgnore:\n",
    "                doc_page = input_doc[page_number]\n",
    "                blocks = doc_page.get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "                #get blocks for grand block list\n",
    "                for block in blocks:\n",
    "                    document_blocks_data.append(block)\n",
    "\n",
    "                 # New list for filtered table bboxes\n",
    "                filtered_table_bboxes = []\n",
    "\n",
    "                for table_bbox in [table.bbox for table in pdf_page.find_tables()]:\n",
    "                    if is_table_large_enough(table_bbox, 70, 50):  #width,height\n",
    "                        adjusted_bbox = adjust_bbox(table_bbox, 'bottom', -6) \n",
    "                        filtered_table_bboxes.append(adjusted_bbox)\n",
    "\n",
    "                page_blocks_data.append({\n",
    "                    \"blocks\": blocks,\n",
    "                    \"table_bboxes\": filtered_table_bboxes,\n",
    "                    \"page_rect\": doc_page.rect\n",
    "                })\n",
    "\n",
    "        final_document_blocks_data = {\n",
    "            \"blocks_data\": page_blocks_data,\n",
    "            \"total_pages\": input_doc.page_count\n",
    "        }\n",
    "    input_doc.close()\n",
    "    return final_document_blocks_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Removes image blocks from the provided blocks data and creates a PDF without these blocks.\n",
    "Args:blocks_data (list): List of dictionaries containing page data including text and image blocks.\n",
    "output_pdf_path (str): Path to save the output PDF.\n",
    "Returns:tuple: A tuple containing two lists - updated block data without image blocks and data of removed image blocks.\"\"\"\n",
    "def seperate_text_image_blocks(document_blocks_data):\n",
    "    page_blocks_data = []\n",
    "    image_blocks_data = []\n",
    "\n",
    "    for page_data in document_blocks_data['blocks_data']:\n",
    "        page_rect = page_data[\"page_rect\"]\n",
    "        blocks = page_data[\"blocks\"]\n",
    "        \n",
    "        non_image_blocks_data = []\n",
    "        page_image_data = []\n",
    "\n",
    "        for block in blocks:\n",
    "            if \"image\" in block.keys():  # Directly checking for image keys\n",
    "                page_image_data.append(block)\n",
    "            else:\n",
    "                non_image_blocks_data.append(block)\n",
    "            \n",
    "\n",
    "        # After processing the page, extract text blocks from the newly created output page\n",
    "        page_blocks_data.append({\n",
    "            \"blocks\": non_image_blocks_data,\n",
    "            \"page_rect\": page_rect,\n",
    "            \"table_bboxes\": page_data['table_bboxes']\n",
    "        })\n",
    "\n",
    "        # Collect data for removed image blocks\n",
    "        image_blocks_data.append(page_image_data)\n",
    "\n",
    "    final_document_blocks_data = {\n",
    "        \"blocks_data\": page_blocks_data,\n",
    "        \"total_pages\": document_blocks_data['total_pages']\n",
    "    }\n",
    "\n",
    "    return final_document_blocks_data, image_blocks_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Separates text and tabular data based on bounding boxes (bboxes).\n",
    "Args:document_blocks_data (dict): Dictionary containing block data for each page.\n",
    "Returns:tuple: A tuple containing two lists:\n",
    "- updated block data with non-tabular (text) blocks\n",
    "- updated block data with tabular block\"\"\"\n",
    "def separate_text_and_tabular_blocks(document_blocks_data):\n",
    "    document_tabular_blocks = []\n",
    "    document_textual_blocks = []\n",
    "\n",
    "    tabular_blocks_data = []\n",
    "    textual_blocks_data = []\n",
    "\n",
    "    for page_data in document_blocks_data['blocks_data']:\n",
    "        blocks = page_data['blocks']\n",
    "        table_bboxes = page_data['table_bboxes']\n",
    "\n",
    "        page_tabular_blocks = []\n",
    "        page_textual_blocks = []\n",
    "\n",
    "        for block in blocks:\n",
    "            is_tabular_block = False\n",
    "\n",
    "            if 'lines' in block:\n",
    "                for line in block['lines']:\n",
    "                    for span in line['spans']:\n",
    "                        bbox = span.get('bbox', [0, 0, 0, 0])\n",
    "\n",
    "                        inside_table = any(\n",
    "                            bbox[0] >= table_bbox[0]\n",
    "                            and bbox[1] >= table_bbox[1]\n",
    "                            and bbox[2] <= table_bbox[2]\n",
    "                            and bbox[3] <= table_bbox[3]\n",
    "                            for table_bbox in table_bboxes\n",
    "                        )\n",
    "\n",
    "                        if inside_table:\n",
    "                            is_tabular_block = True\n",
    "                            break\n",
    "\n",
    "                    if is_tabular_block:\n",
    "                        break\n",
    "\n",
    "            if is_tabular_block:\n",
    "                page_tabular_blocks.append(block)\n",
    "                document_tabular_blocks.append(block)\n",
    "            else:\n",
    "                page_textual_blocks.append(block)\n",
    "                document_textual_blocks.append(block)\n",
    "\n",
    "        tabular_blocks_data.append({\n",
    "            \"blocks\": page_tabular_blocks,\n",
    "            \"page_rect\": page_data['page_rect'],\n",
    "            \"table_bboxes\": table_bboxes\n",
    "        })\n",
    "\n",
    "        textual_blocks_data.append({\n",
    "            \"blocks\": page_textual_blocks,\n",
    "            \"page_rect\": page_data['page_rect'],\n",
    "            \"table_bboxes\": table_bboxes\n",
    "        })\n",
    "\n",
    "    final_textual_blocks_data = {\n",
    "        \"blocks_data\": textual_blocks_data\n",
    "    }\n",
    "\n",
    "    final_tabular_blocks_data = {\n",
    "        \"blocks_data\": tabular_blocks_data\n",
    "    }\n",
    "\n",
    "    return final_textual_blocks_data, final_tabular_blocks_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Value of function\n",
    "#     grand_dict = {\n",
    "#     \"block_data\": [\n",
    "#         \"blocks_data\": [],\n",
    "#         \"page_rect\": ()\n",
    "#     ]\n",
    "#     \"total_pages\":[]\n",
    "# \n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creates a pdf for the data\n",
    "Args:document_data (dict): data to make pdf of.\n",
    "output_path (str): Path to save the modified PDF.\n",
    "\"\"\"\n",
    "def create_pdf_file(document_data, output_pdf_path):\n",
    "    output_doc = fitz.open()\n",
    "    \n",
    "    for page_data in document_data['blocks_data']:\n",
    "        page_rect = page_data['page_rect']\n",
    "        blocks = page_data['blocks']\n",
    "        table_bbox = page_data['table_bboxes']\n",
    "        \n",
    "        output_page = output_doc.new_page(width=page_rect.width, height=page_rect.height)\n",
    "        \n",
    "        for block in blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block['lines']:\n",
    "                    for span in line['spans']:\n",
    "                        bbox = span.get(\"bbox\", [0, 0, 0, 0])\n",
    "                        text = span[\"text\"]\n",
    "                        size = round(float(span.get(\"size\", 12)))  # Ensure font size is rounded\n",
    "                        color = span.get(\"color\", (0, 0, 0))  # Default color (black)\n",
    "                        font = span.get(\"font\", \"Helvetica\") # Default font\n",
    "            \n",
    "                        #process size and color \n",
    "                        color = normalize_rgb_color(color)\n",
    "                        \n",
    "                        map_fonts = {'Heebo-Medium': 'Helvetica',\n",
    "                                    'Inter-Black': 'Helvetica',\n",
    "                                    'Inter-Bold': 'Times-Bold',\n",
    "                                    'Inter-ExtraBold': 'Times-Bold',\n",
    "                                    'Inter-ExtraLight': 'Times-Roman',\n",
    "                                    'Inter-Light': 'Times-Roman',\n",
    "                                    'Inter-Medium': 'Times-Roman',\n",
    "                                    'Inter-Regular': 'Times-Roman',\n",
    "                                    'Inter-SemiBold': 'Times-Bold',\n",
    "                                    'Kailasa': 'Helvetica',\n",
    "                                    'MyriadPro-Regular': 'Helvetica',\n",
    "                                    'Helvetica': 'Helvetica'\n",
    "                                    }\n",
    "                        fontname = map_fonts[font]\n",
    "                                                            \n",
    "                        try:\n",
    "                            output_page.insert_text(\n",
    "                                (bbox[0], bbox[1]),\n",
    "                                text,\n",
    "                                fontsize=size,\n",
    "                                fontname=fontname,\n",
    "                                color=color,\n",
    "                            )\n",
    "                        except Exception:\n",
    "                            output_page.insert_text(\n",
    "                                (bbox[0], bbox[1]),\n",
    "                                text,\n",
    "                                fontsize=size,\n",
    "                                fontname=\"helv\",\n",
    "                                color=color,\n",
    "                            )\n",
    "\n",
    "        \n",
    "         # Drawing the table bounding boxes\n",
    "        for table_bbox in table_bbox:\n",
    "            rect = fitz.Rect(table_bbox)\n",
    "            output_page.draw_rect(rect, color=(.8, 0, 0), width=0.5)\n",
    "            \n",
    "        \n",
    "            \n",
    "    output_doc.save(output_pdf_path)\n",
    "    output_doc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRY RUN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dry run paths\n",
    "dry_run_path = r\"\\output\\DryRun.pdf\"\n",
    "\n",
    "#samco output path\n",
    "no_image_path = path + r\"\\output\\NoImgPdf.pdf\"\n",
    "textual_pdf_path = path + r\"\\output\\TextualPdf.pdf\"\n",
    "tabular_pdf_path = path + r\"\\output\\TabularPdf.pdf\"\n",
    "\n",
    "#tata output path\n",
    "# no_image_path = path +r\"\\output\\TatanoImgPdf.pdf\"\n",
    "# textual_pdf_path = path + r\"\\output\\TatatextalPdf.pdf\"\n",
    "# tabular_pdf_path = path + r\"\\output\\TatatabularPdf.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_data = extract_pdf_blocks(path + samco_path, pagesToIgnore)\n",
    "non_image_data, image_data = seperate_text_image_blocks(blocks_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Success !!\n"
     ]
    }
   ],
   "source": [
    "textual_data,tabular_data = separate_text_and_tabular_blocks(non_image_data)\n",
    "create_pdf_file(non_image_data,no_image_path)\n",
    "create_pdf_file(textual_data, textual_pdf_path)\n",
    "create_pdf_file(tabular_data, tabular_pdf_path)\n",
    "print(\"\\n Success !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle data paths\n",
    "pickle_path_text = r\"\\output\\pkl\\textual_data.pkl\"\n",
    "pickle_path_tab = r\"\\output\\pkl\\tabular_data.pkl\"\n",
    "pickle_path_nonimg = r\"\\output\\pkl\\nonimg_data.pkl\"\n",
    "pickle_path_indices = r\"\\output\\pkl\\indices_var.pkl\"\n",
    "\n",
    "with open(path + pickle_path_text , 'wb') as file:\n",
    "    pickle.dump(textual_data, file)\n",
    "    \n",
    "with open(path + pickle_path_tab , 'wb') as file:\n",
    "    pickle.dump(tabular_data, file)\n",
    "    \n",
    "with open(path + pickle_path_nonimg , 'wb') as file:\n",
    "    pickle.dump(non_image_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Open the pdf , get all text data and blocks and draw a boundary along each boundary boxes\n",
    "    Args:input_pdf_path(str) , output_pdf_path (str)\n",
    "    Returns: nothing, a new pdf created\"\"\"\n",
    "    \n",
    "def draw_table_boundaries(input_pdf_path, output_pdf_path):\n",
    "    with pdfplumber.open(input_pdf_path) as pdf:\n",
    "        doc = fitz.open(input_pdf_path)\n",
    "        for page_number, page in enumerate(pdf.pages):\n",
    "            fitz_page = doc[page_number]\n",
    "            tables = page.find_tables()\n",
    "            for table in tables:\n",
    "                bbox = table.bbox\n",
    "                rect = fitz.Rect(bbox[0], bbox[1], bbox[2], bbox[3])\n",
    "                fitz_page.draw_rect(rect, color=(0, 0, 1), width=1.5, overlay=False)\n",
    "        doc.save(output_pdf_path)\n",
    "        doc.close()\n",
    "\n",
    "draw_table_boundaries(no_image_path, path + dry_run_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIGHLIGHT CORE INDEXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get the indices to be checked from the dumped file, create a grand list to check the content\"\"\"\n",
    "with open(path + pickle_path_indices , 'rb') as file:\n",
    "    indices = pickle.load(file)  \n",
    "final_indices = []\n",
    "for k,v in indices.items():\n",
    "   temp = [k] + v\n",
    "   for t in temp:\n",
    "      final_indices.append(t)\n",
    "      \n",
    "final_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_highlights_to_data(indices_variations, data):\n",
    "    for page_data in data['blocks_data']:\n",
    "        for block in page_data['blocks']:\n",
    "            if \"lines\" in block: #check if page has lines\n",
    "                for line in block['lines']:\n",
    "                        for span in line['spans']:\n",
    "                            if span['flags'] in [20,25]: #indicate bold value\n",
    "                                span_text = span['text'].lower()\n",
    "                                for term in indices_variations:\n",
    "                                    pattern = r'\\b' + re.escape(term.lower()) + r'\\b'\n",
    "                                    if re.search(pattern, span_text):\n",
    "                                        # Add a highlighted key to indicate this span should be highlighted\n",
    "                                        span['highlighted'] = True\n",
    "    return data\n",
    "def check_indices_and_highlight(indices_variations, path):\n",
    "    doc = fitz.open(path)\n",
    "    \n",
    "    important_pages = set()\n",
    "\n",
    "    for page_number, page in enumerate(doc):\n",
    "        text_instances = page.get_text('dict')[\"blocks\"]\n",
    "\n",
    "        for block in text_instances:\n",
    "            if \"lines\" in block: \n",
    "                for line in block[\"lines\"]: \n",
    "                    for span in line[\"spans\"]:\n",
    "                        # Check text attributes\n",
    "                        if span['flags'] in [20,25]:  # Example for bold or large text\n",
    "                            span_text = span['text'].lower()\n",
    "                            for term in indices_variations:\n",
    "                                pattern = r'\\b' + re.escape(term.lower()) + r'\\b'\n",
    "                                if re.search(pattern, span_text):\n",
    "                                    important_pages.add(page_number + 1)\n",
    "                                    # Highlight found terms\n",
    "                                    rect = fitz.Rect(span['bbox']) \n",
    "                                    page.add_highlight_annot(rect)\n",
    "                                    break  # Optional: break if only one highlight per span is needed\n",
    "\n",
    "    if important_pages:\n",
    "        output_path = path.replace('.pdf', '_highlighted.pdf')\n",
    "        doc.save(output_path)\n",
    "        doc.close()\n",
    "        return list(important_pages), output_path\n",
    "    else:\n",
    "        doc.close()\n",
    "        return list(important_pages), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_indices_and_highlight(final_indices, textual_pdf_path)\n",
    "textual_data_high = add_highlights_to_data(final_indices,textual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Open the pdf , get all text data and blocks and draw a boundary along each boundary boxes\n",
    "    Args:input_pdf_path(str) , output_pdf_path (str)\n",
    "    Returns: nothing, a new pdf created\n",
    "\"\"\"\n",
    "def draw_boundaries_on_pdf(input_pdf_path, path):\n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(input_pdf_path)\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"blocks\")  # Get the blocks of text on the page\n",
    "        for block in blocks:\n",
    "            bbox = block[:4]  # The bbox is the first four elements of the block\n",
    "            # Draw a rectangle with an orange border around the bbox\n",
    "            page.draw_rect(bbox, color=(1.0, 0.647, 0.0), width=1.5, overlay=False)\n",
    "    \n",
    "    # Save the modified document to a new file\n",
    "    \n",
    "    output_path = path.replace('.pdf', '_block_highlighted.pdf')\n",
    "    doc.save(output_path)\n",
    "    doc.close()\n",
    "\n",
    "file_path = path + r\"\\output\\TextualPdf_highlighted.pdf\"\n",
    "draw_boundaries_on_pdf(file_path, path + dry_run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Open the pdf , get all text data and blocks and draw a boundary along each boundary boxes\n",
    "    Args:input_pdf_path(str) , output_pdf_path (str)\n",
    "    Returns: nothing, a new pdf created\n",
    "\"\"\"\n",
    "def draw_boundaries_on_lines(input_pdf_path, path):\n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(input_pdf_path)\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    \n",
    "                    bbox = line[\"bbox\"]  # The bbox is now directly accessible from the line\n",
    "                    page.draw_rect(bbox, color=(.4, 0.647, 0.0), width=1.5, overlay=False)\n",
    "    \n",
    "    \n",
    "    output_path = path.replace('.pdf', '_line_highlighted.pdf')\n",
    "    doc.save(output_path)\n",
    "    doc.close()\n",
    "    \n",
    "file_path = path + r\"\\output\\TextualPdf_highlighted.pdf\"\n",
    "draw_boundaries_on_lines(file_path, path + dry_run_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GETTING WHAT YOU WANTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_keys(data, keys_to_remove):\n",
    "    \"\"\"Recursively remove specified keys from dictionaries and lists.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        # Create a new dictionary that does not include the unwanted keys\n",
    "        return {k: remove_unwanted_keys(v, keys_to_remove) for k, v in data.items() if k not in keys_to_remove}\n",
    "    elif isinstance(data, list):\n",
    "        # Apply the function to each element in the list\n",
    "        return [remove_unwanted_keys(item, keys_to_remove) for item in data]\n",
    "\n",
    "    return data\n",
    "\n",
    "remove_keys = ['bbox','dir','ascender', 'descender','wmode', 'number','type','origin','color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textual_data_high['blocks_data'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData = remove_unwanted_keys(textual_data_high, remove_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData['blocks_data'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'spans': [{'size': 72.0, 'flags': 20, 'font': 'Inter-Bold', 'text': 'Factsheet'}]}]\n",
      "Fund Manager: \n",
      "Minimum Additional Amount\n",
      "Benchmark:\n",
      "Modified Duration: \n",
      "Average Maturity: \n",
      "Yield to Maturity (YTM): \n",
      "Standard Deviation: \n",
      "Macaulay duration\n",
      "Sharpe Ratio: \n",
      "Beta Ratio (Portfolio Beta): \n",
      "Portfolio Turnover Ratio: \n",
      "Investment Objective\n",
      "Inception Date\n",
      "Benchmark\n",
      "Total Experience: \n",
      "Fund Manager\n",
      "Average AUM for Month of October 2024\n",
      "Total Experience: \n",
      "Total Experience: \n",
      "Portfolio Turnover Ratio: \n",
      "Benchmark Risk-o-meter\n",
      "Investment Objective\n",
      "Inception Date\n",
      "Benchmark\n",
      "Portfolio Turnover Ratio: \n",
      "Fund Manager\n",
      "Average AUM for Month of \n",
      "Total Experience: \n",
      "Total Experience: \n",
      "Total Experience: \n",
      "Benchmark Risk-o-meter\n",
      "Investment Objective\n",
      "Inception Date\n",
      "Benchmark\n",
      "Total Experience: \n",
      "Fund Manager\n",
      "Average AUM for Month of \n",
      "Total Experience: \n",
      "Total Experience: \n",
      "Annualised Portfolio YTM\n",
      "Macaulay Duration\n",
      "Modified Duration\n",
      "Benchmark Risk-o-meter\n",
      "Investment Objective\n",
      "Inception Date\n",
      "Benchmark\n",
      "Portfolio Turnover Ratio: \n",
      "Fund Manager\n",
      "Average AUM for Month of \n",
      "Total Experience: \n",
      "Total Experience: \n",
      "Total Experience: \n",
      "Benchmark Risk-o-meter\n",
      "Investment Objective\n",
      "Inception Date\n",
      "Benchmark\n",
      "Fund Manager\n",
      "Average AUM for Month of \n",
      "Total Experience: \n",
      "Total Experience: \n",
      "Total Experience: \n",
      "Benchmark Risk-o-meter\n",
      "Investment Objective\n",
      "Inception Date\n",
      "Benchmark\n",
      "Total Experience: \n",
      "Fund Manager\n",
      "Average AUM for Month of October 2024 \n",
      "Total Experience: \n",
      "Portfolio Turnover Ratio: \n",
      "Benchmark Risk-o-meter\n",
      "Investment Objective\n",
      "Inception Date\n",
      "Benchmark\n",
      "Fund Manager\n",
      "Average AUM for Month of October 2024\n",
      "Annualised Portfolio YTM\n",
      "Macaulay Duration\n",
      "Total Experience: \n",
      "Modified Duration\n",
      "Total Experience: \n",
      "Benchmark: \n",
      "Additional Benchmark: \n",
      "Benchmark (\n",
      "Benchmark (\n",
      "Benchmark \n",
      "Benchmark\n",
      "Benchmark: \n",
      "Additional Benchmark: \n",
      "Benchmark (\n",
      "Benchmark (\n",
      "Benchmark \n",
      "Benchmark\n",
      "Benchmark: \n",
      "Additional Benchmark: \n",
      "Benchmark (\n",
      "Benchmark (\n",
      "Benchmark \n",
      "Benchmark\n",
      "Benchmark: \n",
      "Additional Benchmark: \n",
      "Benchmark (\n",
      "Benchmark (\n",
      "Benchmark \n",
      "Benchmark\n",
      "Benchmark\n",
      "Additional Benchmark\n",
      "Benchmark: \n",
      "Additional Benchmark: \n",
      "Benchmark\n",
      "Benchmark\n",
      "Benchmark\n",
      "Benchmark\n",
      "Benchmark: \n",
      "Additional Benchmark: \n",
      "Benchmark\n",
      "Benchmark\n",
      "Benchmark\n",
      "Benchmark\n",
      "Benchmark: \n",
      "Additional Benchmark: \n",
      "Benchmark\n",
      "Benchmark\n",
      "Benchmark\n",
      "Benchmark\n",
      "Riskometer of the Scheme and the Primary Benchmark\n",
      "Benchmark Name\n",
      "Primary Benchmark\n",
      "Scheme Name\n"
     ]
    }
   ],
   "source": [
    "for pgn,blocks in enumerate(cleanedData['blocks_data']): #each page\n",
    "    if pgn == 0:\n",
    "       print(blocks['blocks'][0]['lines'])\n",
    "    for block in blocks['blocks']: #each block in blocks\n",
    "        for line in block['lines']:\n",
    "            for span in line['spans']:\n",
    "                    if 'highlighted' in span and span['flags'] in [20,25]:\n",
    "                        print(span['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'spans': [{'size': 72.0, 'flags': 20, 'font': 'Inter-Bold', 'text': 'Factsheet'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '1'}]}]\n",
      "[{'spans': [{'size': 16.0, 'flags': 4, 'font': 'Inter-Black', 'text': 'HEXASHIELD'}]}, {'spans': [{'size': 16.0, 'flags': 4, 'font': 'Inter-Black', 'text': 'TESTED'}]}, {'spans': [{'size': 16.0, 'flags': 4, 'font': 'Inter-Black', 'text': 'INVESTMENTS'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '3'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '4'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '5'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 4, 'font': 'Inter-Light', 'text': '.'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '7'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '8'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '9'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 4, 'font': 'Inter-Light', 'text': '.'}]}]\n",
      "[{'spans': [{'size': 9.0, 'flags': 20, 'font': 'Inter-SemiBold', 'text': 'Investment Objective', 'highlighted': True}]}]\n",
      "[{'spans': [{'size': 8.132010459899902, 'flags': 20, 'font': 'Inter-Bold', 'text': 'Scheme Risk-o-meter'}]}, {'spans': [{'size': 8.132010459899902, 'flags': 20, 'font': 'Inter-Bold', 'text': 'Benchmark Risk-o-meter', 'highlighted': True}]}, {'spans': [{'size': 8.0, 'flags': 4, 'font': 'Inter-Regular', 'text': 'This product is suitable for investors who are seeking * :'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '13'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '14'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '15'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '16'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '17'}]}]\n",
      "[{'spans': [{'size': 14.0, 'flags': 20, 'font': 'Inter-Bold', 'text': 'Samco Overnight Fund'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '19'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '20'}]}]\n",
      "[{'spans': [{'size': 8.0, 'flags': 4, 'font': 'Inter-Medium', 'text': 'Note:'}, {'size': 8.0, 'flags': 4, 'font': 'Inter-Light', 'text': ' The Scheme risk-o-meter and Benchmark risk-o-meter is based on evaluation of the portfolio data as on September 30, 2024. ', 'highlighted': True}]}]\n",
      "[{'spans': [{'size': 17.0, 'flags': 20, 'font': 'Inter-ExtraBold', 'text': '25%'}]}]\n",
      "[{'spans': [{'size': 10.0, 'flags': 20, 'font': 'Inter-Bold', 'text': '14'}]}]\n"
     ]
    }
   ],
   "source": [
    "for blocks in cleanedData['blocks_data']: #each page\n",
    "    print(blocks['blocks'][0]['lines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

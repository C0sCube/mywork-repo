{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pprint, json, math, os, sys\n",
    "import fitz\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "dir_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\"\n",
    "fund_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\Dec 24\"\n",
    "\n",
    "# dir_path = r\"C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\"\n",
    "# fund_path = r'C:\\Users\\rando\\OneDrive\\Documents\\Dec 24'\n",
    "sys.path.append(os.path.abspath(dir_path))\n",
    "\n",
    "from app.fundData import *\n",
    "from app.helper import Helper\n",
    "\n",
    "dry_path = r'\\data\\output\\DryRun.pdf'\n",
    "fin_path = r'\\data\\input\\financial_indices.xlsx'\n",
    "rep_path = r'\\data\\output\\pdf_report.xlsx'\n",
    "\n",
    "json_path = dir_path + r'\\data\\output\\dump.json'\n",
    "pkl_path = dir_path + r'\\data\\output\\sample.pkl'\n",
    "\n",
    "mutual_fund = Helper.get_fund_paths(fund_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samco active momentum fund\n",
      "samco active momentum fund\n",
      "samco dynamic asset allocation fund\n",
      "samco dynamic asset allocation fund\n",
      "samco flexi cap fund\n",
      "samco flexi cap fund\n",
      "samco multi cap fund\n",
      "samco multi cap fund\n",
      "samco special opportunities fund\n",
      "samco special opportunities fund\n",
      "samco elss tax saver fund\n",
      "samco elss tax saver fund\n",
      "samco multi asset allocation fund\n",
      "samco multi asset allocation fund\n",
      "samco overnight fund\n",
      "samco arbitrage fund\n",
      "\n",
      "Doc Saved At: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\pdf_report.xlsx\n",
      "\n",
      "Pages to Extract: [3, 5, 7, 9, 11, 13, 15, 17, 18]\n",
      "\n",
      "-----samco active momentum fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----samco dynamic asset allocation fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----samco flexi cap fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----samco multi cap fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----samco special opportunities fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----samco elss tax saver fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----samco multi asset allocation fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----samco overnight fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----samco arbitrage fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      " JSON saved at C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\dump.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\" SAMCO PDF FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = Samco(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Samco Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages =  [3, 5, 7, 9, 11, 13, 15, 17, 18]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title)\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m Tata(dir_path, dry_path, fin_path, rep_path)\n\u001b[0;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m mutual_fund[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTata Mutual Fund\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m path, df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_and_highlight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m title \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtitle\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m      8\u001b[0m pages \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m17\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m26\u001b[39m, \u001b[38;5;241m27\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m29\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m33\u001b[39m, \u001b[38;5;241m34\u001b[39m, \u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m36\u001b[39m, \u001b[38;5;241m37\u001b[39m, \u001b[38;5;241m38\u001b[39m, \u001b[38;5;241m39\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m41\u001b[39m, \u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m43\u001b[39m, \u001b[38;5;241m44\u001b[39m, \u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m46\u001b[39m, \u001b[38;5;241m47\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m49\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m51\u001b[39m, \u001b[38;5;241m52\u001b[39m, \u001b[38;5;241m53\u001b[39m, \u001b[38;5;241m54\u001b[39m, \u001b[38;5;241m55\u001b[39m, \u001b[38;5;241m56\u001b[39m, \u001b[38;5;241m57\u001b[39m, \u001b[38;5;241m58\u001b[39m, \u001b[38;5;241m59\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m62\u001b[39m, \u001b[38;5;241m63\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m66\u001b[39m, \u001b[38;5;241m67\u001b[39m, \u001b[38;5;241m68\u001b[39m, \u001b[38;5;241m69\u001b[39m, \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m71\u001b[39m, \u001b[38;5;241m72\u001b[39m, \u001b[38;5;241m73\u001b[39m, \u001b[38;5;241m74\u001b[39m, \u001b[38;5;241m75\u001b[39m, \u001b[38;5;241m76\u001b[39m, \u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m78\u001b[39m, \u001b[38;5;241m79\u001b[39m, \u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m81\u001b[39m, \u001b[38;5;241m82\u001b[39m, \u001b[38;5;241m83\u001b[39m]\n",
      "File \u001b[1;32m~\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\app\\pdfParse.py:105\u001b[0m, in \u001b[0;36mReader.check_and_highlight\u001b[1;34m(self, path, count)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indice \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[0;32m    104\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mre\u001b[38;5;241m.\u001b[39mescape(indice)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match\u001b[38;5;241m:=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    106\u001b[0m         df\u001b[38;5;241m.\u001b[39mloc[dpgn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighlights\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    107\u001b[0m         df\u001b[38;5;241m.\u001b[39mloc[dpgn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetect_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(match\u001b[38;5;241m.\u001b[39mgroup())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\__init__.py:174\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Try to apply the pattern to all of the string, returning\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39mfullmatch(string)\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msearch(string)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" TATA FILE MAIN CODE \"\"\"\n",
    "object = Tata(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Tata Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 10)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title)\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" FRANKLIN TEMPLETON FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = FranklinTempleton(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Franklin Templeton Mutual Fund\"]\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 6)\n",
    "title = df.title.to_dict()\n",
    "pages =  [i for i in range(17,50)]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BANDHAN MF FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = Bandhan(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Bandhan Mutual Fund\"]\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path,6)\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"HELIOS MF FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = Helios(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Helios Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path,6)\n",
    "title = df.title.to_dict()\n",
    "pages =  [2, 4, 6, 8, 10]\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages ,'left', title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EDELWEISS MP FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = Edelweiss(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Edelweiss Mutual Fund']\n",
    "\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 6)\n",
    "\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75]\n",
    "\n",
    "title,objectives = object.get_proper_fund_names(file_path,pages)\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages ,'right',title ) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"HSBC MAIN FILE CODE\"\"\" #Issue: Some pages have 2 or more fund data on same page\n",
    "#some data is present on right side as well so define two lines\n",
    "\n",
    "object = HSBC(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['HSBC Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "data_cond = object.PARAMS['data']\n",
    "\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x ,'right', fund_titles) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INVESCO MF MAIN FILE CODE\"\"\" #Issue: two fund on same page\n",
    "\n",
    "object = Invesco(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Invesco Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [i for i in range(4,44)]\n",
    "data = object.get_clipped_data(file_path,pages,bbox, fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ITI MAIN FILE CODE\"\"\" #Issues: NO so far\n",
    "\n",
    "object = ITI(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['ITI Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [i for i in range(9,27)]\n",
    "\n",
    "data = object.get_clipped_data(file_path,pages,bbox,fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"JM FUND MAIN FILE CODE\"\"\" #objective on left, sometimes date is with header\n",
    "\n",
    "object = JMMF(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['JM Financial Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "pages = [22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37]\n",
    "\n",
    "data = object.get_clipped_data(file_path,pages,bbox,fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DSP MAIN FILE CODE\"\"\" #Issue: highlight count must be lower\n",
    "#Issue: data on both side ends so issue coming\n",
    "\n",
    "object = DSP(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['DSP Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [ i for i in range(1,66)]\n",
    "\n",
    "data = object.get_clipped_data(file_path,pages,bbox,fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"KOTAK FUND MAIN CODE\"\"\" #Issue: 1 or more fund on same page, color on headers\n",
    "object = Kotak(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Kotak Mahindra Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 40, 41, 43, 44, 46, 48, 49, 50, 52, 54, 55, 56, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,'left',fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ISSUE: THE FUND NAMES ARE IMAGES \"\"\" LIC MF MAIN CODE\"\"\"\n",
    " #Issue: objective on right of line\n",
    "\n",
    "object = LIC(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Kotak Mahindra Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MAHINDRA MANULIFE MAIN CODE\"\"\" #incrase pages count\n",
    "\n",
    "object = MahindraManu(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Mahindra Manulife Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "\n",
    "fund_titles = object.get_proper_fund_names(file_path,[i for i in range(1,80)])\n",
    "pages = [i for i in range(8,34)]\n",
    "\n",
    "data = object.get_clipped_data(file_path,pages,bbox,fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MOTILAL OSWAL MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = MotilalOswal(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Motilal Oswal Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [i for i in range(4,21)]\n",
    "data = object.get_clipped_data(file_path,pages,bbox,fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NJMF MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = NJMF(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['NJ Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [1, 5, 7, 9]\n",
    "\n",
    "data = object.get_clipped_data(file_path,pages,bbox,fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"QUANT MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = QuantMF(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Quant Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 61, 63, 65]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 61, 63, 65]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SUNDARAM MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = Sundaram(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Sundaram Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TAURUS MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = Taurus(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Taurus Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [13, 14, 15, 16, 17, 19, 20]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRUST MAIN FILE CODE\"\"\" #Issue: Invest Obj in right #Names coming as headers fund managers\n",
    "\n",
    "object = Trust(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Trust Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UTI MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = UTI(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['UTI Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 46, 48, 50, 52, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WHITEOAK MAIN FILE CODE\"\"\" #Issue: Inv Obj in the right\n",
    "object = WhiteOak(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['WhiteOak Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [7, 9, 11, 13, 15, 17, 19, 20, 21, 23, 25, 26, 28, 30, 32, 34, 35]\n",
    "data = object.get_clipped_data(file_path,pages,bbox,fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''' 360 ONE MAIN FILE CODE'''\n",
    "\n",
    "object = ThreeSixtyOne(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['360 ONE Mutual Fund']\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_bbox']\n",
    "data_cond = object.PARAMS['data']\n",
    "\n",
    "# print(fund_data,line_x,bbox,data_cond)\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BAJAJ FINSERV MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = BajajFinServ(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Bajaj finserv Mutual Fund']\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_bbox']\n",
    "data_cond = object.PARAMS['data']\n",
    "\n",
    "# print(fund_data,line_x,bbox,data_cond)\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [15, 17, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33]\n",
    "\n",
    "data_l = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used line here\n",
    "data_r = object.extract_data_relative_line(file_path,pages,line_x,\"right\",fund_titles) #used line here\n",
    "\n",
    "data = object.combine_left_right_data([data_l,data_r])\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond)\n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BARODA BNP MAIN FILE CODE\"\"\" #Issue: Header funds\n",
    "\n",
    "object = BarodaBNP(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Baroda BNP Paribas Mutual Fund']\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_bbox']\n",
    "data_cond = object.PARAMS['data']\n",
    "\n",
    "# print(fund_data,line_x,bbox,data_cond)\n",
    "# path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "# msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
    "\n",
    "fund_titles = object.get_proper_fund_names(file_path, pages,(0,0,210,75))\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,'left', fund_titles) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "navi niy 50 index fund\n",
      "navi us total stock market\n",
      "navi nasdaq 100\n",
      "navi niy next 50\n",
      "navi niy bank\n",
      "navi niy midcap 150\n",
      "navi niy india\n",
      "navi elss tax saver\n",
      "navi bse sensex\n",
      "navi niy it index fund\n",
      "navi niy 500 multicap 50:25:25\n",
      "\n",
      "Doc Saved At: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\pdf_report.xlsx\n",
      "\n",
      "Pages to Extract: [2, 4, 5, 6, 8, 10, 13, 16, 18, 20, 22]\n",
      "\n",
      "-----navi niy 50 index fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----navi niy next 50------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----navi niy bank------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----navi niy midcap 150------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----navi niy india------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----navi elss tax saver------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----navi bse sensex------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----navi niy it index fund------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "-----navi niy 500 multicap 50:25:25------ \n",
      "PDF Generated at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n"
     ]
    }
   ],
   "source": [
    "\"\"\"NAVI MAIN FILE CODE\"\"\" #Issue: Left and right\n",
    "\n",
    "object = NAVI(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Navi Mutual Fund']\n",
    "\n",
    "\n",
    "path,df = object.check_and_highlight(file_path,5)\n",
    "title = df.title.to_dict()\n",
    "pages = [2, 6, 8, 10, 13, 16, 18, 20, 22]\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_r = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "\n",
    "data = object.combine_left_right_data([data_l,data_r])\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data)\n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ZERODHA MAIN CODE\"\"\" #Issue left and right\n",
    "\n",
    "object = Zerodha(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Zerodha Mutual Fund']\n",
    "\n",
    "# path,df= object.check_and_highlight(file_path,7)\n",
    "title = df.title.to_dict()\n",
    "pages = [3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "#left\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_l = object.extract_span_data(data_l,[])\n",
    "clean_data = object.process_text_data(data_l)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "#right\n",
    "data_r = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data_r = object.extract_span_data(data_r,[])\n",
    "clean_data = object.process_text_data(data_r)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "nested_data = {key:{**nested_data_left[key],**nested_data_right[key] }for key in nested_data_left.keys()}\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "navi niy 50 index fund\n",
      "['(Annualised as on December 31, 2024)',\n",
      " 'Tracking Error Tracking Dierence',\n",
      " '0.04% -0.23%']\n",
      "navi niy next 50\n",
      "['(Annualised as on December 31, 2024)',\n",
      " 'Tracking Error Tracking Dierence',\n",
      " '0.43% -0.34%']\n",
      "navi niy bank\n",
      "['(Annualised as on December 31, 2024)',\n",
      " 'Tracking Error Tracking Dierence',\n",
      " '0.07% -0.39%']\n",
      "navi niy midcap 150\n",
      "['(Annualised as on December 31, 2024)',\n",
      " 'Tracking Error Tracking Dierence',\n",
      " '0.24% -0.66%']\n",
      "navi niy india\n",
      "['PAPER, FOREST & JUTE PRODUCTS',\n",
      " '(Annualised as on December 31, 2024)',\n",
      " 'Tracking Error Tracking Dierence',\n",
      " '0.24% -0.61%']\n",
      "navi elss tax saver\n",
      "['(Annualised as on December 31, 2024)',\n",
      " 'Tracking Error Tracking Dierence',\n",
      " '0.O5% -0.39%']\n",
      "navi bse sensex\n",
      "['(Annualised as on December 31, 2024)',\n",
      " 'Tracking Error Tracking Dierence',\n",
      " '0.12% -0.34%']\n",
      "navi niy it index fund\n",
      "['(Annualised as on December 31, 2024)',\n",
      " 'Tracking Error Tracking Dierence',\n",
      " '0.11% -0.97']\n",
      "navi niy 500 multicap 50:25:25\n",
      "['TELECOM - EQUIPMENT & ACCESSORIES',\n",
      " '(Annualised as on December 31, 2024)',\n",
      " 'Tracking Error Tracking Dierence',\n",
      " '0.25% -0.71%']\n"
     ]
    }
   ],
   "source": [
    "for fund, content in final_text.items():\n",
    "    print(fund)\n",
    "    if \"tracking_error\" in content.keys():\n",
    "        pprint.pprint(content['tracking_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " JSON saved at C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\dump.json\n"
     ]
    }
   ],
   "source": [
    "Helper.quick_json_dump(final_text,json_path)       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pprint, json, math, os, sys\n",
    "import fitz\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "dir_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\"\n",
    "fund_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\Dec 24\"\n",
    "\n",
    "# dir_path = r\"C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\"\n",
    "# fund_path = r'C:\\Users\\rando\\OneDrive\\Documents\\Dec 24'\n",
    "sys.path.append(os.path.abspath(dir_path))\n",
    "\n",
    "from app.fundData import *\n",
    "from app.helper import Helper\n",
    "\n",
    "dry_path = r'\\data\\output\\DryRun.pdf'\n",
    "fin_path = r'\\data\\input\\financial_indices.xlsx'\n",
    "rep_path = r'\\data\\output\\pdf_report.xlsx'\n",
    "\n",
    "json_path = dir_path + r'\\data\\output\\dump.json'\n",
    "pkl_path = dir_path + r'\\data\\output\\sample.pkl'\n",
    "\n",
    "mutual_fund = Helper.get_fund_paths(fund_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WHITEOAK MAIN FILE CODE\"\"\" #Issue: Inv Obj in the right #json issue\n",
    "object = WhiteOak(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['WhiteOak Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 6)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 9, 11, 13, 15, 17, 19, 20, 21, 23, 25, 26, 28, 30, 32, 34, 35]\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_dict = Helper.drop_dict(final_text)\n",
    "Helper.quick_json_dump(final_dict, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''' 360 ONE MAIN FILE CODE''' #No issues as of now\n",
    "\n",
    "object = ThreeSixtyOne(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['360 ONE Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_dict = Helper.drop_dict(final_text)\n",
    "Helper.quick_json_dump(final_dict, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MAHINDRA MANULIFE MAIN CODE\"\"\" #incrase pages count\n",
    "\n",
    "object = MahindraManu(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Mahindra Manulife Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = object.get_proper_fund_names(file_path,[i for i in range(1,80)])\n",
    "pages = [i for i in range(8,34)]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"JM FUND MAIN FILE CODE\"\"\" #objective on left, sometimes date is with header\n",
    "\n",
    "object = JMMF(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['JM Financial Mutual Fund']\n",
    "\n",
    "\n",
    "#path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INVESCO MF MAIN FILE CODE\"\"\" #Issue: two fund on same page\n",
    "\n",
    "object = Invesco(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Invesco Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SAMCO PDF FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = Samco(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Samco Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages =  [3, 5, 7, 9, 11, 13, 15, 17, 18]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title)\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TATA FILE MAIN CODE \"\"\"\n",
    "object = Tata(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Tata Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 10)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title)\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = Helper.drop_dict(extracted_text)\n",
    "final_data = object.refine_extracted_data(final_text)\n",
    "Helper.quick_json_dump(final_data, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" FRANKLIN TEMPLETON FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = FranklinTempleton(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Franklin Templeton Mutual Fund\"]\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 6)\n",
    "title = df.title.to_dict()\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "# final_dict = Helper.drop_empty_dict_values()\n",
    "Helper.quick_json_dump(final_text, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BANDHAN MF FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = Bandhan(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Bandhan Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path,6)\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"KOTAK FUND MAIN CODE\"\"\" #Issue: 1 or more fund on same page, # title overlap the content\n",
    "object = Kotak(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Kotak Mahindra Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 40, 41, 43, 44, 46, 48, 49, 50, 52, 54, 55, 56, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
    "data = object.extract_clipped_data(file_path,pages,title)#used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text, ['folio_count_data_as_on_30th_november','idcw_frequency','available_plans/options'])\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ZERODHA MAIN CODE\"\"\" \n",
    "\n",
    "object = Zerodha(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Zerodha Mutual Fund']\n",
    "\n",
    "path,df= object.check_and_highlight(file_path,7)\n",
    "title = df.title.to_dict()\n",
    "pages = [3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "#left\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_l = object.extract_span_data(data_l,[])\n",
    "clean_data = object.process_text_data(data_l)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "#right\n",
    "data_r = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data_r = object.extract_span_data(data_r,[])\n",
    "clean_data = object.process_text_data(data_r)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "nested_data = {key:{**nested_data_left[key],**nested_data_right[key] }for key in nested_data_left.keys()}\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NAVI MAIN FILE CODE\"\"\" #Issue: Left and right\n",
    "\n",
    "object = NAVI(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Navi Mutual Fund']\n",
    "\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path,5)\n",
    "title = df.title.to_dict()\n",
    "pages = [2, 6, 8, 10, 13, 16, 18, 20, 22]\n",
    "\n",
    "#left\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_l = object.extract_span_data(data_l,[])\n",
    "clean_data = object.process_text_data(data_l)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 9.0)\n",
    "\n",
    "#right\n",
    "data_r = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data_r = object.extract_span_data(data_r,[])\n",
    "clean_data = object.process_text_data(data_r)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 9.0)\n",
    "\n",
    "nested_data = {key:{**nested_data_left[key],**nested_data_right[key] }for key in nested_data_left.keys()}\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BARODA BNP MAIN FILE CODE\"\"\" #Issue: Header funds #scheme details\n",
    "\n",
    "object = BarodaBNP(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Baroda BNP Paribas Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
    "title = object.get_proper_fund_names(file_path, pages, (0,0,210,75))\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\", title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_dict = Helper.drop_dict(final_text)\n",
    "Helper.quick_json_dump(final_dict, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MOTILAL OSWAL MAIN CODE FILE\"\"\" #Fund Manager Regex\n",
    "\n",
    "object = MotilalOswal(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Motilal Oswal Mutual Fund']\n",
    "\n",
    "# path,df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [i for i in range(4,21)]\n",
    "title = df.title.to_dict()\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"HELIOS MF FILE MAIN CODE\"\"\" #fund manager \n",
    "\n",
    "object = Helios(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Helios Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path,6)\n",
    "title = df.title.to_dict()\n",
    "pages =  [2, 4, 6, 8, 10]\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages ,'left', title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EDELWEISS MP FILE MAIN CODE\"\"\" #Issues: objective in seperate dict, scheme launch date issue\n",
    "\n",
    "object = Edelweiss(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Edelweiss Mutual Fund']\n",
    "\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 6)\n",
    "\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75]\n",
    "\n",
    "title,objectives = object.get_proper_fund_names(file_path,pages)\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages ,'right',title ) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILES TO BE CLEANED ARE BELOW , DATA ABLE TO EXTRACTED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"HSBC MAIN FILE CODE\"\"\" #Issue: Some pages have 2 or more fund data on same page\n",
    "#some data is present on right side as well so define two lines\n",
    "#objective is to be exracted seperately\n",
    "\n",
    "object = HSBC(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['HSBC Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
    "data = object.extract_clipped_data(file_path, pages, title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ITI MAIN FILE CODE\"\"\" #Issues: NO so far\n",
    "\n",
    "object = ITI(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['ITI Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DSP MAIN FILE CODE\"\"\" #Issue: highlight count must be lower\n",
    "#Issue: data on both side ends so issue coming\n",
    "\n",
    "object = DSP(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['DSP Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 5)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ISSUE: THE FUND NAMES ARE IMAGES \"\"\" LIC MF MAIN CODE\"\"\"\n",
    " #Issue: objective on right of line\n",
    "\n",
    "object = LIC(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund[]\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NJMF MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = NJMF(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['NJ Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "pages = [1, 5, 7, 9]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " JSON saved at C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\dump_nj_17_59.json\n"
     ]
    }
   ],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nj flexi cap fund\n",
      "[]\n",
      "[('Portfolio Turnover Ratio', '1.11')]\n",
      "[('Beta', ','), ('Standard Deviation', ',')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "nj balanced advantage fund\n",
      "[('Standard deviation', '9.03')]\n",
      "[('Beta', '1.23')]\n",
      "[('Sharpe Ratio', '0.40')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "nj arbitrage fund\n",
      "[]\n",
      "[('Average Maturity', '73')]\n",
      "[('Modified Duration', '71')]\n",
      "[('Yield to Maturity', '6.53')]\n",
      "[('Macaulay Duration', '73')]\n",
      "[('Portfolio Turnover Ratio', '9.82')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[('Beta', ','), ('Standard Deviation', ',')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "nj overnight fund\n",
      "[]\n",
      "[('Average Maturity', '1')]\n",
      "[('Modified Duration', '1')]\n",
      "[('Yield to Maturity', '6.67')]\n",
      "[('Macaulay Duration', '1')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "pattern = r'(Portfolio Turnover Ratio|Standard Deviation|Beta|Sharpe Ratio|Average Maturity|Modified Duration|Yield to Maturity|Macaulay Duration)\\s*([\\d\\.,]+)'\n",
    "for fund, content in final_text.items():\n",
    "    print(fund)\n",
    "    if \"metrics\" in content:\n",
    "        for text in content['metrics']:\n",
    "            text = re.sub(r\"[\\^#*\\$:]\", \"\", text.strip())\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(as on December 31, 2024)\n",
      "Portfolio Turnover Ratio 1.11\n",
      "Note: Portfolio Beta, Standard Deviation, R Squared and Sharpe Ratio of\n",
      "the Scheme are not computed owing to the short time frame since launch\n",
      "of the Scheme.\n",
      "IDCW history is not available since no income is distributed since the\n",
      "launch of the scheme.\n",
      "# # Total Expense Ratio is as on the last business day of the month and\n",
      "incudes Additional Expenses and Goods & Service Tax on Management\n",
      "Fees.\n",
      "DISCLAIMER: MUTUAL FUND INVESTMENTS ARE SUBJE\n",
      "Standard deviation 9.03\n",
      "Beta 1.23\n",
      "Sharpe Ratio** 0.40\n",
      "Computed for the 3 years period ended December 31,2024.\n",
      "Based on the month end NAV.\n",
      "DISCLAIMER: MUTUAL FUND INVESTMENTS ARE SUBJE\n",
      "(as on December 31, 2024)\n",
      "Average Maturity* 73 Days\n",
      "Modified Duration* 71 Days\n",
      "Yield to Maturity 6.53%\n",
      "Macaulay Duration* 73 Days\n",
      "Portfolio Turnover Ratio 9.82\n",
      "#Total Expense Ratio is as on the last business day of the month and\n",
      "includes Additional Expenses and Goods & Service Tax on\n",
      "Management Fees.\n",
      "*Calculated on amount invested in debt securities (including accrued\n",
      "interest), deployment of funds in TREPS.\n",
      "Portfolio Beta, Standard Deviation, R-Squared and Sharpe Ratio\n",
      "of the Scheme are not computed owing to the short time frame since\n",
      "launch of the Scheme.\n",
      "DISCLAIMER: MUTUAL FUND INVESTMENTS ARE SUBJE\n",
      "(as on December 31, 2024)\n",
      "Average Maturity* 1 Day\n",
      "Modified Duration* 1 Day\n",
      "Yield to Maturity 6.67%\n",
      "Macaulay Duration* 1 Day\n",
      "#Total Expense Ratio is as on the last business day of the month and includes\n",
      "Additional Expenses and Goods & Service Tax on Management Fees.\n",
      "*Calculated on amount invested in debt securities (including accrued interest),\n",
      "deployment of funds in TREPS.\n",
      "DISCLAIMER: MUTUAL FUND INVESTMENTS ARE SUBJE\n"
     ]
    }
   ],
   "source": [
    "for fund, content in final_text.items():\n",
    "    if \"metrics\" in content:\n",
    "        for text in content['metrics']:\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"QUANT MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = QuantMF(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Quant Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 61, 63, 65]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SUNDARAM MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = Sundaram(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Sundaram Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TAURUS MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = Taurus(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Taurus Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [13, 14, 15, 16, 17, 19, 20]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRUST MAIN FILE CODE\"\"\" #Issue: Invest Obj in right #Names coming as headers fund managers\n",
    "\n",
    "object = Trust(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Trust Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UTI MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = UTI(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['UTI Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 46, 48, 50, 52, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " JSON saved at C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\dump_uti_17_58.json\n"
     ]
    }
   ],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "# final_dict = Helper.drop_dict(final_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BAJAJ FINSERV MAIN FILE CODE\"\"\" #major issue of lines #minor of dropping keys of final dict\n",
    "\n",
    "object = BajajFinServ(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Bajaj finserv Mutual Fund']\n",
    "\n",
    "#path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [15, 17, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "#left\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_l = object.extract_span_data(data_l,[])\n",
    "clean_data = object.process_text_data(data_l)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "#right\n",
    "data_r = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data_r = object.extract_span_data(data_r,[])\n",
    "clean_data = object.process_text_data(data_r)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "nested_data = {key:{**nested_data_left[key],**nested_data_right[key] }for key in nested_data_left.keys()}\n",
    "extracted_text = object.get_generated_content(nested_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_dict = Helper.drop_dict(final_text)\n",
    "Helper.quick_json_dump(final_dict, json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_parse import Reader\n",
    "from samco import Samco\n",
    "import pprint, json\n",
    "import pandas as pd\n",
    "\n",
    "dir_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\"\n",
    "#dir_path = r\"C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Doc saved at C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\pdf_report.xlsx\n",
      "samco flexi cap fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "samco elss tax saver fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "samco active momentum fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "samco special opportunities fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "samco dynamic asset allocation fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "samco overnight fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "\n",
      "JSON CREATED\n"
     ]
    }
   ],
   "source": [
    "\"\"\" SAMCO PDF FILE MAIN CODE\"\"\"\n",
    "\n",
    "_reader = Reader(dir_path)\n",
    "\n",
    "file_path = _reader.get_file_path(r'\\files\\samco\\58_30-Jun-24_FS.pdf')\n",
    "dry_path  = _reader.get_file_path(r'\\output\\DryRun.pdf')\n",
    "fin_path  = _reader.get_file_path(r'\\files\\financial_indices.xlsx')\n",
    "json_path = _reader.get_file_path(r'\\output\\dump.json')\n",
    "\n",
    "\n",
    "_samco = Samco()\n",
    "financial_indices = _reader.get_financial_indices(fin_path)\n",
    "fund_data = _samco.fund_data\n",
    "\n",
    "path,fund_names,imp_pages = _reader.check_and_highlight(file_path, financial_indices,fund_data)\n",
    "_reader.save_pdf_data(imp_pages, fund_names)\n",
    "\n",
    "\n",
    "user_input = input(\"Enter the desired pages: \")\n",
    "pages = list(map(int,user_input.split(\" \")))\n",
    "bbox = _samco.content_bbox\n",
    "\n",
    "data = _reader.get_clipped_data(file_path,pages,bbox, fund_names)\n",
    "data = _reader.extract_span_data(data,[])\n",
    "clean_data = _reader.process_text_data(data, _samco.data_cond)\n",
    "\n",
    "nested_data, matrix = _reader.create_nested_dict(clean_data, 20.0, 10.0)\n",
    "\n",
    "#GENERATE/EXTRACT\n",
    "\n",
    "extracted_text = dict() #hv to write a function for this !!\n",
    "for fund, items in nested_data.items():\n",
    "    print(fund)\n",
    "    _reader.generate_pdf_from_data(items, dry_path)\n",
    "    extract_data = _reader.extract_data_from_pdf(dry_path)\n",
    "    extracted_text[fund] = extract_data\n",
    "    \n",
    "#CREATE FINAL CONTENT    \n",
    "final_text = dict()\n",
    "for fund, items in extracted_text.items():\n",
    "    \n",
    "    content_dict = dict()\n",
    "    for header, content in items.items():\n",
    "        header_content = _samco.match_regex_to_content(header, content)\n",
    "        content_dict.update(header_content)\n",
    "\n",
    "    final_text[fund] = content_dict\n",
    "\n",
    "\n",
    "#pprint.pprint(final_text)  \n",
    "with open(json_path, 'w',encoding='utf-8') as file:\n",
    "    json.dump(final_text,file,ensure_ascii=False, indent=4)\n",
    "    print(\"\\nJSON CREATED\")\n",
    "\n",
    "# print(\"\\n___________ Code Successfully Run _______________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Doc saved at C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\pdf_report.xlsx\n",
      "\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "\n",
      "JSON CREATED\n"
     ]
    }
   ],
   "source": [
    "\"\"\" TATA PDF FILE MAIN CODE\"\"\"\n",
    "\n",
    "_reader = Reader(dir_path)\n",
    "\n",
    "file_path = _reader.get_file_path(r'\\files\\TataFactSheet2024.pdf')\n",
    "dry_path  = _reader.get_file_path(r'\\output\\DryRun.pdf')\n",
    "fin_path  = _reader.get_file_path(r'\\files\\financial_indices.xlsx')\n",
    "json_path = _reader.get_file_path(r'\\output\\dump_tata.json')\n",
    "\n",
    "\n",
    "_samco = Samco()\n",
    "financial_indices = _reader.get_financial_indices(fin_path)\n",
    "fund_data = _samco.fund_data\n",
    "\n",
    "path,fund_names,imp_pages = _reader.check_and_highlight(file_path, financial_indices,fund_data)\n",
    "_reader.save_pdf_data(imp_pages, fund_names)\n",
    "\n",
    "\n",
    "user_input = input(\"Enter the desired pages: \")\n",
    "pages = list(map(int,user_input.split(\" \")))\n",
    "bbox = _samco.content_bbox\n",
    "\n",
    "data = _reader.get_clipped_data(file_path,pages,bbox, fund_names)\n",
    "data = _reader.extract_span_data(data,[])\n",
    "clean_data = _reader.process_text_data(data, _samco.data_cond)\n",
    "\n",
    "nested_data, matrix = _reader.create_nested_dict(clean_data, 20.0, 10.0)\n",
    "\n",
    "#GENERATE/EXTRACT\n",
    "\n",
    "extracted_text = dict() #hv to write a function for this !!\n",
    "for fund, items in nested_data.items():\n",
    "    print(fund)\n",
    "    _reader.generate_pdf_from_data(items, dry_path)\n",
    "    extract_data = _reader.extract_data_from_pdf(dry_path)\n",
    "    extracted_text[fund] = extract_data\n",
    "    \n",
    "#CREATE FINAL CONTENT    \n",
    "final_text = dict()\n",
    "for fund, items in extracted_text.items():\n",
    "    \n",
    "    content_dict = dict()\n",
    "    for header, content in items.items():\n",
    "        header_content = _samco.match_regex_to_content(header, content)\n",
    "        content_dict.update(header_content)\n",
    "\n",
    "    final_text[fund] = content_dict\n",
    "\n",
    "\n",
    "#pprint.pprint(final_text)  \n",
    "with open(json_path, 'w',encoding='utf-8') as file:\n",
    "    json.dump(final_text,file,ensure_ascii=False, indent=4)\n",
    "    print(\"\\nJSON CREATED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

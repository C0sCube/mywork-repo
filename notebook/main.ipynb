{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_parse import Reader\n",
    "from samco import Samco\n",
    "import pprint, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fitz\n",
    "\n",
    "dir_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\"\n",
    "#dir_path = r\"C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SAMCO PDF FILE MAIN CODE\"\"\"\n",
    "\n",
    "_reader = Reader(dir_path)\n",
    "\n",
    "file_path = _reader.get_file_path(r'\\files\\samco\\58_30-Jun-24_FS.pdf')\n",
    "dry_path  = _reader.get_file_path(r'\\output\\DryRun.pdf')\n",
    "fin_path  = _reader.get_file_path(r'\\files\\financial_indices.xlsx')\n",
    "json_path = _reader.get_file_path(r'\\output\\dump.json')\n",
    "\n",
    "\n",
    "_tata = Samco()\n",
    "financial_indices = _reader.get_financial_indices(fin_path)\n",
    "fund_data = _tata.fund_data\n",
    "\n",
    "path,fund_names,imp_pages = _reader.check_and_highlight(file_path, financial_indices,fund_data)\n",
    "_reader.save_pdf_data(imp_pages, fund_names)\n",
    "\n",
    "\n",
    "user_input = input(\"Enter the desired pages: \")\n",
    "pages = list(map(int,user_input.split(\" \")))\n",
    "bbox = _tata.content_bbox\n",
    "\n",
    "data = _reader.get_clipped_data(file_path,pages,bbox, fund_names)\n",
    "data = _reader.extract_span_data(data,[])\n",
    "clean_data = _reader.process_text_data(data, _tata.data_cond)\n",
    "\n",
    "nested_data, matrix = _reader.create_nested_dict(clean_data, 20.0, 10.0)\n",
    "\n",
    "#GENERATE/EXTRACT\n",
    "\n",
    "extracted_text = dict() #hv to write a function for this !!\n",
    "for fund, items in nested_data.items():\n",
    "    print(fund)\n",
    "    _reader.generate_pdf_from_data(items, dry_path)\n",
    "    extract_data = _reader.extract_data_from_pdf(dry_path)\n",
    "    extracted_text[fund] = extract_data\n",
    "    \n",
    "#CREATE FINAL CONTENT    \n",
    "final_text = dict()\n",
    "for fund, items in extracted_text.items():\n",
    "    \n",
    "    content_dict = dict()\n",
    "    for header, content in items.items():\n",
    "        header_content = _tata.match_regex_to_content(header, content)\n",
    "        content_dict.update(header_content)\n",
    "\n",
    "    final_text[fund] = content_dict\n",
    "\n",
    "\n",
    "#pprint.pprint(final_text)  \n",
    "with open(json_path, 'w',encoding='utf-8') as file:\n",
    "    json.dump(final_text,file,ensure_ascii=False, indent=4)\n",
    "    print(\"\\nJSON CREATED\")\n",
    "\n",
    "# print(\"\\n___________ Code Successfully Run _______________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TATA PDF FILE MAIN CODE\"\"\"\n",
    "from tata import Tata\n",
    "_reader = Reader(dir_path)\n",
    "\n",
    "file_path = _reader.get_file_path(r'\\files\\TataFactSheet2024.pdf')\n",
    "dry_path  = _reader.get_file_path(r'\\output\\DryRun.pdf')\n",
    "fin_path  = _reader.get_file_path(r'\\files\\financial_indices.xlsx')\n",
    "json_path = _reader.get_file_path(r'\\output\\dump_tata.json')\n",
    "\n",
    "\n",
    "_tata = Tata()\n",
    "financial_indices = _reader.get_financial_indices(fin_path)\n",
    "fund_data = _tata.fund_data\n",
    "\n",
    "path,fund_names,imp_pages = _reader.check_and_highlight(file_path, financial_indices,fund_data)\n",
    "_reader.save_pdf_data(imp_pages, fund_names)\n",
    "\n",
    "\n",
    "user_input = input(\"Enter the desired pages: \")\n",
    "pages = [ i for i in range(16,60)]+ [61,63] + [i for i in range(65,82)]\n",
    "bbox = _tata.content_bbox\n",
    "\n",
    "data = _reader.get_clipped_data(file_path,pages,bbox, fund_names)\n",
    "data = _reader.extract_span_data(data,[])\n",
    "clean_data = _reader.process_text_data(data, _tata.data_conditions)\n",
    "\n",
    "nested_data, matrix = _reader.create_nested_dict(clean_data, 20.0, 10.0)\n",
    "\n",
    "#GENERATE/EXTRACT\n",
    "\n",
    "extracted_text = dict() #hv to write a function for this !!\n",
    "for fund, items in nested_data.items():\n",
    "    print(fund)\n",
    "    _reader.generate_pdf_from_data(items, dry_path)\n",
    "    extract_data = _reader.extract_data_from_pdf(dry_path)\n",
    "    extracted_text[fund] = extract_data\n",
    "    \n",
    "# #CREATE FINAL CONTENT    \n",
    "# final_text = dict()\n",
    "# for fund, items in extracted_text.items():\n",
    "    \n",
    "#     content_dict = dict()\n",
    "#     for header, content in items.items():\n",
    "#         header_content = _tata.match_regex_to_content(header, content)\n",
    "#         content_dict.update(header_content)\n",
    "\n",
    "#     final_text[fund] = content_dict\n",
    "\n",
    "\n",
    "#pprint.pprint(final_text)  \n",
    "with open(json_path, 'w',encoding='utf-8') as file:\n",
    "    json.dump(extracted_text,file,ensure_ascii=False, indent=4)\n",
    "    print(\"\\nJSON CREATED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Doc saved at C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\pdf_report.xlsx\n",
      "360 one focused equity fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "360 one flexicap fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "360 one quant fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "360 one elss tax saver nifty 50 index fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "360 one balanced hybrid fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n",
      "360 one dynamic bond fund\n",
      " pdf generated to: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\DryRun.pdf\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ASSET ONE 360 FILE MAIN CODE\"\"\"\n",
    "\n",
    "from asset360 import One360\n",
    "\n",
    "\n",
    "_reader = Reader(dir_path)\n",
    "file_path = _reader.get_file_path(r'\\files\\one360.pdf')\n",
    "dry_path  = _reader.get_file_path(r'\\output\\DryRun.pdf')\n",
    "fin_path  = _reader.get_file_path(r'\\files\\financial_indices.xlsx')\n",
    "json_path = _reader.get_file_path(r'\\output\\dump360.json')\n",
    "\n",
    "_one360 = One360()\n",
    "\n",
    "financial_indices = _reader.get_financial_indices(fin_path)\n",
    "fund_data = _one360.fund_data\n",
    "bbox = [[0,50,160,900]]\n",
    "\n",
    "path,fund_names,imp_pages = _reader.check_and_highlight(file_path, financial_indices,fund_data)\n",
    "_reader.save_pdf_data(imp_pages, fund_names)\n",
    "\n",
    "#user_input = input(\"Enter the desired pages: \")\n",
    "pages = [5,6,7,8,9,10,11]\n",
    "\n",
    "data = _reader.get_clipped_data(file_path,pages,bbox, fund_names)\n",
    "extract_data = _reader.extract_span_data(data,[])\n",
    "data_conditions = [[8.0],-10791002,20.0]\n",
    "cleaned_data = _reader.process_text_data(extract_data, data_conditions)\n",
    "nested_data, matrix = _reader.create_nested_dict(cleaned_data, 20.0, 10.0)\n",
    "\n",
    "\n",
    "extracted_text = dict() #hv to write a function for this !!\n",
    "for fund, items in nested_data.items():\n",
    "    print(fund)\n",
    "    _reader.generate_pdf_from_data(items, dry_path)\n",
    "    extract_data = _reader.extract_data_from_pdf(dry_path)\n",
    "    extracted_text[fund] = extract_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BAJAJ FINSERV FILE MAIN CODE\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = _reader.get_file_path(r'\\files\\bajaj finserv.pdf')\n",
    "doc = fitz.open(file_path)\n",
    "\n",
    "count = doc.page_count\n",
    "all_blocks = list()\n",
    "\n",
    "for pgn in range(count):\n",
    "    page = doc[pgn]\n",
    "    \n",
    "    blocks = page.get_text('dict')['blocks']\n",
    "    images = page.get_images()\n",
    "    filtered_blocks = [block for block in blocks if block['type']==0]\n",
    "    sorted_blocks = sorted(blocks, key=lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "    all_blocks.append({\n",
    "        \"pgn\":pgn,\n",
    "        \"blocks\":sorted_blocks,\n",
    "        \"images\": images\n",
    "    })\n",
    "    \n",
    "    #draw lines\n",
    "    \n",
    "    lines = fitz.Rect()\n",
    "    \n",
    "doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(465, 464, 824, 359, 8, 'Indexed', '', 'X140', 'FlateDecode')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_blocks[17]['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_number, page in enumerate(doc, start=0):\n",
    "    print(f\"\\n_____________{page_number}______________\")\n",
    "    images = page.get_images(full=True)  # Get all images on the page\n",
    "    for img_index, img in enumerate(images, start=1):\n",
    "        print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blocks[17]['blocks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

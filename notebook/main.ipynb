{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pprint, json, math, os, sys\n",
    "import fitz\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "dir_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\"\n",
    "fund_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\Dec 24\"\n",
    "\n",
    "# dir_path = r\"C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\"\n",
    "# fund_path = r'C:\\Users\\rando\\OneDrive\\Documents\\Dec 24'\n",
    "sys.path.append(os.path.abspath(dir_path))\n",
    "\n",
    "from app.fundData import *\n",
    "from app.helper import Helper\n",
    "\n",
    "dry_path = r'\\data\\output\\DryRun.pdf'\n",
    "fin_path = r'\\data\\input\\financial_indices.xlsx'\n",
    "rep_path = r'\\data\\output\\pdf_report.xlsx'\n",
    "\n",
    "json_path = dir_path + r'\\data\\output\\dump.json'\n",
    "pkl_path = dir_path + r'\\data\\output\\sample.pkl'\n",
    "\n",
    "mutual_fund = Helper.get_fund_paths(fund_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WHITEOAK MAIN FILE CODE\"\"\" #Issue: Inv Obj in the right #json issue\n",
    "object = WhiteOak(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['WhiteOak Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 6)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 9, 11, 13, 15, 17, 19, 20, 21, 23, 25, 26, 28, 30, 32, 34, 35]\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_dict = Helper.drop_dict(final_text)\n",
    "Helper.quick_json_dump(final_dict, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''' 360 ONE MAIN FILE CODE''' #No issues as of now\n",
    "\n",
    "object = ThreeSixtyOne(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['360 ONE Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_dict = Helper.drop_dict(final_text)\n",
    "Helper.quick_json_dump(final_dict, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MAHINDRA MANULIFE MAIN CODE\"\"\" #incrase pages count\n",
    "\n",
    "object = MahindraManu(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Mahindra Manulife Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = object.get_proper_fund_names(file_path,[i for i in range(1,80)])\n",
    "pages = [i for i in range(8,34)]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"JM FUND MAIN FILE CODE\"\"\" #objective on left, sometimes date is with header\n",
    "\n",
    "object = JMMF(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['JM Financial Mutual Fund']\n",
    "\n",
    "\n",
    "#path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INVESCO MF MAIN FILE CODE\"\"\" #Issue: two fund on same page\n",
    "\n",
    "object = Invesco(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Invesco Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SAMCO PDF FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = Samco(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Samco Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages =  [3, 5, 7, 9, 11, 13, 15, 17, 18]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title)\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TATA FILE MAIN CODE \"\"\"\n",
    "object = Tata(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Tata Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 10)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title)\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = Helper.drop_dict(extracted_text)\n",
    "final_data = object.refine_extracted_data(final_text)\n",
    "Helper.quick_json_dump(final_data, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" FRANKLIN TEMPLETON FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = FranklinTempleton(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Franklin Templeton Mutual Fund\"]\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 6)\n",
    "title = df.title.to_dict()\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "# final_dict = Helper.drop_empty_dict_values()\n",
    "Helper.quick_json_dump(final_text, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BANDHAN MF FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = Bandhan(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Bandhan Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path,6)\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"KOTAK FUND MAIN CODE\"\"\" #Issue: 1 or more fund on same page, # title overlap the content\n",
    "object = Kotak(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Kotak Mahindra Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 40, 41, 43, 44, 46, 48, 49, 50, 52, 54, 55, 56, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
    "data = object.extract_clipped_data(file_path,pages,title)#used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text, ['folio_count_data_as_on_30th_november','idcw_frequency','available_plans/options'])\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ZERODHA MAIN CODE\"\"\" \n",
    "\n",
    "object = Zerodha(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Zerodha Mutual Fund']\n",
    "\n",
    "path,df= object.check_and_highlight(file_path,7)\n",
    "title = df.title.to_dict()\n",
    "pages = [3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "#left\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_l = object.extract_span_data(data_l,[])\n",
    "clean_data = object.process_text_data(data_l)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "#right\n",
    "data_r = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data_r = object.extract_span_data(data_r,[])\n",
    "clean_data = object.process_text_data(data_r)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "nested_data = {key:{**nested_data_left[key],**nested_data_right[key] }for key in nested_data_left.keys()}\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NAVI MAIN FILE CODE\"\"\" #Issue: Left and right\n",
    "\n",
    "object = NAVI(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Navi Mutual Fund']\n",
    "\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path,5)\n",
    "title = df.title.to_dict()\n",
    "pages = [2, 6, 8, 10, 13, 16, 18, 20, 22]\n",
    "\n",
    "#left\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_l = object.extract_span_data(data_l,[])\n",
    "clean_data = object.process_text_data(data_l)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 9.0)\n",
    "\n",
    "#right\n",
    "data_r = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data_r = object.extract_span_data(data_r,[])\n",
    "clean_data = object.process_text_data(data_r)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 9.0)\n",
    "\n",
    "nested_data = {key:{**nested_data_left[key],**nested_data_right[key] }for key in nested_data_left.keys()}\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BARODA BNP MAIN FILE CODE\"\"\" #Issue: Header funds #scheme details\n",
    "\n",
    "object = BarodaBNP(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Baroda BNP Paribas Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
    "title = object.get_proper_fund_names(file_path, pages, (0,0,210,75))\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\", title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_dict = Helper.drop_dict(final_text)\n",
    "Helper.quick_json_dump(final_dict, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MOTILAL OSWAL MAIN CODE FILE\"\"\" #Fund Manager Regex\n",
    "\n",
    "object = MotilalOswal(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Motilal Oswal Mutual Fund']\n",
    "\n",
    "# path,df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [i for i in range(4,21)]\n",
    "title = df.title.to_dict()\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"HELIOS MF FILE MAIN CODE\"\"\" #fund manager \n",
    "\n",
    "object = Helios(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Helios Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path,6)\n",
    "title = df.title.to_dict()\n",
    "pages =  [2, 4, 6, 8, 10]\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages ,'left', title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EDELWEISS MP FILE MAIN CODE\"\"\" #Issues: objective in seperate dict, scheme launch date issue\n",
    "\n",
    "object = Edelweiss(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Edelweiss Mutual Fund']\n",
    "\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 6)\n",
    "\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75]\n",
    "\n",
    "title,objectives = object.get_proper_fund_names(file_path,pages)\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages ,'right',title ) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NJMF MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = NJMF(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['NJ Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "pages = [1, 3, 5, 7, 9]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SUNDARAM MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = Sundaram(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Sundaram Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "#below functions are optional to run\n",
    "final_text = Helper.drop_selected_dict_values(final_text,['performance_10,000_invested_value_of_10,000-a-month_sip','market_capital','~since_inception','last_5_years','last_3_years','last_1_year','period'])\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ITI MAIN FILE CODE\"\"\" #Issues: more data cleaning\n",
    "\n",
    "object = ITI(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['ITI Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text,['this_product_is_suitable'])\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MIRAE MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = MIRAE(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Mirae Asset Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 7)\n",
    "pages = [25, 26, 27, 28, 29, 30, 31, 32, 33, 34,35, 36, 37, 38, 39, 40, 41,42,43,44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,61,62,63,64, 65, 66, 67, 68]\n",
    "title = object.get_proper_fund_names(file_path,pages)\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILES TO BE CLEANED ARE BELOW , DATA ABLE TO EXTRACTED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"HSBC MAIN FILE CODE\"\"\" #Issue: Some pages have 2 or more fund data on same page\n",
    "#some data is present on right side as well so define two lines\n",
    "#objective is to be exracted seperately\n",
    "\n",
    "object = HSBC(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['HSBC Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
    "data = object.extract_clipped_data(file_path, pages, title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DSP MAIN FILE CODE\"\"\" #Issue: highlight count must be lower\n",
    "#Issue: data on both side ends so issue coming\n",
    "\n",
    "object = DSP(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['DSP Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 5)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LIC MF FILE CODE\"\"\"\n",
    "\n",
    "#ISSUE: THE FUND NAMES ARE IMAGES \"\"\" LIC MF MAIN CODE\"\"\"\n",
    " #Issue: objective on right of line\n",
    "\n",
    "object = LIC(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund[]\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"QUANT MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = QuantMF(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Quant Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 61, 63, 65]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TAURUS MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = Taurus(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Taurus Mutual Fund']\n",
    "\n",
    "# path, df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [13, 14, 15, 16, 17, 19, 20]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BANK OF INDIA\"\"\"\n",
    "object = BankOfIndia(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Bank of India Mutual Fund']\n",
    "\n",
    "# path, df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "\n",
    "#left\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_l = object.extract_span_data(data_l,[])\n",
    "clean_data = object.process_text_data(data_l)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "\n",
    "#right\n",
    "data_r = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data_r = object.extract_span_data(data_r,[])\n",
    "clean_data = object.process_text_data(data_r)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "\n",
    "nested_data = {key:{**nested_data_left[key],**nested_data_right[key] }for key in nested_data_left.keys()}\n",
    "extracted_text = object.get_generated_content(nested_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " JSON saved at C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\dump_bank_18_08.json\n"
     ]
    }
   ],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "remove = ['certificate_of_deposit','treasury_bill','who_are_seeking*:','who_should_invest','equity_holdings','this_product_is_suitable_for_investors','december_31,_2024']\n",
    "final_clean_text = Helper.drop_selected_dict_values(final_text, remove)\n",
    "final_clean_text = Helper.drop_empty_dict_values(final_clean_text)\n",
    "Helper.quick_json_dump(final_clean_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.94']\n",
      "['0.60']\n",
      "['0.92']\n",
      "['0.96']\n",
      "['1.40']\n",
      "['0.64']\n",
      "['0.00']\n",
      "['1.01']\n",
      "['0.59']\n",
      "['1.15']\n"
     ]
    }
   ],
   "source": [
    "pattern = r'(Growth|IDCW)\\s*([\\d,.]+)' #regex takes 2 kv pairs\n",
    "expense_pattern = r'(Regular Plan|Direct Plan)\\s*([\\d,.]+)'\n",
    "total_pattern = r'^([\\d,.]+)' #only first value required hence ^\n",
    "for fund, content in final_text.items():\n",
    " if \"portfolio_turover_ratio\" in content:\n",
    "     for text in content['portfolio_turover_ratio']:\n",
    "        text = re.sub(r'[\\*,:\\^;]+', \"\", text)\n",
    "        if matches := re.findall(total_pattern, text, re.IGNORECASE):\n",
    "            print(matches)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94 Times# #( Basis last rolling 12 months)\n",
      "0.60 Times# #( Basis last rolling 12 months)\n",
      "0.92 Times# #( Basis last rolling 12 months)\n",
      "0.96 Times# #( Basis last rolling 12 months)\n",
      "1.40 Times# #( Basis last rolling 12 months)\n",
      "0.64 Times# #( Basis last rolling 12 months)\n",
      "0.00 Times# #( Basis last rolling 12 months)\n",
      "1.01 Times# #( Basis last rolling 12 months)\n",
      "0.59 Times# #( Basis last rolling 12 months)\n",
      "1.15 Times# #( Basis last rolling 12 months)\n"
     ]
    }
   ],
   "source": [
    "for fund, content in final_clean_text.items():\n",
    " if \"portfolio_turover_ratio\" in content:\n",
    "     for text in content['portfolio_turover_ratio']:\n",
    "         print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data successfully dumped to C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\sample.pkl\n"
     ]
    }
   ],
   "source": [
    "Helper.dump_pickle_data(final_text,pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRUST MAIN FILE CODE\"\"\" #Issue: Invest Obj in right #Names coming as headers fund managers\n",
    "\n",
    "object = Trust(dir_path,dry_path,fin_path)\n",
    "file_path = mutual_fund['Trust Mutual Fund']\n",
    "\n",
    "fund_data = object.PARAMS['fund']\n",
    "line_x = object.PARAMS['line_x']\n",
    "bbox = object.PARAMS['clip_box']\n",
    "data_cond = object.PARAMS['data']\n",
    "path, imp, fund_titles = object.check_and_highlight(file_path, fund_data)\n",
    "msgs = input(\"\\nEnter Y/N: \")\n",
    "\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "data = object.extract_data_relative_line(file_path,pages,line_x,\"left\",fund_titles) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data, data_cond) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data, object.DRYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UTI MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = UTI(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['UTI Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 46, 48, 50, 52, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BAJAJ FINSERV MAIN FILE CODE\"\"\" #major issue of lines #minor of dropping keys of final dict\n",
    "\n",
    "object = BajajFinServ(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Bajaj finserv Mutual Fund']\n",
    "\n",
    "#path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [15, 17, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "#left\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_l = object.extract_span_data(data_l,[])\n",
    "clean_data = object.process_text_data(data_l)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "#right\n",
    "data_r = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data_r = object.extract_span_data(data_r,[])\n",
    "clean_data = object.process_text_data(data_r)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "nested_data = {key:{**nested_data_left[key],**nested_data_right[key] }for key in nested_data_left.keys()}\n",
    "extracted_text = object.get_generated_content(nested_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

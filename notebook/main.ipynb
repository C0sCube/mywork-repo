{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pprint, json, math, os, sys\n",
    "import fitz\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "dir_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\"\n",
    "fund_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\Dec 24\"\n",
    "\n",
    "# dir_path = r\"C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\"\n",
    "# fund_path = r'C:\\Users\\rando\\OneDrive\\Documents\\Dec 24'\n",
    "sys.path.append(os.path.abspath(dir_path))\n",
    "\n",
    "from app.fundData import *\n",
    "from app.helper import Helper\n",
    "\n",
    "dry_path = r'\\data\\output\\DryRun.pdf'\n",
    "fin_path = r'\\data\\input\\financial_indices.xlsx'\n",
    "rep_path = r'\\data\\output\\pdf_report.xlsx'\n",
    "\n",
    "json_path = dir_path + r'\\data\\output\\dump.json'\n",
    "pkl_path = dir_path + r'\\data\\output\\sample.pkl'\n",
    "\n",
    "mutual_fund = Helper.get_fund_paths(fund_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WHITEOAK MAIN FILE CODE\"\"\" #Issue: Inv Obj in the right #Fund Manager Data\n",
    "object = WhiteOak(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['WhiteOak Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 6)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 9, 11, 13, 15, 17, 19, 20, 21, 23, 25, 26, 28, 30, 32, 34, 35]\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''' 360 ONE MAIN FILE CODE''' #No issues as of now\n",
    "\n",
    "object = ThreeSixtyOne(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['360 ONE Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MAHINDRA MANULIFE MAIN CODE\"\"\" #incrase pages count\n",
    "\n",
    "object = MahindraManu(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Mahindra Manulife Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = object.get_proper_fund_names(file_path,[i for i in range(1,80)])\n",
    "pages = [i for i in range(8,34)]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"JM FUND MAIN FILE CODE\"\"\" #objective on left, sometimes date is with header\n",
    "\n",
    "object = JMMF(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['JM Financial Mutual Fund']\n",
    "\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INVESCO MF MAIN FILE CODE\"\"\" #Issue: two fund on same page\n",
    "\n",
    "object = Invesco(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Invesco Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SAMCO PDF FILE MAIN CODE\"\"\" #Issues: TTER data regex rst fine !!\n",
    "\n",
    "object = Samco(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Samco Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages =  [3, 5, 7, 9, 11, 13, 15, 17, 18]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title)\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TATA FILE MAIN CODE \"\"\"\n",
    "object = Tata(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Tata Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 10)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title)\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = Helper.drop_empty_dict_values(extracted_text)\n",
    "final_text = object.refine_extracted_data(final_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" FRANKLIN TEMPLETON FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = FranklinTempleton(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Franklin Templeton Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 6)\n",
    "title = df.title.to_dict()\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BANDHAN MF FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = Bandhan(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Bandhan Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path,6)\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages, title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"KOTAK FUND MAIN CODE\"\"\" #Issue: 1 or more fund on same page, # title overlap the content\n",
    "object = Kotak(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Kotak Mahindra Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 40, 41, 43, 44, 46, 48, 49, 50, 52, 54, 55, 56, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
    "data = object.extract_clipped_data(file_path,pages,title)#used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text, ['ideal_investments_horizon','before','idcw_frequency','available_plansoptions'])\n",
    "final_text = Helper.drop_keys_by_regex(final_text,[r'^folio'])\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ZERODHA MAIN CODE\"\"\" \n",
    "\n",
    "object = Zerodha(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Zerodha Mutual Fund']\n",
    "\n",
    "path,df= object.check_and_highlight(file_path,7)\n",
    "title = df.title.to_dict()\n",
    "pages = [3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "#left\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "#right\n",
    "data = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "nested_data = Helper.merge_nested_dicts(nested_data_left, nested_data_right)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NAVI MAIN FILE CODE\"\"\" #Issue: Left and right\n",
    "\n",
    "object = NAVI(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Navi Mutual Fund']\n",
    "\n",
    "\n",
    "path,df = object.check_and_highlight(file_path,5)\n",
    "title = df.title.to_dict()\n",
    "pages = [2, 6, 8, 10, 13, 16, 18, 20, 22]\n",
    "\n",
    "#left\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 9.0)\n",
    "\n",
    "#right\n",
    "data = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 9.0)\n",
    "\n",
    "nested_data = Helper.merge_nested_dicts(nested_data_left, nested_data_right)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text,['industry_allocation','equity_','this_product_is_suitable_for_investors_who_are_seeking'])\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BARODA BNP MAIN FILE CODE\"\"\" #Issue: Header funds #scheme details\n",
    "\n",
    "object = BarodaBNP(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Baroda BNP Paribas Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
    "title = object.get_proper_fund_names(file_path, pages, (0,0,210,75))\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\", title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,[r\"^(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\",r'^key_statistics',r'^the_risk_free_rate_of_retu'])\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MOTILAL OSWAL MAIN CODE FILE\"\"\" #Fund Manager Regex\n",
    "\n",
    "object = MotilalOswal(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Motilal Oswal Mutual Fund']\n",
    "\n",
    "path,df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [i for i in range(4,21)]\n",
    "title = df.title.to_dict()\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"HELIOS MF FILE MAIN CODE\"\"\" #fund manager \n",
    "\n",
    "object = Helios(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Helios Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path,6)\n",
    "title = df.title.to_dict()\n",
    "pages =  [2, 4, 6, 8, 10]\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages ,'left', title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,[r'^(An open|Large).*'])\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_head = []\n",
    "for content in final_text.values():\n",
    "    for key in content.keys():\n",
    "        grand_head.append(key)\n",
    "\n",
    "grand_head = set(grand_head)\n",
    "\n",
    "grand_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EDELWEISS MP FILE MAIN CODE\"\"\" #Issues: objective in seperate dict, scheme launch date issue\n",
    "\n",
    "object = Edelweiss(dir_path, dry_path, fin_path, rep_path)\n",
    "file_path = mutual_fund['Edelweiss Mutual Fund']\n",
    "\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 6)\n",
    "\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75]\n",
    "\n",
    "title,objectives = object.get_proper_fund_names(file_path,pages)\n",
    "\n",
    "data = object.extract_data_relative_line(file_path,pages ,'right',title ) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,20.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NJMF MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = NJMF(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['NJ Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "pages = [1, 3, 5, 7, 9]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SUNDARAM MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = Sundaram(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Sundaram Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "#below functions are optional to run\n",
    "final_text = Helper.drop_selected_dict_values(final_text,['performance_10,000_invested_value_of_10,000-a-month_sip','market_capital','~since_inception','last_5_years','last_3_years','last_1_year','period'])\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ITI MAIN FILE CODE\"\"\" #Issues: more data cleaning\n",
    "\n",
    "object = ITI(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['ITI Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
    "\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text,['this_product_is_suitable'])\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MIRAE MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = MIRAE(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Mirae Asset Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 7)\n",
    "pages = [25, 26, 27, 28, 29, 30, 31, 32, 33, 34,35, 36, 37, 38, 39, 40, 41,42,43,44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,61,62,63,64, 65, 66, 67, 68]\n",
    "title = object.get_proper_fund_names(file_path,pages)\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BANK OF INDIA\"\"\" #Issues: Fund Manger extraction\n",
    "object = BankOfIndia(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Bank of India Mutual Fund']\n",
    "\n",
    "path, df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "\n",
    "#left\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_l = object.extract_span_data(data_l,[])\n",
    "clean_data = object.process_text_data(data_l)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "\n",
    "#right\n",
    "data_r = object.extract_data_relative_line(file_path,pages,\"right\",title) #used line here\n",
    "data_r = object.extract_span_data(data_r,[])\n",
    "clean_data = object.process_text_data(data_r)\n",
    "nested_data_right, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "\n",
    "nested_data = {key:{**nested_data_left[key],**nested_data_right[key] }for key in nested_data_left.keys()}\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "remove = ['certificate_of_deposit','treasury_bill','who_are_seeking*:','who_should_invest','equity_holdings','this_product_is_suitable_for_investors','december_31,_2024']\n",
    "final_clean_text = Helper.drop_selected_dict_values(final_text, remove)\n",
    "final_clean_text = Helper.drop_keys_by_regex(final_clean_text, [r'^total'])\n",
    "final_clean_text = Helper.drop_empty_dict_values(final_clean_text)\n",
    "Helper.quick_json_dump(final_clean_text, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TAURUS MAIN FILE CODE\"\"\" #Issues: Nothing Yet\n",
    "\n",
    "object = Taurus(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Taurus Mutual Fund']\n",
    "\n",
    "# path, df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [13, 14, 15, 16, 17, 19, 20]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRUST MAIN FILE CODE\"\"\" #Issue: Clean data more, nested dict unload Invest Obj in right #Names coming as headers fund managers\n",
    "\n",
    "object = Trust(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Trust Mutual Fund']\n",
    "\n",
    "# path, df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CANARA MUTUAL FUND\"\"\" #Issues: very complicated \"\"HHHHHHHHHHHHHHHHHHHHHHHH\n",
    "\n",
    "object = Canara(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Canara Robeco Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "#segment 1\n",
    "data_a = object.extract_clipped_data(file_path,pages,title) #used line here\n",
    "data_a = object.extract_span_data(data_a,[])\n",
    "clean_data_a = object.process_text_data(data_a)\n",
    "nested_data_a, matrix = object.create_nested_dict(clean_data_a,30.0, 10.0)\n",
    "\n",
    "#segment 2\n",
    "data_b = object.extract_clipped_data(file_path, pages, title,[(220,115,400,812)])\n",
    "data_b = object.extract_span_data(data_b,[])\n",
    "clean_data_b = object.process_text_data(data_b)\n",
    "nested_data_b, matrix = object.create_nested_dict(clean_data_b,30.0, 10.0)\n",
    "\n",
    "\n",
    "nested_data = {key:{**nested_data_a[key],**nested_data_b[key] }for key in nested_data_b.keys()}\n",
    "final_text = Helper.merge_key_values(extracted_text,'fund_information','before')\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text,['portfolio','product_positioning'])\n",
    "Helper.quick_json_dump(final_text,json_path)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BAJAJ FINSERV MAIN FILE CODE\"\"\" #major issue of lines #minor of dropping keys of final dict\n",
    "\n",
    "object = BajajFinServ(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Bajaj finserv Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [15, 17, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "#segmant 1 left\n",
    "data_l = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data_l = object.extract_span_data(data_l,[])\n",
    "clean_data = object.process_text_data(data_l)\n",
    "nested_data_left, matrix = object.create_nested_dict(clean_data,30.0, 14.0)\n",
    "\n",
    "#segment 2\n",
    "data_a = object.extract_clipped_data(file_path,pages,title,[(180,45,360,300)]) #used line here\n",
    "data_a = object.extract_span_data(data_a,[])\n",
    "clean_data_a = object.process_text_data(data_a)\n",
    "nested_data_a, matrix = object.create_nested_dict(clean_data_a,30.0, 10.0)\n",
    "\n",
    "#segment 3\n",
    "data_b = object.extract_clipped_data(file_path, pages, title,[(360,45,580,300)])\n",
    "data_b = object.extract_span_data(data_b,[])\n",
    "clean_data_b = object.process_text_data(data_b)\n",
    "nested_data_b, matrix = object.create_nested_dict(clean_data_b,30.0, 10.0)\n",
    "\n",
    "\n",
    "nested_data = Helper.merge_nested_dicts(nested_data_left, nested_data_a, nested_data_b)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UTI MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = UTI(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['UTI Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 46, 48, 50, 52, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77]\n",
    "data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text,['high/low_nav_in_the_month','plans/options','porolio_details','market_capital'])\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NIPPON MUTUAL FUND\"\"\"\n",
    "\n",
    "object = Nippon(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Nippon India Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92]\n",
    "title = df.title.to_dict()\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"QUANTUM MAIN FILE CODE\"\"\" #ISSUES: Clean data further\n",
    "\n",
    "object = Quantum(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund[\"Quantum Mutual Fund\"]\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 28, 29, 30]\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 8.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UNION MUTUAL FUND\"\"\" #Issues: Clean Further\n",
    "\n",
    "object = Union(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Union Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,]\n",
    "title = df.title.apply(lambda x: \"Union \"+ x if x !=\"\" else x).to_dict()\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data)\n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILES TO BE CLEANED ARE BELOW , DATA ABLE TO EXTRACTED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"QUANT MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = QuantMF(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Quant Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 61, 63, 65]\n",
    "# data = object.extract_data_relative_line(file_path,pages,\"left\",title) #used clip here\n",
    "# data = object.extract_span_data(data,[])\n",
    "# clean_data = object.process_text_data(data) \n",
    "# nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "# extracted_text = object.get_generated_content(nested_data)\n",
    "\n",
    "\"\"\"\"HSBC MAIN FILE CODE\"\"\" #Issue: Some pages have 2 or more fund data on same page\n",
    "#some data is present on right side as well so define two lines\n",
    "#objective is to be exracted seperately\n",
    "\n",
    "object = HSBC(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['HSBC Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
    "data = object.extract_clipped_data(file_path, pages, title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PGIM MUTUAL FUND\"\"\"\n",
    "\n",
    "object = PGIM(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['PGIM India Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "pages = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34]\n",
    "title = df.title.apply(lambda x: \"PGIM \"+x if not x == \"\" else x).to_dict()\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used line here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_data, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DSP MAIN FILE CODE\"\"\" #Issue: highlight count must be lower\n",
    "#Issue: data on both side ends so issue coming\n",
    "\n",
    "object = DSP(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['DSP Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 5)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]\n",
    "\n",
    "#segment 1\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data1, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "\n",
    "#segment2\n",
    "data = object.extract_clipped_data(file_path,pages,title,[(480,5,596,812)]) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data2, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "\n",
    "nested_data = Helper.merge_nested_dicts(nested_data1, nested_data2)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ADITYA BIRLA FILE CODE\"\"\" #Issue: highlight count must be lower\n",
    "#Issue: data on both side ends so issue coming\n",
    "\n",
    "object = AdityaBirla(dir_path,dry_path,fin_path, rep_path)\n",
    "file_path = mutual_fund['Aditya Birla Sun Life Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 16)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [12, 14, 16, 18, 20, 22, 24, 26, 27, 28, 30, 32, 34, 35, 36, 38, 40, 44, 47, 49, 53, 55, 57, 61, 63, 66, 68, 69, 72, 73, 74, 75, 76, 78, 80, 81, 85, 95, 102, 104, 108, 110, 112, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 141, 143, 147, 149, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 170, 171, 172, 173, 174]\n",
    "#segment 1\n",
    "data = object.extract_clipped_data(file_path,pages,title) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data1, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "\n",
    "#segment2\n",
    "data = object.extract_clipped_data(file_path,pages,title,[(200, 50, 380, 812)]) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data2, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "\n",
    "#segment3\n",
    "data = object.extract_clipped_data(file_path,pages,title,[(380, 50, 580, 812)]) #used clip here\n",
    "data = object.extract_span_data(data,[])\n",
    "clean_data = object.process_text_data(data) \n",
    "nested_data3, matrix = object.create_nested_dict(clean_data,30.0, 10.0)\n",
    "\n",
    "nested_data = Helper.merge_nested_dicts(nested_data1, nested_data2,nested_data3)\n",
    "extracted_text = object.get_generated_content(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "# final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text,json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pdf_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\singular\\TextualPage4.pdf\" # Replace with your input PDF file path\n",
    "output_pdf_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\singular\\sample.pdf\"  # Replace with your desired output PDF file path\n",
    "file_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\files\\SamcoFactSheet2024.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\TextualPdf.pdf\"\n",
    "\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\TabularPdf.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz \n",
    "import camelot\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Usage\n",
    "pdf_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\singular\\TextualPage4.pdf\"\n",
    "text_data = extract_text(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def detect_columns(pdf_path, eps=50, min_samples=2):\n",
    "    \"\"\"\n",
    "    Detect the number of text columns in each page of a PDF.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path: str, path to the PDF file.\n",
    "    - eps: float, maximum distance between two samples for them to be considered in the same neighborhood (DBSCAN parameter).\n",
    "    - min_samples: int, number of samples in a neighborhood for a point to be considered a core point (DBSCAN parameter).\n",
    "\n",
    "    Returns:\n",
    "    - List of integers representing the number of columns detected on each page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    column_counts = []\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text_dict = page.get_text(\"dict\")\n",
    "\n",
    "        # Collect x-coordinates of text blocks\n",
    "        x_coords = []\n",
    "        for block in text_dict.get(\"blocks\", []):\n",
    "            bbox = block.get(\"bbox\", [])\n",
    "            if bbox:\n",
    "                x0 = bbox[0]  # x-coordinate of the left side of the block\n",
    "                x_coords.append([x0])\n",
    "\n",
    "        if x_coords:\n",
    "            # Convert to numpy array\n",
    "            x_coords = np.array(x_coords)\n",
    "\n",
    "            # Apply DBSCAN clustering\n",
    "            clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(x_coords)\n",
    "\n",
    "            # Number of clusters (excluding noise if present)\n",
    "            num_columns = len(set(clustering.labels_)) - (1 if -1 in clustering.labels_ else 0)\n",
    "            column_counts.append(num_columns)\n",
    "        else:\n",
    "            column_counts.append(0)\n",
    "\n",
    "    doc.close()\n",
    "    return column_counts\n",
    "\n",
    "# Example usage\n",
    "pdf_path = file_path  # Replace with your PDF file path\n",
    "columns_per_page = detect_columns(pdf_path)\n",
    "for i, num_columns in enumerate(columns_per_page):\n",
    "    print(f\"Page {i + 1}: {num_columns} columns detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def annotate_pdf(input_path, output_path):\n",
    "    # Open the PDF document\n",
    "    pdf = fitz.open(input_path)\n",
    "    \n",
    "    # Iterate through each page\n",
    "    for page_num in range(len(pdf)):\n",
    "        page = pdf.load_page(page_num)\n",
    "        # Extract text as a dictionary containing blocks, lines, and spans\n",
    "        text_dict = page.get_text(\"dict\")\n",
    "        \n",
    "        # Iterate through blocks\n",
    "        for block in text_dict.get(\"blocks\", []):\n",
    "            # Check if the block contains lines\n",
    "            if \"lines\" in block:\n",
    "                # Iterate through lines\n",
    "                for line in block[\"lines\"]:\n",
    "                    # Get the bounding box of the line\n",
    "                    line_bbox = fitz.Rect(line[\"bbox\"])\n",
    "                    # Draw a rectangle around the line\n",
    "                    page.draw_rect(line_bbox, color=(1, 0, 0), width=0.5)\n",
    "    \n",
    "    # Save the annotated PDF to the output path\n",
    "    pdf.save(output_path)\n",
    "    pdf.close()\n",
    "\n",
    "# Example usage\n",
    "input_pdf_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\singular\\TextualPage4.pdf\" # Replace with your input PDF file path\n",
    "output_pdf_path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\output\\singular\\sample.pdf\"  # Replace with your desired output PDF file path\n",
    "annotate_pdf(input_pdf_path, output_pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pages:1\n"
     ]
    }
   ],
   "source": [
    "def extract_pdf(path):\n",
    "    \n",
    "    pdf = fitz.open(path)\n",
    "    page_content = []\n",
    "    \n",
    "    for pgn in range(len(pdf)):\n",
    "        page = pdf.load_page(pgn)\n",
    "        text = page.get_text(\"dict\")\n",
    "        page_content.append(text)\n",
    "    return page_content\n",
    "        \n",
    "    # sort_by_y = []\n",
    "    # for block in page_content:\n",
    "    #     for lines in block['lines']:\n",
    "    #         for span in lines['span']\n",
    "    \n",
    "    \n",
    "content = extract_pdf(input_pdf_path)\n",
    "print(f\"\\nPages:{len(content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPage = content[0]\n",
    "#print all the content of the block\n",
    "print(f\"\\nLength of Blocks: {len(firstPage['blocks'])}\")\n",
    "for block in firstPage['blocks']:\n",
    "    for spans in block['lines']:\n",
    "        txt = \" \".join(item['text'] for item in spans['spans'])\n",
    "        print(block['bbox'],txt, spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort Left to Right Top to Bottom\n",
    "# x0, y0 lower-left x1, y1 upper-right\n",
    "\n",
    "SortedBlocks = sorted(firstPage['blocks'], key= lambda x : (x['bbox'][1], x['bbox'][0]))\n",
    "\n",
    "block_sizes = {}\n",
    "block_fonts = {}\n",
    "for block in SortedBlocks:\n",
    "    for spans in block['lines']:\n",
    "        temp = []\n",
    "        txt = \" \".join(item['text'] for item in spans['spans'])\n",
    "        for span in spans['spans']:\n",
    "            temp.append(span['size'])\n",
    "            #get size \n",
    "            size  = span['size']\n",
    "            if size not in block_sizes.keys():\n",
    "                block_sizes[size] = 1\n",
    "            else:\n",
    "                block_sizes[size] +=1\n",
    "            \n",
    "            #get font agg\n",
    "            color = span['color']\n",
    "            if color not in block_fonts.keys():\n",
    "                block_fonts[color] = 1\n",
    "            else:\n",
    "                block_fonts[color]+=1\n",
    "        print(block['bbox'],txt, \"size:\",temp)\n",
    "        \n",
    "        \n",
    "sorted_blk_fonts = sorted(block_fonts.items(), key=lambda item: item[1])\n",
    "sorted_blk_sizes = sorted(block_sizes.items(), key=lambda item: item[1])\n",
    "print(\"\\nSize: \", sorted_blk_sizes)\n",
    "print(\"\\nColors: \", sorted_blk_fonts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sizes = [i[0] for i in sorted_blk_sizes]\n",
    "colors = [i[0] for i in sorted_blk_fonts]\n",
    "\n",
    "X,Y = len(colors), len(sizes)\n",
    "\n",
    "matrix_keys  = [(i,j) for i in colors for j in sizes]\n",
    "matrix = {}\n",
    "\n",
    "for block in SortedBlocks:\n",
    "    # count occrences of (color, size) on each page block by block\n",
    "    for spans in block['lines']:\n",
    "        for span in spans['spans']:\n",
    "            size = span['size']\n",
    "            color = span['color']\n",
    "            matrix[(color,size)] = matrix.get((color,size), 0) + 1\n",
    "\n",
    "\n",
    "data = sorted(matrix.items(), key  = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-12368828, 7.0), 52)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the heatmap\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'x': [pt[0][0] for pt in data],\n",
    "        'y': [pt[0][1] for pt in data],\n",
    "        'value': [pt[1]     for pt in data],\n",
    "    }\n",
    ")\n",
    "\n",
    "# 2. Pivot so that rows = y, columns = x, and cell entries = 'value'\n",
    "heatmap_df = df.pivot(index='y', columns='x', values='value')\n",
    "\n",
    "plt.imshow(heatmap_df, origin=\"upper\", cmap=\"inferno\")\n",
    "\n",
    "plt.colorbar(label='Value')\n",
    "plt.title(\"Heatmap via Pandas Pivot\")\n",
    "plt.xlabel(\"X coordinate\")\n",
    "plt.ylabel(\"Y coordinate\")\n",
    "\n",
    "plt.xticks(ticks=range(len(heatmap_df.columns)), labels=heatmap_df.columns, rotation=45, ha=\"right\")\n",
    "plt.yticks(ticks=range(len(heatmap_df.index)),   labels=heatmap_df.index)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "string title : the principle title of the page\n",
    "list headers: (txt, bbox, size, color) of all headers with side <title\n",
    "list paras: (txt, bbox, size, color) of all paras with highest size occurence\n",
    "list other: (txt, bbox, size, color)  of all the other chars, txt\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Solely based on color\n",
    "sorted_block_by_color = {key[0]: [] for key in sorted_blk_fonts}\n",
    "sorted_blocks_by_size = {key[0]: [] for key in sorted_blk_sizes}\n",
    "sorted_by_both = {(key[0][0],key[0][1]): [] for key in data} #sorted wrt color and size\n",
    "\n",
    "\n",
    "for blocks in SortedBlocks:\n",
    "    text = []\n",
    "    for spans in blocks['lines']:\n",
    "        txt = \" \".join(item['text'] for item in spans['spans'])\n",
    "        for span in spans['spans']:\n",
    "            color = span['color']\n",
    "            sorted_block_by_color[color].append(txt)\n",
    "            size = span['size']\n",
    "            sorted_blocks_by_size[size].append(txt)\n",
    "            \n",
    "            sorted_by_both[(color,size)].append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_block_by_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_blocks_by_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(-12684359, 24.0)\n",
      "\n",
      "Samco Active Momentum Fund\n",
      "\n",
      "(-12303035, 8.0)\n",
      "\n",
      "(An open-ended equity scheme following momentum theme)\n",
      "\n",
      "(-12220216, 6.0)\n",
      "\n",
      "exposure of\n",
      "\n",
      "(-1, 6.0)\n",
      "\n",
      "NAV as on 31  st October 2024 (· per unit)\n",
      "\n",
      "(-1, 10.0)\n",
      "\n",
      "3\n",
      "\n",
      "(-12220216, 8.0)\n",
      "\n",
      "Mr. Paras Matalia,\n",
      "\n",
      "Mr. Umeshkumar Mehta,\n",
      "\n",
      "Mr. Dhawal Ghanshyam Dhanani\n",
      "\n",
      "(-12368828, 6.0)\n",
      "\n",
      "(Date of Allotment)\n",
      "\n",
      "(With effect from October 03, 2024)\n",
      "\n",
      "as on October 31,\n",
      "\n",
      "2024\n",
      "\n",
      "Lower of sales or purchases divided by average AUM for last rolling 12 months\n",
      "\n",
      "(-1, 9.0)\n",
      "\n",
      "Investment Objective\n",
      "\n",
      "Portfolio as on October 31, 2024\n",
      "\n",
      "Scheme Details\n",
      "\n",
      "Fund Manager\n",
      "\n",
      "NAV as on 31  st October 2024 (· per unit)\n",
      "\n",
      "NAV as on 31  st October 2024 (· per unit)\n",
      "\n",
      "Quantitative Data\n",
      "\n",
      "Assets Under Management (AUM)\n",
      "\n",
      "(-12303035, 7.0)\n",
      "\n",
      "The investment objective of the Scheme is to seek to\n",
      "\n",
      "generate long-term capital appreciation by investing in\n",
      "\n",
      "stocks showing strong momentum. Momentum stocks are\n",
      "\n",
      "such that exhibit positive price momentum · based on the\n",
      "\n",
      "phenomenon that stocks which have performed well in the\n",
      "\n",
      "past relative to other stocks (winners) continue to perform\n",
      "\n",
      "well in the future, and stocks that have performed\n",
      "\n",
      "relatively poorly (losers) continue to perform poorly.\n",
      "\n",
      "However, there can be no assurance or guarantee that the\n",
      "\n",
      "investment objective of the scheme would be achieved.\n",
      "\n",
      "(-12368828, 7.0)\n",
      "\n",
      "Inception Date\n",
      "\n",
      "05-Jul-2023\n",
      "\n",
      "Nifty 500 TRI\n",
      "\n",
      "Benchmark\n",
      "\n",
      "·5000/- and in multiples of ·1/-\n",
      "\n",
      "thereafter\n",
      "\n",
      "Min.Application\n",
      "\n",
      "Amount\n",
      "\n",
      "Additional\n",
      "\n",
      "Purchase\n",
      "\n",
      "·500/- and in multiples of ·1/- thereafter\n",
      "\n",
      "Entry Load\n",
      "\n",
      "NIL\n",
      "\n",
      "1.00% If the investment is redeemed\n",
      "\n",
      "or switched out on or before 365 days\n",
      "\n",
      "from the date of allotment of units.\n",
      "\n",
      "Exit Load\n",
      "\n",
      ":\n",
      "\n",
      "No Exit Load will be charged if\n",
      "\n",
      "investment is redeemed or switched\n",
      "\n",
      "out after 365 days from the date of\n",
      "\n",
      "allotment of units.\n",
      "\n",
      "Total Expense\n",
      "\n",
      "Regular Plan\n",
      "\n",
      "Direct Plan\n",
      "\n",
      "Ratio (TER)\n",
      "\n",
      "0.86%\n",
      "\n",
      "2.26%\n",
      "\n",
      "Including Goods and Service Tax on\n",
      "\n",
      "Management Fees.\n",
      "\n",
      "Fund Manager & Head - Research Equity\n",
      "\n",
      "(Managing this scheme since inception)\n",
      "\n",
      "Total Experience: Around 9 years\n",
      "\n",
      "Director, CIO & Fund Manager\n",
      "\n",
      "(Managing the scheme since August 01, 2023)\n",
      "\n",
      "Total Experience: Over 20 years\n",
      "\n",
      "Total Experience: Around 6 years\n",
      "\n",
      "(Dedicated Fund Manager for Overseas investments since inception)\n",
      "\n",
      "Regular Growth\n",
      "\n",
      "·  14.53\n",
      "\n",
      "·  14.53\n",
      "\n",
      "Direct Growth\n",
      "\n",
      "·  14.81\n",
      "\n",
      "·  14.81\n",
      "\n",
      "Portfolio Turnover Ratio:\n",
      "\n",
      "5.11 times\n",
      "\n",
      "AUM as on October 31, 2024\n",
      "\n",
      "·  850.06 Crs\n",
      "\n",
      "·  850.06 Crs\n",
      "\n",
      "·  852.46 Crs\n",
      "\n",
      "·  852.46 Crs\n",
      "\n",
      "Average AUM for Month of October 2024\n"
     ]
    }
   ],
   "source": [
    "for item in sorted_by_both:\n",
    "    print(f\"\\n{item[0]}\")\n",
    "    for text in item[1]:\n",
    "        print(f\"\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPpaLsQz1x7bY/3Wt5A037y",
   "mount_file_id": "13CsgmhaDfqGoLm8aJEhgpfpDdRvQtgVH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

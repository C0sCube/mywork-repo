{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import camelot\n",
    "import warnings , math, collections\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "\n",
    "#path = r\"C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\"\n",
    "path = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\"\n",
    "\n",
    "\n",
    "pickle_path_text = r\"\\output\\pkl\\textual_data.pkl\"\n",
    "pickle_path_tab = r\"\\output\\pkl\\tabular_data.pkl\"\n",
    "samco_path = r\"\\files\\SamcoFactSheet2024.pdf\"\n",
    "tata_path = r\"\\files\\TataFactSheet2024.pdf\"\n",
    "dry_run_path = r\"\\output\\DryRun.pdf\"\n",
    "\n",
    "no_image_pkl = r\"\\output\\pkl\\sam\\nonimg_data.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + no_image_pkl , 'rb') as file:\n",
    "    document_data = pickle.load(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_data) #ignore first and last page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samco active momentum fund\n",
      "samco active momentum fund\n",
      "samco flexi cap fund\n",
      "samco flexi cap fund\n",
      "samco dynamic asset allocation fund\n",
      "samco dynamic asset allocation fund\n",
      "samco multi cap fund\n",
      "samco multi cap fund\n",
      "samco special opportunities fund\n",
      "samco special opportunities fund\n",
      "samco elss tax saver fund\n",
      "samco elss tax saver fund\n",
      "samco overnight fund\n",
      "samco dynamic asset allocation fund \n",
      "samco overnight fund\n",
      "samco elss tax saver fund \n"
     ]
    }
   ],
   "source": [
    "fonts = set()\n",
    "\n",
    "for page in document_data['blocks_data']:\n",
    "    sortedPage = sorted(page['blocks'], key= lambda k: (round(k['bbox'][1]), round(k['bbox'][0]))) #sort t to b, l to r\n",
    "    firstBlock = sortedPage[0] #get first block of sorted data\n",
    "    \n",
    "    if 'lines' in firstBlock:\n",
    "        for line in firstBlock['lines']:\n",
    "            for span in line['spans']:\n",
    "                text = span['text'].lower()\n",
    "                font = span['font']\n",
    "                fonts.add(font)\n",
    "                \n",
    "                #regex condition\n",
    "                cond1 = re.findall('^samco|^tata|fund$', text)\n",
    "                if cond1:\n",
    "                    print(text)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extract and sort lines for a two-column layout, returning all data associated with each line without duplicates.\n",
    "    Args:data (list): The raw extracted data from Fitz.\n",
    "        split_x_coord (float): The x-coordinate dividing the left and right columns.\n",
    "    Returns:list: Sorted list of all unique line data in reading order (top-to-bottom, left-to-right).\n",
    "    \"\"\"\n",
    "def sort_data_blocks(data, split_x_coord):\n",
    "    # Separate lines into left and right columns\n",
    "    left_column = []\n",
    "    right_column = []\n",
    "\n",
    "    for item in data:\n",
    "        for line in item.get('lines', []):\n",
    "            bbox = line.get('bbox', None)\n",
    "            spans = line.get('spans', [])\n",
    "            if bbox and spans:\n",
    "                # Classify line based on its x-coordinate\n",
    "                block = {'bbox': bbox, 'spans': spans, 'line': line}\n",
    "                if bbox[0] < split_x_coord:  # Left column\n",
    "                    left_column.append(block)\n",
    "                else:  # Right column\n",
    "                    right_column.append(block)\n",
    "\n",
    "    # Sort lines within each column\n",
    "    left_column.sort(key=lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "    right_column.sort(key=lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "\n",
    "    return left_column, right_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right = sort_data_blocks(document_data['blocks_data'][17]['blocks'], 173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_keys(data, keys_to_remove):\n",
    "    \"\"\"Recursively remove specific keys from nested dictionaries or lists.\n",
    "    Args:data (dict | list): The input data (nested structure of dictionaries and lists).\n",
    "        keys_to_remove (set): Keys to be removed from the dictionaries.\n",
    "    Returns:dict | list: Data with specified keys removed.\"\"\"\n",
    "    if isinstance(data, list):\n",
    "        # Process each element in the list\n",
    "        return [remove_keys(item, keys_to_remove) for item in data]\n",
    "    elif isinstance(data, dict):\n",
    "        # Process each key-value pair in the dictionary\n",
    "        return {key: remove_keys(value, keys_to_remove) for key, value in data.items() if key not in keys_to_remove}\n",
    "    else:\n",
    "        # Return data as is if it's neither a dict nor a list\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in left:\n",
    "    del line['spans']\n",
    "    \n",
    "keys_to_remove = {'bbox','wmode', 'ascender', 'descender',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_keys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cleaned_data \u001b[38;5;241m=\u001b[39m \u001b[43mremove_keys\u001b[49m(left, keys_to_remove)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'remove_keys' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned_data = remove_keys(left, keys_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m content_max_font \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8.0\u001b[39m  \u001b[38;5;66;03m# Example maximum content font size\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Call the function with your data\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m result \u001b[38;5;241m=\u001b[39m create_matrix_structure(\u001b[43mcleaned_data\u001b[49m[\u001b[38;5;241m0\u001b[39m], title_font, subheader_font, content_max_font)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaned_data' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Create a nested dictionary structure using a matrix-based approach.\n",
    "    Args:\n",
    "        data (list): List of text blocks, each containing font size, text, and bbox.\n",
    "        title_font (float): Font size for titles.\n",
    "        subheader_font (float): Font size for subheaders.\n",
    "        content_max_font (float): Maximum font size for content.\n",
    "    Returns:\n",
    "        dict: A nested dictionary structure with titles, subheaders, and content.\n",
    "    \"\"\"\n",
    "    \n",
    "def create_matrix_structure(data, title_font, subheader_font, content_max_font):\n",
    "\n",
    "    # Step 1: Extract all unique coordinates\n",
    "    coordinates = []\n",
    "    fonts = set()\n",
    "    for block in data:\n",
    "        for span in block['line']['spans']:\n",
    "            bbox = block['line'].get('bbox', (0, 0, 0, 0))\n",
    "            coordinates.append((bbox[0], bbox[1]))  # x, y from bbox\n",
    "            fonts.add(span['size'])\n",
    "\n",
    "    coordinates = sorted(set(coordinates), key=lambda c: (c[1], c[0]))  # Sort by y, then x\n",
    "    fonts = sorted(fonts)\n",
    "\n",
    "    # Step 2: Initialize the matrix\n",
    "    coord_to_index = {coord: idx for idx, coord in enumerate(coordinates)}\n",
    "    font_to_index = {font: idx for idx, font in enumerate(fonts)}\n",
    "    matrix = np.zeros((len(coordinates), len(fonts)), dtype=object)\n",
    "\n",
    "    # Step 3: Fill the matrix\n",
    "    for block in data:\n",
    "        for span in block['line']['spans']:\n",
    "            bbox = block['line'].get('bbox', (0, 0, 0, 0))\n",
    "            coord = (bbox[0], bbox[1])\n",
    "            font = span['size']\n",
    "            if coord in coord_to_index and font in font_to_index:\n",
    "                row = coord_to_index[coord]\n",
    "                col = font_to_index[font]\n",
    "                if matrix[row, col] == 0:\n",
    "                    matrix[row, col] = []\n",
    "                matrix[row, col].append(span['text'])\n",
    "\n",
    "    # Step 4: Generate the nested dictionary\n",
    "    nested_dict = {}\n",
    "    current_title = None\n",
    "    current_subheader = None\n",
    "\n",
    "    for row_idx, coord in enumerate(coordinates):\n",
    "        for col_idx, font in enumerate(fonts):\n",
    "            if matrix[row_idx, col_idx] != 0:\n",
    "                text = \" \".join(matrix[row_idx, col_idx])\n",
    "\n",
    "                if font == title_font:\n",
    "                    current_title = text\n",
    "                    nested_dict[current_title] = {}\n",
    "                elif font == subheader_font and current_title:\n",
    "                    current_subheader = text\n",
    "                    nested_dict[current_title][current_subheader] = []\n",
    "                elif font <= content_max_font and current_subheader:\n",
    "                    nested_dict[current_title][current_subheader].append(text)\n",
    "\n",
    "    return nested_dict\n",
    "\n",
    "\n",
    "# Example usage\n",
    "title_font = 24.0  # Example title font size\n",
    "subheader_font = 9.0  # Example subheader font size\n",
    "content_max_font = 8.0  # Example maximum content font size\n",
    "\n",
    "# Call the function with your data\n",
    "result = create_matrix_structure(left, title_font, subheader_font, content_max_font)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result\n",
    "import pprint\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

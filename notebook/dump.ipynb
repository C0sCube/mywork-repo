{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, logging, os, sys, json\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_generic_data(self, main_key: str, data: list, pattern: str):\n",
    "    final_dict = {}\n",
    "    for text in data:\n",
    "        text = re.sub(self.REGEX['escape'], \"\", text.strip())\n",
    "        matches = re.findall(self.REGEX[pattern], text, re.IGNORECASE)\n",
    "        for key, value in matches:\n",
    "            final_dict[key] = value\n",
    "    return {main_key: final_dict}\n",
    "\n",
    "def _extract_str_data(self, key: str, data: list):\n",
    "    return {key: ' '.join(data)}\n",
    "\n",
    "def _extract_manager_data(self, main_key: str, data: list, pattern:str):\n",
    "    final_list = []\n",
    "    for i in range(0, len(data), 3):\n",
    "        txt = \" \".join(data[i:i+3])\n",
    "        txt = re.sub(self.REGEX['escape'], \"\", txt).strip()\n",
    "        if matches := re.findall(self.REGEX[pattern], txt, re.IGNORECASE):\n",
    "            for match in matches:\n",
    "                name, desig, since, exp = match\n",
    "                final_list.append({\n",
    "                    \"name\": name,\n",
    "                    \"designation\": desig,\n",
    "                    \"managing_since\": since,\n",
    "                    \"experience\": exp\n",
    "                })\n",
    "    return {main_key: final_list}\n",
    "\n",
    "def _extract_dum_data(self, key, data):\n",
    "    return {key: data}\n",
    "\n",
    "def _extract_scheme_data(self,main_key:str,data:list, pattern:str):\n",
    "    regex_ = self.REGEX[pattern] #list\n",
    "    mention_start = regex_[:-1]\n",
    "    mention_end = regex_[1:]\n",
    "\n",
    "    patterns = [r\"({start})\\s*(.+?)\\s*({end}|$)\".format(start=start, end=end)\n",
    "        for start, end in zip(mention_start, mention_end)]\n",
    "    \n",
    "    final_dict = {}\n",
    "    scheme_data = \" \".join(data)\n",
    "    for pattern in patterns:\n",
    "        if matches:= re.findall(pattern, scheme_data, re.DOTALL|re.IGNORECASE):\n",
    "            for match in matches:\n",
    "                key, value, dummy = match\n",
    "                value = value.strip()\n",
    "                final_dict[key] = value\n",
    "    \n",
    "    return {main_key:final_dict}\n",
    "\n",
    "def match_regex_to_content(self, string: str, data: list, *args):\n",
    "    for pattern, (func_name, regex_key) in self.PATTERN_TO_FUNCTION.items():\n",
    "        if re.match(pattern, string, re.IGNORECASE):\n",
    "            func = getattr(self, func_name)\n",
    "            if regex_key:\n",
    "                return func(string, data, regex_key)\n",
    "            return func(string, data)\n",
    "    return self._extract_dum_data(string, data)\n",
    "\n",
    "def _extract_load_data(self,main_key:str,data:list, pattern:str):\n",
    "        load_data = \" \".join(data)\n",
    "        load_data = re.sub(r\"[\\^*\\$:;~]\",\"\",load_data).strip()\n",
    "        final_dict = {}\n",
    "        if match:= re.findall(self.REGEX[pattern],load_data.strip(), re.IGNORECASE):\n",
    "            exit_,entry_ = match[0]\n",
    "            final_dict['entry_load'] = entry_,\n",
    "            final_dict['exit_load'] = exit_\n",
    "        return {main_key:final_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(?:Entry Load)?\\s*(Nil|.*?)\\s*Exit Load\\s*(.*)$'\n",
    "for fund, content in final_text.items():\n",
    "    check = 'scheme_details.load_structure'\n",
    "    if check in content:\n",
    "        text =re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+', \"\",content[check]).strip()\n",
    "        print(text)\n",
    "        match = re.findall(pattern,text, re.IGNORECASE)\n",
    "        print(match)\n",
    "        \n",
    "pattern = r'(AUM|Monthly Average AUM)\\s*([\\d,.]+)'\n",
    "for fund, content in final_text.items():\n",
    "    check = 'aum'\n",
    "    if check in content:\n",
    "        for text in  content[check]:\n",
    "            text =re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+', \"\",text).strip()\n",
    "            print(text)\n",
    "            match = re.findall(pattern,text, re.IGNORECASE)\n",
    "            print(match)\n",
    "            \n",
    "pattern = r'(?:Entry Load)?\\s*(Nil|.*?)\\s*Exit Load\\s*(.*)$'\n",
    "for fund, content in final_text.items():\n",
    "    check = 'scheme_details.load_structure'\n",
    "    if check in content:\n",
    "        all_text = \" \".join(content[check])\n",
    "        all_text =re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+', \"\", all_text).strip()\n",
    "        print(all_text)\n",
    "        print(re.findall(pattern,all_text, re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_amt = \"([\\\\d,]+).*?([\\\\d,]+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_start = [\n",
    "        \"Date of Allotment\",\n",
    "        \"Fund Manager\",\n",
    "        \"Fund Size\",\n",
    "        \"Load Structure\",\n",
    "        \"Benchmark\",\n",
    "        \"Minimum Additional\",\n",
    "        r\"Minimum Redemption\\s*\\/\\s*Switch-out Amount\",\n",
    "    ]\n",
    "    \n",
    "mention_end = mention_start[1:] + [\"End_of_Data\"]\n",
    "\n",
    "# Generate regex patterns dynamically\n",
    "patterns = [r\"({start}\\s*)(.+?)({end}|$)\".format(start=start, end=end)\n",
    "    for start, end in zip(mention_start, mention_end)]\n",
    "final_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_keys(json_files):\n",
    "    unique_keys = set()  # Store unique keys\n",
    "\n",
    "    for file in json_files:\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "                for fund_name, fund_data in data.items():\n",
    "                    if isinstance(fund_data, dict):\n",
    "                        extract_keys(fund_data, unique_keys)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    return unique_keys\n",
    "\n",
    "def extract_keys(data, key_set):\n",
    "    \"\"\"Recursively extract keys from JSON data.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            key_set.add(\"_\".join(key.lower().split(\" \")))\n",
    "            extract_keys(value, key_set)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            extract_keys(item, key_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\"  # Update this to your folder path\n",
    "json_files = [os.path.join(json_folder, file) for file in os.listdir(json_folder) if file.endswith('.json')]\n",
    "unique_keys = get_unique_keys(json_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, pprint\n",
    "from app.pdfParse import Reader\n",
    "from app.fundRegex import FundRegex\n",
    "import fitz\n",
    "\n",
    "class FranklinTempleton(Reader):\n",
    "    PARAMS = {\n",
    "        'fund': [[25,20],r\"^(Franklin|Templeton).*$\",[16,24],[-65794]], #[flag], regex_fund_name, range(font_size), [font_color]\n",
    "        'clip_bbox': [(0,100,180,812)],\n",
    "        'line_x': 180.0,\n",
    "        'data': [[6,9],[-16751720],30.0,['ZurichBT-BoldCondensed']], #sizes, color, set_size font_name\n",
    "        'content_size':[30.0,10.0]\n",
    "    }\n",
    "    \n",
    "    REGEX = {\n",
    "        'nav': r'(Growth Plan|IDCW Plan|Direct Growth Plan|Direct IDCW Plan)\\s*([\\d\\-,]+\\.\\d+)',\n",
    "        'metric': r'(Sharpe Ratio|Standard Deviation|Beta|Annualised)[\\s]+([\\d\\-,]+\\.\\d+)',\n",
    "        'expense': r'(Regular|Direct)\\s*([\\d,.-]+)',\n",
    "        'load': r'ENTRY LOA(.*?)\\s*EXIT LOAD\\s*(.*?)$',\n",
    "        'aum': r'(Month End|Monthly Average)\\s*([\\d,.\\-]+)',\n",
    "        'ptr':r'^(Portfolio Turnover|Total Portfolio).*\\s*([\\d\\-,]+\\.\\d+)',\n",
    "        # 'manager': r'([A-Za-z\\s]+)\\s*\\(Managing Since\\s*([A-Za-z0-9\\s]+) and overall experience of ([a-z0-9\\s]+)\\)',\n",
    "        'escape': r'[^A-Za-z0-9\\s\\-\\(\\).,]+'\n",
    "    }\n",
    "\n",
    "    PATTERN_TO_FUNCTION = {\n",
    "        r\"^(date|benchmark|investment|type_of|scheme|multiples|minimum).*\":(\"_extract_str_data\", None),\n",
    "        r\"^nav.*\":(\"_extract_generic_data\", \"nav\"),\n",
    "        # r\"^fund_mana.*\": self.__extract_manager_data,\n",
    "        r\"^aum.*\": (\"_extract_generic_data\", 'aum'),\n",
    "        r\"^portfolio_turnover_ratio\": (\"_extract_generic_data\", 'ptr'),\n",
    "        r\"^load\": (\"_extract_load_data\", 'load'),\n",
    "        r\"^metrics\": (\"_extract_generic_data\", \"metric\"),\n",
    "    }\n",
    "\n",
    "    def __init__(self, paths_config: str):\n",
    "        super().__init__(paths_config, self.PARAMS)\n",
    "    \n",
    "    def _extract_str_data(self, key: str, data: list):\n",
    "        return {key: ' '.join(data)}\n",
    "    \n",
    "    def _extract_dummy_data(self, main_key:str, data:list):\n",
    "        return{main_key:data}\n",
    "    \n",
    "    def _extract_generic_data(self, main_key: str, data: list, pattern: str):\n",
    "        final_dict = {}\n",
    "        for text in data:\n",
    "            text = re.sub(self.REGEX['escape'], \"\", text.strip())\n",
    "            matches = re.findall(self.REGEX[pattern], text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                if len(match) == 2:\n",
    "                    key, value = match\n",
    "                    final_dict[key.strip()] = value.strip()\n",
    "                elif len(match) == 3:\n",
    "                    key,v1,v2 = match\n",
    "                    final_dict[key.strip()] = v1.strip()\n",
    "        return {main_key: final_dict}\n",
    "    \n",
    "    def _extract_manager_data(self, main_key: str, data: list, pattern:str):\n",
    "        manager_data = \" \".join(data)\n",
    "        manager_data = re.sub(self.REGEX[pattern], \"\", manager_data).strip()\n",
    "        final_list = []\n",
    "        if matches := re.findall(self.REGEX['manager'], manager_data, re.IGNORECASE):\n",
    "            for match in matches:\n",
    "                name, since, exp = match\n",
    "                final_list.append({\n",
    "                    \"name\": name.strip(),\n",
    "                    \"designation\": \"\",\n",
    "                    \"managing_since\": since.strip(),\n",
    "                    \"experience\": exp.strip()\n",
    "                })\n",
    "        return {main_key: final_list}\n",
    "    \n",
    "    def _extract_load_data(self,main_key:str,data:list, pattern:str):\n",
    "        load_data = \" \".join(data)\n",
    "        load_data = re.sub(self.REGEX['escape'], \"\", load_data).strip()\n",
    "        final_dict = {}\n",
    "        if match:= re.findall(self.REGEX[pattern],load_data.strip(), re.IGNORECASE):\n",
    "            exit_,entry_ = match[0]\n",
    "            final_dict['entry_load'] = entry_,\n",
    "            final_dict['exit_load'] = exit_\n",
    "        return {main_key:final_dict}\n",
    "        \n",
    "    \n",
    "    def match_regex_to_content(self, string: str, data: list, *args):\n",
    "        for pattern, (func_name, regex_key) in self.PATTERN_TO_FUNCTION.items():\n",
    "            if re.match(pattern, string, re.IGNORECASE):\n",
    "                func = getattr(self, func_name)\n",
    "                if regex_key and regex_key in self.REGEX:\n",
    "                    return func(string, data, regex_key)\n",
    "                return func(string, data)\n",
    "        return self._extract_dummy_data(string, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT CODE DONT DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\" thissssssssssssssssssssssss\"\"\"\n",
    "class HSBC(Reader):\n",
    "    \n",
    "    PARAMS = {\n",
    "        'fund': [[20,16], r'^(HSBC|Bharat).*Fund$',[12,20],[-1237724]],\n",
    "        'clip_bbox': [(0,100,180,812)],\n",
    "        'line_x': 180.0,\n",
    "        'data': [[6,8], [-16777216], 30.0, ['Arial-BoldMT']],\n",
    "        'content_size':[30.0,10.0]\n",
    "    }\n",
    "    \n",
    "    def __init__(self,paths_config:str):\n",
    "        super().__init__(paths_config, self.PARAMS)\n",
    "        \n",
    "    #Fund REGEX\n",
    "    def __return_all_data(self,key,data:list):\n",
    "        return {key:data}\n",
    "    \n",
    "    def __extract_inv_data(self,key:str, data:list):            \n",
    "        return {key: ' '.join(data)}\n",
    "    \n",
    "    #MAPPING\n",
    "    def match_regex_to_content(self, string:str, data:list):\n",
    "        check_header = string\n",
    "        if re.match(r\"^(investment).*\", check_header, re.IGNORECASE):\n",
    "            return self.__extract_inv_data(string,data)\n",
    "        # elif re.match(r\"^total.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_total_expense_data(string, data)\n",
    "        # elif re.match(r\"^nav.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_nav_data(string, data)\n",
    "        # elif re.match(r\"^portfolio.*\", check_header, re.IGNORECASE): #error here portfolio is read\n",
    "        #     return self.__extract_scheme_data(string, data)\n",
    "        return self.__return_all_data(string,data)     \n",
    "\n",
    "\n",
    "class PPFAIS(Reader):\n",
    "    PARAMS = {\n",
    "        'fund': [[16,20], r'^(Parag).*',[14,24],[-16777216,-13159371,-14869475]],\n",
    "        'clip_bbox': [(0,65,290,812)],\n",
    "        'line_x': 290.0,\n",
    "        'data': [[6,10], [-65794], 30.0, ['Arial-BoldMT',]]\n",
    "        }\n",
    "    \n",
    "    def __init__(self, paths_config:str):\n",
    "        super().__init__(paths_config,self.PARAMS)\n",
    "        \n",
    "    #REGEX\n",
    "    def __return_all_data(self,main_key,data:list):\n",
    "        return {main_key:data}\n",
    "    \n",
    "    def __extract_inv_data(self,main_key:str, data:list):            \n",
    "        return {main_key: ' '.join(data)}\n",
    "    \n",
    "    #MAPPING\n",
    "    def match_regex_to_content(self, string: str, data: list):\n",
    "        pattern_to_function = {\n",
    "            r\"^investment.*\": self.__extract_inv_data,\n",
    "            # r\"^scheme.*\": self.__extract_scheme_data,\n",
    "            # r\"^metrics.*\": self.__extract_metric_data,\n",
    "        }\n",
    "\n",
    "        for pattern, func in pattern_to_function.items():\n",
    "            if re.match(pattern, string, re.IGNORECASE):\n",
    "                return func(string, data)\n",
    "\n",
    "        return self.__return_all_data(string, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first\n",
    "final_dic = {\n",
    "    \"metadata\": [],\n",
    "    \"records\": []\n",
    "}\n",
    "\n",
    "#second\n",
    "meta_data = {\n",
    "    \"document_name\": \"\",\n",
    "    \"file_type\": \"\",\n",
    "    \"process_date\": \"\"\n",
    "}\n",
    "record = {\n",
    "            \"amc_name\": \"\",\n",
    "            \"benchmark_index\":[],\n",
    "            \"field_location\": [],\n",
    "            \"fund_manager\": [],\n",
    "            \"load\": [],\n",
    "            \"main_scheme_name\": \"\",\n",
    "            \"metrics\": [],\n",
    "            \"min_addl_amt\": \"\",\n",
    "            \"min_addl_multiple\":\"\",\n",
    "            \"min_amt\":\"\",\n",
    "            \"monthly_aaum_date\":\"\",\n",
    "            \"monthly_aaum_value\":\"\",\n",
    "            \"mutual_fund_name\": \"\",\n",
    "            \"scheme_launch_date\":\"\"\n",
    "            \n",
    "        }\n",
    "\n",
    "#third  \n",
    "fund_manager = {\n",
    "    \"managing_fund_since\":\"\",\n",
    "    \"name\": \"\",\n",
    "    \"qualification\": \"\",\n",
    "    \"total_exp\": \"\"\n",
    "}\n",
    "load = {\n",
    "    \"type\": \"\",\n",
    "    \"comment\": \"\"\n",
    "}   \n",
    "metrics= {\n",
    "    \"name\":\"\",\n",
    "    \"value\":\"\"\n",
    "}    \n",
    "field_location = {\n",
    "    \"amc_name\": \"\",\n",
    "    \"benchmark_index\": \"\",\n",
    "    \"count\": 0,\n",
    "    \"fund_manager_managing_fund_since\": \"\",\n",
    "    \"fund_manager_name\": \"\",\n",
    "    \"fund_manager_total_exp\": \"\",\n",
    "    \"load_entry\": \"\",\n",
    "    \"load_exit\": \"\",\n",
    "    \"main_scheme_name\": \"\",\n",
    "    \"metrics_beta\": \"\",\n",
    "    \"metrics_port_turnover_ratio\": \"\",\n",
    "    \"metrics_r_squared_ratio\": \"\",\n",
    "    \"metrics_sharpe\": \"\",\n",
    "    \"metrics_std_dev\": \"\",\n",
    "    \"metrics_treynor_ratio\": \"\",\n",
    "    \"min_addl_amt\": \"\",\n",
    "    \"min_addl_amt_multiple\": \"\",\n",
    "    \"min_amt\": \"\",\n",
    "    \"min_amt_multiple\": \"\",\n",
    "    \"monthly_aaum_date\": \"\",\n",
    "    \"monthly_aaum_value\": \"\",\n",
    "    \"mutual_fund_name\": \"\",\n",
    "    \"scheme_launch_date\": \"\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aditya Birla Sun Life Mutual Fund\n",
    "# Kotak Mahindra Mutual Fund\n",
    "# Shriram Mutual fund\n",
    "# PPFAS Mutual Fund\n",
    "# ITI Mutual Fund\n",
    "# PGIM India Mutual Fund\n",
    "# BajaJ Finserv Mutual Fund\n",
    "# Union Mutual Fund\n",
    "# Sundaram Mutual Fund\n",
    "# NJ Mutual Fund\n",
    "# Samco Mutual Fund\n",
    "# Bank of India Mutual Fund\n",
    "# DSP Mutual Fund\n",
    "# Edelweiss Mutual Fund\n",
    "# Invesco Mutual Fund\n",
    "# Helios Mutual Fund\n",
    "# Groww Mutual Fund\n",
    "# Nippon India Mutual Fund\n",
    "# Quantum Mutual Fund\n",
    "# Franklin Templeton Mutual Fund\n",
    "# Bandhan Mutual Fund\n",
    "# IL&FS Mutual Fund (IDF)\n",
    "# Tata Mutual Fund\n",
    "# Mirae Asset Mutual Fund\n",
    "# Motilal Oswal Mutual Fund\n",
    "# Old Bridge Mutual Fund\n",
    "# 360 ONE Mutual Fund\n",
    "# LIC Mutual Fund\n",
    "# Mahindra Manulife Mutual Fund\n",
    "# WhiteOak Mutual Fund\n",
    "# Navi Mutual Fund\n",
    "# Baroda BNP Paribas Mutual Fund\n",
    "# SBI Mutual Fund\n",
    "# Taurus Mutual Fund\n",
    "# JM Financial Mutual Fund\n",
    "# Trust Mutual Fund\n",
    "# Zerodha Mutual Fund\n",
    "# ICICI Prudential Mutual Fund\n",
    "# Quant Mutual Fund\n",
    "# Axis Mutual Fund\n",
    "# Canara Robeco Mutual Fund\n",
    "# HDFC Mutual Fund\n",
    "# HSBC Mutual Fund\n",
    "# UTI Mutual Fund\n",
    "# Angel One Mutual Fund\n",
    "# Unifi Mutual Fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axis Asset Management Company Limited\n",
    "# Aditya Birla Sun Life AMC Limited\n",
    "# Bank of India Investment Managers Private Limited\n",
    "# Canara Robeco Asset Management Company Limited\n",
    "# PGIM India Asset Management Private Limited\n",
    "# DSP Investment Managers Private Limited\n",
    "# Edelweiss Asset Management Limited\n",
    "# Quant Money Managers Limited\n",
    "# Franklin Templeton Asset Management (India) Private Limited\n",
    "# HDFC Asset Management Company Limited\n",
    "# HSBC Asset Management (India) Private Limited\n",
    "# ICICI Prudential Asset Management Company Limited\n",
    "# Bandhan AMC Limited\n",
    "# 360 ONE Asset Management Limited\n",
    "# IL&FS Infra Asset Management Limited\n",
    "# Groww Asset Management Limited\n",
    "# Invesco Asset Management (India) Private Limited\n",
    "# JM Financial Asset Management Limited\n",
    "# Kotak Mahindra Asset Management Company Limited(KMAMCL)\n",
    "# LIC Mutual Fund Asset Management Limited\n",
    "# Mahindra Manulife Investment Management Private Limited\n",
    "# Mirae Asset Investment Managers (India) Private Limited\n",
    "# Motilal Oswal Asset Management Company Limited\n",
    "# PPFAS Asset Management Private Limited\n",
    "# Quantum Asset Management Company Private Limited\n",
    "# Nippon Life India Asset Management Limited\n",
    "# SBI Funds Management Limited\n",
    "# Shriram Asset Management Company Limited\n",
    "# Sundaram Asset Management Company Limited\n",
    "# Tata Asset Management Private Limited\n",
    "# Taurus Asset Management Company Limited\n",
    "# Union Asset Management Company Private Limited\n",
    "# UTI Asset Management Company Limited\n",
    "# WhiteOak Capital Asset Management Limited\n",
    "# ITI Asset Management Limited\n",
    "# Navi AMC Limited\n",
    "# NJ Asset Management Private Limited\n",
    "# Samco Asset Management Private Limited\n",
    "# Trust Asset Management Private Limited\n",
    "# Baroda BNP Paribas Asset Management India Private Limited\n",
    "# Bajaj Finserv Asset Management Limited\n",
    "# Helios Capital Asset Management (India) Private Limited\n",
    "# Zerodha Asset Management Private Limited\n",
    "# Old Bridge Asset Management Private Limited\n",
    "# Angel One Asset Management Company Limited\n",
    "# Unifi Asset Management Private Limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_date_data(self,main_key:str,data):\n",
    "    dates = {\n",
    "        'pgim india large cap fund': '30/01/2003|01/01/2013',\n",
    "        'pgim india flexi cap fund': '04/08/2015|04/03/2015',\n",
    "        'pgim india large and mid cap fund': '12/02/2024|12/02/2024',\n",
    "        'pgim india multicap fund': '10/09/2024|10/09/2024',\n",
    "        'pgim india midcap opportunities fund': '02/12/2013|02/12/2013',\n",
    "        'pgim india small cap fund': ' 29/07/2021| 29/07/2021',\n",
    "        'pgim india t elss tax saver fund': '11/12/2015|11/12/2015',\n",
    "        'pgim india healthcare fund': '06/12/2024|06/12/2024',\n",
    "        'pgim india retirement fund': '15/04/2024|15/04/2024',\n",
    "        'pgim india emerging markets equity fund': '11/09/2007|01/01/2013',\n",
    "        'pgim india global equity opportunities fund': '14/05/2010|01/01/2013',\n",
    "        'pgim india global select real estate securities fund of fund': '03/12/2021|03/12/2021',\n",
    "        'pgim india hybrid equity fund': '05/02/2004| 01/01/2013',\n",
    "        'pgim india d arbitrage fund': '27/08/2014|27/08/2014',\n",
    "        'pgim india d equity savings fund': '05/02/2004|01/01/2013',\n",
    "        'pgim india balanced advantage fund': '04/02/2021|04/02/2021',\n",
    "        'pgim india overnight fund': '27/08/2019|27/08/2019',\n",
    "        'pgim india liquid fund': ': 05/09/2007|01/01/2013',\n",
    "        'pgim india ultra short duration fun': '14/07/2008|01/01/2013',\n",
    "        'pgim india money market fund': '06/03/2020|06/03/2020',\n",
    "        'pgim india t dynamic bond fund': '12/01/2012|01/01/2013',\n",
    "        'pgim india corporate bond fund': '30/01/2003| 01/01/2013 ',\n",
    "        'pgim india gilt fund': '27/10/2008|01/01/2013',\n",
    "        'pgim india crisil ibx gilt index - apr 2028 fund': '22/02/2023|22/02/2023'\n",
    "    }\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finkstein\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"1234\",\n",
    "    database=\"cog_updated_db\"\n",
    ")\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"172.22.225.155\",\n",
    "    user=\"cog_mf\",\n",
    "    password=\"bnYwFChjLAV2Z%9E\",\n",
    "    database=\"cog_mf\",\n",
    "    port=3306,\n",
    "    charset='utf8mb4'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def get_or_create_amc(amc_name):\n",
    "    cursor.execute(\"SELECT id FROM mf_amcs WHERE amc_name = %s\", (amc_name,))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        return result[0]\n",
    "    cursor.execute(\"INSERT INTO mf_amcs (amc_name) VALUES (%s)\", (amc_name,))\n",
    "    conn.commit()\n",
    "    return cursor.lastrowid\n",
    "\n",
    "def insert_mutual_fund(cursor, amc_id, details, curr_time, amc_month,data_from):\n",
    "    keys = [\"amc_id\", \"entered_time\", \"amc_for_month\",\"data_from\", \"amc_name\", \"benchmark_index\",\n",
    "            \"main_scheme_name\", \"mutual_fund_name\", \"monthly_aaum_date\", \"monthly_aaum_value\",\n",
    "            \"scheme_launch_date\", \"min_addl_amt\", \"min_addl_amt_multiple\", \"min_amt\", \"min_amt_multiple\"]\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        INSERT INTO mf_mutual_funds ({', '.join(keys)})\n",
    "        VALUES ({', '.join(['%s'] * len(keys))})\n",
    "    \"\"\"\n",
    "\n",
    "    values = [\n",
    "        amc_id, curr_time, amc_month,data_from, details.get(\"amc_name\", \"\"),\n",
    "        \", \".join(details.get(\"benchmark_index\", [])),\n",
    "        details.get(\"main_scheme_name\", \"\"),\n",
    "        details.get(\"mutual_fund_name\", \"\"),\n",
    "        details.get(\"monthly_aaum_date\", \"\"),\n",
    "        details.get(\"monthly_aaum_value\", \"\"),\n",
    "        details.get(\"scheme_launch_date\", \"\"),\n",
    "        details.get(\"min_addl_amt\", \"\"),\n",
    "        details.get(\"min_addl_amt_multiple\", \"\"),\n",
    "        details.get(\"min_amt\", \"\"),\n",
    "        details.get(\"min_amt_multiple\", \"\")\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        cursor.execute(query, values)\n",
    "    except Exception as e:\n",
    "        print(\"Error inserting mutual fund:\")\n",
    "        print(\"Scheme Name:\", details.get(\"main_scheme_name\"))\n",
    "        print(\"Query:\", query)\n",
    "        print(\"Values:\", values)\n",
    "        print(\"Exception:\", e)\n",
    "        return None\n",
    "    return cursor.lastrowid\n",
    "\n",
    "def insert_fund_managers(cursor, amc_id, entered_time, amc_for_month, data_from, mutual_fund_id, details):\n",
    "    if not isinstance(details.get(\"fund_manager\"), list):\n",
    "        return\n",
    "    for manager in details[\"fund_manager\"]:\n",
    "        query = \"\"\"\n",
    "            INSERT INTO mf_fund_managers\n",
    "            (amc_id, entered_time, amc_for_month, data_from, mutual_fund_id, main_scheme_name, name, qualification, managing_fund_since, total_exp)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        values = [\n",
    "            amc_id,\n",
    "            entered_time,\n",
    "            amc_for_month,\n",
    "            data_from,\n",
    "            mutual_fund_id,\n",
    "            details[\"main_scheme_name\"],\n",
    "            manager.get(\"name\", \"\"),\n",
    "            manager.get(\"qualification\", \"\"),\n",
    "            manager.get(\"managing_fund_since\", \"\"),\n",
    "            manager.get(\"total_exp\", \"\")\n",
    "        ]\n",
    "        try:\n",
    "            cursor.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Manager: {e}\")\n",
    "\n",
    "def insert_load(cursor, amc_id, mutual_fund_id, details):\n",
    "    entry_load = exit_load = \"\"\n",
    "    for item in details.get(\"load\", []):\n",
    "        if item.get(\"type\") == \"entry\":\n",
    "            entry_load = item.get(\"comment\", \"\")\n",
    "        elif item.get(\"type\") == \"exit\":\n",
    "            exit_load = item.get(\"comment\", \"\")\n",
    "\n",
    "    query = \"\"\"\n",
    "        INSERT INTO mf_transformed_loads\n",
    "        (amc_id, mutual_fund_id, main_scheme_name, entry_load, exit_load)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    values = [\n",
    "        amc_id,\n",
    "        mutual_fund_id,\n",
    "        details.get(\"main_scheme_name\", \"\"),\n",
    "        entry_load,\n",
    "        exit_load\n",
    "    ]\n",
    "    cursor.execute(query, values)\n",
    "\n",
    "def insert_metrics(cursor, amc_id, mutual_fund_id, details):\n",
    "    metric_template = {\n",
    "        \"alpha\": \"\", \"arithmetic_mean_ratio\": \"\", \"average_div_yld\": \"\", \"average_pb\": \"\", \"average_pe\": \"\",\n",
    "        \"avg_maturity\": \"\", \"beta\": \"\", \"correlation_ratio\": \"\", \"downside_deviation\": \"\", \"information_ratio\": \"\",\n",
    "        \"macaulay\": \"\", \"mod_duration\": \"\", \"port_turnover_ratio\": \"\", \"r_squared_ratio\": \"\", \"roe_ratio\": \"\",\n",
    "        \"sharpe\": \"\", \"sortino_ratio\": \"\", \"std_dev\": \"\", \"tracking_error\": \"\", \"treynor_ratio\": \"\",\n",
    "        \"upside_deviation\": \"\", \"ytm\": \"\"\n",
    "    }\n",
    "\n",
    "    for metric in details.get(\"metrics\", []):\n",
    "        metric_name = metric.get(\"name\")\n",
    "        if metric_name in metric_template:\n",
    "            metric_template[metric_name] = metric.get(\"value\", \"\")\n",
    "\n",
    "    keys = [\"amc_id\", \"main_scheme_name\", \"mutual_fund_id\"] + list(metric_template.keys())\n",
    "    query = f\"\"\"\n",
    "        INSERT INTO mf_transformed_metrics\n",
    "        ({', '.join(keys)})\n",
    "        VALUES ({', '.join(['%s'] * len(keys))})\n",
    "    \"\"\"\n",
    "    values = [\n",
    "        amc_id,\n",
    "        details.get(\"main_scheme_name\", \"\"),\n",
    "        mutual_fund_id\n",
    "    ] + list(metric_template.values())\n",
    "\n",
    "    cursor.execute(query, values)\n",
    "\n",
    "# Begin inserting all records\n",
    "curr_time = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "amc_month = \"FEB 25\"\n",
    "data_from = \"finkstein\"\n",
    "\n",
    "for amc_key, records in combined_records.items():\n",
    "    print(f\"Doing {amc_key}\")\n",
    "    for record in records:\n",
    "        try:\n",
    "            details = record[\"value\"]\n",
    "            amc_id = get_or_create_amc(details[\"amc_name\"])\n",
    "            mutual_fund_id = insert_mutual_fund(cursor, amc_id, details, curr_time, amc_month, data_from)\n",
    "            if mutual_fund_id:\n",
    "                insert_fund_managers(cursor, amc_id, curr_time, amc_month, data_from, mutual_fund_id, details)\n",
    "                insert_load(cursor, amc_id, mutual_fund_id, details)\n",
    "                insert_metrics(cursor, amc_id, mutual_fund_id, details)\n",
    "            else:\n",
    "                print\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting scheme '{scheme_name}' under AMC '{amc_name}': {e}\")\n",
    "    print(f\"Done {amc_key}\")\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"Data insertion completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata\n",
    "# conn = mysql.connector.connect(\n",
    "#     host=\"localhost\",\n",
    "#     user=\"root\",\n",
    "#     password=\"1234\",\n",
    "#     database=\"cog_updated_db\"\n",
    "# )\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"1234\",\n",
    "    database=\"try_db\"\n",
    ")\n",
    "\n",
    "# conn = mysql.connector.connect(\n",
    "#     host=\"172.22.225.155\",\n",
    "#     user=\"cog_mf\",\n",
    "#     password=\"bnYwFChjLAV2Z%9E\",\n",
    "#     database=\"cog_mf\",\n",
    "#     port=3306,\n",
    "#     charset='utf8mb4'\n",
    "# )\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def get_or_create_amc(amc_name):\n",
    "    cursor.execute(\"SELECT id FROM mf_amcs WHERE amc_name = %s\", (amc_name,))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        return result[0]\n",
    "    cursor.execute(\"INSERT INTO mf_amcs (amc_name) VALUES (%s)\", (amc_name,))\n",
    "    conn.commit()\n",
    "    return cursor.lastrowid\n",
    "\n",
    "def insert_mutual_fund(cursor, amc_id, details, curr_time, amc_month, data_from):\n",
    "    keys = [\"amc_id\", \"entered_time\", \"amc_for_month\", \"data_from\", \"amc_name\", \"benchmark_index\",\n",
    "            \"main_scheme_name\", \"mutual_fund_name\", \"monthly_aaum_date\", \"monthly_aaum_value\",\n",
    "            \"scheme_launch_date\", \"min_addl_amt\", \"min_addl_amt_multiple\", \"min_amt\", \"min_amt_multiple\"]\n",
    "\n",
    "    query = f\"INSERT INTO mf_mutual_funds ({', '.join(keys)}) VALUES ({', '.join(['%s'] * len(keys))})\"\n",
    "    values = [\n",
    "        amc_id, curr_time, amc_month, data_from, details.get(\"amc_name\", \"\"),\n",
    "        details.get(\"benchmark_index\", \"\"),\n",
    "        details.get(\"main_scheme_name\", \"\"),\n",
    "        details.get(\"mutual_fund_name\", \"\"),\n",
    "        details.get(\"monthly_aaum_date\", \"\"),\n",
    "        details.get(\"monthly_aaum_value\", \"\"),\n",
    "        details.get(\"scheme_launch_date\", \"\"),\n",
    "        details.get(\"min_addl_amt\", \"\"),\n",
    "        details.get(\"min_addl_amt_multiple\", \"\"),\n",
    "        details.get(\"min_amt\", \"\"),\n",
    "        details.get(\"min_amt_multiple\", \"\")\n",
    "    ]\n",
    "    try:\n",
    "        cursor.execute(query, values)\n",
    "    except Exception as e:\n",
    "        print(\"Error inserting mutual fund:\")\n",
    "        print(\"Scheme Name:\", details.get(\"main_scheme_name\"))\n",
    "        print(\"Query:\", query)\n",
    "        print(\"Values:\", values)\n",
    "        print(\"Exception:\", e)\n",
    "        return None\n",
    "    \n",
    "    return cursor.lastrowid\n",
    "\n",
    "def insert_fund_managers(cursor, amc_id,entered_time, amc_for_month,data_from, mutual_fund_id, details):\n",
    "    if not isinstance(details.get(\"fund_manager\"), list):\n",
    "        return\n",
    "    for manager in details[\"fund_manager\"]:\n",
    "        query = \"\"\"\n",
    "            INSERT INTO mf_fund_managers\n",
    "            (amc_id,entered_time, amc_for_month, data_from, mutual_fund_id, main_scheme_name, name, qualification, managing_fund_since, total_exp)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        values = [\n",
    "            amc_id,\n",
    "            entered_time, \n",
    "            amc_for_month,\n",
    "            data_from,\n",
    "            mutual_fund_id,\n",
    "            details[\"main_scheme_name\"],\n",
    "            manager.get(\"name\", \"\"),\n",
    "            manager.get(\"qualification\", \"\"),\n",
    "            manager.get(\"managing_fund_since\", \"\"),\n",
    "            manager.get(\"total_exp\", \"\")\n",
    "        ]\n",
    "        try:\n",
    "            cursor.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Manager: {e}\")\n",
    "\n",
    "def insert_load(cursor, amc_id, mutual_fund_id, details):\n",
    "    load = details.get(\"load\", {})\n",
    "    if not isinstance(load, dict):\n",
    "        print(f\"Error in Loads, {details.get('main_scheme_name', '')}\")\n",
    "        return\n",
    "    query = \"\"\"\n",
    "        INSERT INTO mf_transformed_loads\n",
    "        (amc_id, mutual_fund_id, main_scheme_name, entry_load, exit_load)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    values = [\n",
    "        amc_id,\n",
    "        mutual_fund_id,\n",
    "        details.get(\"main_scheme_name\", \"\"),\n",
    "        load.get(\"entry_load\", \"\"),\n",
    "        load.get(\"exit_load\", \"\")\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(query, values)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Load: {e}\")\n",
    "\n",
    "def insert_metrics(cursor, amc_id, mutual_fund_id, details):\n",
    "    keys = ['amc_id', 'main_scheme_name', 'mutual_fund_id', \"alpha\", \"arithmetic_mean_ratio\", \"average_div_yld\", \"average_pb\", \"average_pe\", \"avg_maturity\", \n",
    "            \"beta\", \"correlation_ratio\", \"downside_deviation\", \"information_ratio\", \"macaulay\", \"mod_duration\", \"port_turnover_ratio\", \"r_squared_ratio\", \n",
    "            \"roe_ratio\", \"sharpe\", \"sortino_ratio\", \"std_dev\", \"tracking_error\", \"treynor_ratio\", \"upside_deviation\", \"ytm\"]\n",
    "    metrics = details.get(\"metrics\", {})\n",
    "    if not isinstance(metrics, dict):\n",
    "        print(f\"Error in Metrics, {details.get('main_scheme_name', '')}\")\n",
    "        return\n",
    "    query = f\"INSERT INTO mf_transformed_metrics ({', '.join(keys)}) VALUES ({', '.join(['%s'] * len(keys))})\"\n",
    "    values = [amc_id, details.get(\"main_scheme_name\", \"\"), mutual_fund_id] + [metrics.get(k, \"\") for k in keys[3:]]\n",
    "    try:\n",
    "        cursor.execute(query, values)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Metrics: {e}\")\n",
    "\n",
    "curr_time = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "amc_month = \"FEBRUARY 25\"\n",
    "data_from = \"mydata\"\n",
    "\n",
    "for amc_name, schemes in combined_records.items():\n",
    "    print(f\"Inserting Data For: {amc_name}\")\n",
    "    amc_id = get_or_create_amc(next(iter(schemes.values())).get(\"amc_name\", \"\"))\n",
    "    for scheme_name, details in schemes.items():\n",
    "        try:\n",
    "            mutual_fund_id = insert_mutual_fund(cursor, amc_id, details, curr_time, amc_month, data_from)\n",
    "            if mutual_fund_id:\n",
    "                insert_fund_managers(cursor, amc_id,curr_time, amc_month, data_from, mutual_fund_id, details)\n",
    "                insert_load(cursor, amc_id, mutual_fund_id, details)\n",
    "                insert_metrics(cursor, amc_id, mutual_fund_id, details)\n",
    "            else:\n",
    "                print(f\"Skipped Data Insertion for AMC {scheme_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting scheme '{scheme_name}' under AMC '{amc_name}': {e}\")\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"Working!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "def sanitize_sheet_name(name):\n",
    "    name = re.sub(r'[^A-Za-z0-9_ ]+', '', name)\n",
    "    return name.strip().replace(\" \", \"_\")[:31]\n",
    "\n",
    "def fetch_data_for_source(conn, amc_name, source, entered_time_pattern=\"%\"):\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        mf.data_from,mf.entered_time,mf.amc_for_month,mf.main_scheme_name,mf.benchmark_index,mf.monthly_aaum_value,\n",
    "        mf.monthly_aaum_value,mf.scheme_launch_date,mf.min_addl_amt,mf.min_addl_amt_multiple,mf.min_amt,mf.min_amt_multiple,tl.entry_load, tl.exit_load,\n",
    "        tm.alpha,tm.arithmetic_mean_ratio,tm.average_div_yld,tm.average_pb,tm.average_pe,tm.avg_maturity,tm.beta,tm.correlation_ratio,tm.downside_deviation,\n",
    "        tm.information_ratio,tm.macaulay,tm.mod_duration,tm.port_turnover_ratio,tm.r_squared_ratio, tm.roe_ratio, tm.sharpe,tm.sortino_ratio,tm.std_dev,\n",
    "        tm.tracking_error,tm.treynor_ratio,tm.upside_deviation,tm.ytm\n",
    "    FROM mf_mutual_funds mf\n",
    "    LEFT JOIN mf_transformed_loads tl ON mf.id = tl.mutual_fund_id\n",
    "    LEFT JOIN mf_transformed_metrics tm ON mf.id = tm.mutual_fund_id\n",
    "    WHERE mf.amc_name LIKE %s AND mf.data_from = %s AND mf.entered_time LIKE %s;\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor(dictionary=True)\n",
    "    cursor.execute(query, (f\"%{amc_name}%\", source, entered_time_pattern))\n",
    "    rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return pd.DataFrame(rows) if rows else pd.DataFrame()\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"172.22.225.155\",\n",
    "    user=\"cog_mf\",\n",
    "    password=\"bnYwFChjLAV2Z%9E\",\n",
    "    database=\"cog_mf\",\n",
    "    port=3306,\n",
    "    charset='utf8mb4'\n",
    ")\n",
    "\n",
    "# conn = mysql.connector.connect(\n",
    "#     host=\"localhost\",\n",
    "#     user=\"root\",\n",
    "#     password=\"1234\",\n",
    "#     database=\"cog_updated_db\"\n",
    "# )\n",
    "\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "amc_names = pd.read_sql(\"SELECT amc_name FROM mf_amcs;\", conn)[\"amc_name\"].tolist()\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "output_path = f\"comparison_export_{timestamp}.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "    workbook = writer.book\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7E4BC',\n",
    "        'border': 1\n",
    "    })\n",
    "    gray_format = workbook.add_format({'bg_color': '#D3D3D3'})  # for mydata rows\n",
    "\n",
    "    for amc in amc_names:\n",
    "        df_A = fetch_data_for_source(conn, amc, \"finkstein\", \"%2025-04-23%\")\n",
    "        df_B = fetch_data_for_source(conn, amc, \"mydata\", \"%2025-04-23%\")\n",
    "\n",
    "        if df_A.empty and df_B.empty:\n",
    "            print(f\"Skipped: {amc} (no data)\")\n",
    "            continue\n",
    "\n",
    "        df_A[\"data_from\"] = \"finkstein\"\n",
    "        df_B[\"data_from\"] = \"mydata\"\n",
    "\n",
    "        combined_df = pd.concat([df_A, df_B], ignore_index=True)\n",
    "        # combined_df = combined_df.sort_values(by=\"main_scheme_name\")\n",
    "        front_cols = ['data_from', 'main_scheme_name']\n",
    "        remaining_cols = [col for col in combined_df.columns if col not in front_cols]\n",
    "        combined_df = combined_df[front_cols + remaining_cols]\n",
    "\n",
    "        sheet_name = sanitize_sheet_name(amc)\n",
    "        combined_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "        for col_num, header in enumerate(combined_df.columns.values):\n",
    "            worksheet.write(0, col_num, header, header_format)\n",
    "            header_width = len(header)\n",
    "            worksheet.set_column(col_num, col_num, header_width + 8)\n",
    "\n",
    "\n",
    "        # Highlight mydata rows\n",
    "        for row_num, row in enumerate(combined_df[\"data_from\"], start=1):\n",
    "            if row == \"mydata\":\n",
    "                worksheet.set_row(row_num, None, gray_format)\n",
    "\n",
    "print(f\"Data exported to: {output_path}\")\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, logging, os, sys, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_generic_data(self, main_key: str, data: list, pattern: str):\n",
    "    final_dict = {}\n",
    "    for text in data:\n",
    "        text = re.sub(self.REGEX['escape'], \"\", text.strip())\n",
    "        matches = re.findall(self.REGEX[pattern], text, re.IGNORECASE)\n",
    "        for key, value in matches:\n",
    "            final_dict[key] = value\n",
    "    return {main_key: final_dict}\n",
    "\n",
    "def _extract_str_data(self, key: str, data: list):\n",
    "    return {key: ' '.join(data)}\n",
    "\n",
    "def _extract_manager_data(self, main_key: str, data: list, pattern:str):\n",
    "    final_list = []\n",
    "    for i in range(0, len(data), 3):\n",
    "        txt = \" \".join(data[i:i+3])\n",
    "        txt = re.sub(self.REGEX['escape'], \"\", txt).strip()\n",
    "        if matches := re.findall(self.REGEX[pattern], txt, re.IGNORECASE):\n",
    "            for match in matches:\n",
    "                name, desig, since, exp = match\n",
    "                final_list.append({\n",
    "                    \"name\": name,\n",
    "                    \"designation\": desig,\n",
    "                    \"managing_since\": since,\n",
    "                    \"experience\": exp\n",
    "                })\n",
    "    return {main_key: final_list}\n",
    "\n",
    "def _extract_dum_data(self, key, data):\n",
    "    return {key: data}\n",
    "\n",
    "def _extract_scheme_data(self,main_key:str,data:list, pattern:str):\n",
    "    regex_ = self.REGEX[pattern] #list\n",
    "    mention_start = regex_[:-1]\n",
    "    mention_end = regex_[1:]\n",
    "\n",
    "    patterns = [r\"({start})\\s*(.+?)\\s*({end}|$)\".format(start=start, end=end)\n",
    "        for start, end in zip(mention_start, mention_end)]\n",
    "    \n",
    "    final_dict = {}\n",
    "    scheme_data = \" \".join(data)\n",
    "    for pattern in patterns:\n",
    "        if matches:= re.findall(pattern, scheme_data, re.DOTALL|re.IGNORECASE):\n",
    "            for match in matches:\n",
    "                key, value, dummy = match\n",
    "                value = value.strip()\n",
    "                final_dict[key] = value\n",
    "    \n",
    "    return {main_key:final_dict}\n",
    "\n",
    "def match_regex_to_content(self, string: str, data: list, *args):\n",
    "    for pattern, (func_name, regex_key) in self.PATTERN_TO_FUNCTION.items():\n",
    "        if re.match(pattern, string, re.IGNORECASE):\n",
    "            func = getattr(self, func_name)\n",
    "            if regex_key:\n",
    "                return func(string, data, regex_key)\n",
    "            return func(string, data)\n",
    "    return self._extract_dum_data(string, data)\n",
    "\n",
    "def _extract_load_data(self,main_key:str,data:list, pattern:str):\n",
    "        load_data = \" \".join(data)\n",
    "        load_data = re.sub(r\"[\\^*\\$:;~]\",\"\",load_data).strip()\n",
    "        final_dict = {}\n",
    "        if match:= re.findall(self.REGEX[pattern],load_data.strip(), re.IGNORECASE):\n",
    "            exit_,entry_ = match[0]\n",
    "            final_dict['entry_load'] = entry_,\n",
    "            final_dict['exit_load'] = exit_\n",
    "        return {main_key:final_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r'([\\d,]+).*?([\\d,]+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(?:Entry Load)?\\s*(Nil|.*?)\\s*Exit Load\\s*(.*)$'\n",
    "for fund, content in final_text.items():\n",
    "    check = 'scheme_details.load_structure'\n",
    "    if check in content:\n",
    "        text =re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+', \"\",content[check]).strip()\n",
    "        print(text)\n",
    "        match = re.findall(pattern,text, re.IGNORECASE)\n",
    "        print(match)\n",
    "        \n",
    "pattern = r'(AUM|Monthly Average AUM)\\s*([\\d,.]+)'\n",
    "for fund, content in final_text.items():\n",
    "    check = 'aum'\n",
    "    if check in content:\n",
    "        for text in  content[check]:\n",
    "            text =re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+', \"\",text).strip()\n",
    "            print(text)\n",
    "            match = re.findall(pattern,text, re.IGNORECASE)\n",
    "            print(match)\n",
    "            \n",
    "pattern = r'(?:Entry Load)?\\s*(Nil|.*?)\\s*Exit Load\\s*(.*)$'\n",
    "for fund, content in final_text.items():\n",
    "    check = 'scheme_details.load_structure'\n",
    "    if check in content:\n",
    "        all_text = \" \".join(content[check])\n",
    "        all_text =re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+', \"\", all_text).strip()\n",
    "        print(all_text)\n",
    "        print(re.findall(pattern,all_text, re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_amt = \"([\\\\d,]+).*?([\\\\d,]+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_start = [\n",
    "        \"Date of Allotment\",\n",
    "        \"Fund Manager\",\n",
    "        \"Fund Size\",\n",
    "        \"Load Structure\",\n",
    "        \"Benchmark\",\n",
    "        \"Minimum Additional\",\n",
    "        r\"Minimum Redemption\\s*\\/\\s*Switch-out Amount\",\n",
    "    ]\n",
    "    \n",
    "mention_end = mention_start[1:] + [\"End_of_Data\"]\n",
    "\n",
    "# Generate regex patterns dynamically\n",
    "patterns = [r\"({start}\\s*)(.+?)({end}|$)\".format(start=start, end=end)\n",
    "    for start, end in zip(mention_start, mention_end)]\n",
    "final_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_keys(json_files):\n",
    "    unique_keys = set()  # Store unique keys\n",
    "\n",
    "    for file in json_files:\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "                for fund_name, fund_data in data.items():\n",
    "                    if isinstance(fund_data, dict):\n",
    "                        extract_keys(fund_data, unique_keys)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    return unique_keys\n",
    "\n",
    "def extract_keys(data, key_set):\n",
    "    \"\"\"Recursively extract keys from JSON data.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            key_set.add(\"_\".join(key.lower().split(\" \")))\n",
    "            extract_keys(value, key_set)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            extract_keys(item, key_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\"  # Update this to your folder path\n",
    "json_files = [os.path.join(json_folder, file) for file in os.listdir(json_folder) if file.endswith('.json')]\n",
    "unique_keys = get_unique_keys(json_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, pprint\n",
    "from app.pdfParse import Reader\n",
    "from app.fundRegex import FundRegex\n",
    "import fitz\n",
    "\n",
    "class FranklinTempleton(Reader):\n",
    "    PARAMS = {\n",
    "        'fund': [[25,20],r\"^(Franklin|Templeton).*$\",[16,24],[-65794]], #[flag], regex_fund_name, range(font_size), [font_color]\n",
    "        'clip_bbox': [(0,100,180,812)],\n",
    "        'line_x': 180.0,\n",
    "        'data': [[6,9],[-16751720],30.0,['ZurichBT-BoldCondensed']], #sizes, color, set_size font_name\n",
    "        'content_size':[30.0,10.0]\n",
    "    }\n",
    "    \n",
    "    REGEX = {\n",
    "        'nav': r'(Growth Plan|IDCW Plan|Direct Growth Plan|Direct IDCW Plan)\\s*([\\d\\-,]+\\.\\d+)',\n",
    "        'metric': r'(Sharpe Ratio|Standard Deviation|Beta|Annualised)[\\s]+([\\d\\-,]+\\.\\d+)',\n",
    "        'expense': r'(Regular|Direct)\\s*([\\d,.-]+)',\n",
    "        'load': r'ENTRY LOA(.*?)\\s*EXIT LOAD\\s*(.*?)$',\n",
    "        'aum': r'(Month End|Monthly Average)\\s*([\\d,.\\-]+)',\n",
    "        'ptr':r'^(Portfolio Turnover|Total Portfolio).*\\s*([\\d\\-,]+\\.\\d+)',\n",
    "        # 'manager': r'([A-Za-z\\s]+)\\s*\\(Managing Since\\s*([A-Za-z0-9\\s]+) and overall experience of ([a-z0-9\\s]+)\\)',\n",
    "        'escape': r'[^A-Za-z0-9\\s\\-\\(\\).,]+'\n",
    "    }\n",
    "\n",
    "    PATTERN_TO_FUNCTION = {\n",
    "        r\"^(date|benchmark|investment|type_of|scheme|multiples|minimum).*\":(\"_extract_str_data\", None),\n",
    "        r\"^nav.*\":(\"_extract_generic_data\", \"nav\"),\n",
    "        # r\"^fund_mana.*\": self.__extract_manager_data,\n",
    "        r\"^aum.*\": (\"_extract_generic_data\", 'aum'),\n",
    "        r\"^portfolio_turnover_ratio\": (\"_extract_generic_data\", 'ptr'),\n",
    "        r\"^load\": (\"_extract_load_data\", 'load'),\n",
    "        r\"^metrics\": (\"_extract_generic_data\", \"metric\"),\n",
    "    }\n",
    "\n",
    "    def __init__(self, paths_config: str):\n",
    "        super().__init__(paths_config, self.PARAMS)\n",
    "    \n",
    "    def _extract_str_data(self, key: str, data: list):\n",
    "        return {key: ' '.join(data)}\n",
    "    \n",
    "    def _extract_dummy_data(self, main_key:str, data:list):\n",
    "        return{main_key:data}\n",
    "    \n",
    "    def _extract_generic_data(self, main_key: str, data: list, pattern: str):\n",
    "        final_dict = {}\n",
    "        for text in data:\n",
    "            text = re.sub(self.REGEX['escape'], \"\", text.strip())\n",
    "            matches = re.findall(self.REGEX[pattern], text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                if len(match) == 2:\n",
    "                    key, value = match\n",
    "                    final_dict[key.strip()] = value.strip()\n",
    "                elif len(match) == 3:\n",
    "                    key,v1,v2 = match\n",
    "                    final_dict[key.strip()] = v1.strip()\n",
    "        return {main_key: final_dict}\n",
    "    \n",
    "    def _extract_manager_data(self, main_key: str, data: list, pattern:str):\n",
    "        manager_data = \" \".join(data)\n",
    "        manager_data = re.sub(self.REGEX[pattern], \"\", manager_data).strip()\n",
    "        final_list = []\n",
    "        if matches := re.findall(self.REGEX['manager'], manager_data, re.IGNORECASE):\n",
    "            for match in matches:\n",
    "                name, since, exp = match\n",
    "                final_list.append({\n",
    "                    \"name\": name.strip(),\n",
    "                    \"designation\": \"\",\n",
    "                    \"managing_since\": since.strip(),\n",
    "                    \"experience\": exp.strip()\n",
    "                })\n",
    "        return {main_key: final_list}\n",
    "    \n",
    "    def _extract_load_data(self,main_key:str,data:list, pattern:str):\n",
    "        load_data = \" \".join(data)\n",
    "        load_data = re.sub(self.REGEX['escape'], \"\", load_data).strip()\n",
    "        final_dict = {}\n",
    "        if match:= re.findall(self.REGEX[pattern],load_data.strip(), re.IGNORECASE):\n",
    "            exit_,entry_ = match[0]\n",
    "            final_dict['entry_load'] = entry_,\n",
    "            final_dict['exit_load'] = exit_\n",
    "        return {main_key:final_dict}\n",
    "        \n",
    "    \n",
    "    def match_regex_to_content(self, string: str, data: list, *args):\n",
    "        for pattern, (func_name, regex_key) in self.PATTERN_TO_FUNCTION.items():\n",
    "            if re.match(pattern, string, re.IGNORECASE):\n",
    "                func = getattr(self, func_name)\n",
    "                if regex_key and regex_key in self.REGEX:\n",
    "                    return func(string, data, regex_key)\n",
    "                return func(string, data)\n",
    "        return self._extract_dummy_data(string, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(data, keys, target_key):\n",
    "    \"\"\"\n",
    "    Merges values of two keys inside each fund and stores the result in target_key.\n",
    "\n",
    "    :param data: Dictionary containing funds.\n",
    "    :param keys: List of two keys whose values need to be merged.\n",
    "    :param target_key: The key where the merged result should be stored.\n",
    "    \"\"\"\n",
    "    if len(keys) != 2:\n",
    "        raise ValueError(\"Exactly two keys must be provided for merging.\")\n",
    "\n",
    "    key1, key2 = keys\n",
    "\n",
    "    for fund, values in data.items():\n",
    "        if key1 in values and key2 in values:\n",
    "            val1, val2 = values[key1], values[key2]\n",
    "\n",
    "            if isinstance(val1, str) and isinstance(val2, str):\n",
    "                values[target_key] = val1 + val2\n",
    "            elif isinstance(val1, list) and isinstance(val2, list):\n",
    "                values[target_key] = val1 + val2\n",
    "            elif isinstance(val1, dict) and isinstance(val2, dict):\n",
    "                values[target_key] = {**val1, **val2}\n",
    "            else:\n",
    "                raise TypeError(f\"Cannot merge different data types: {type(val1)} and {type(val2)}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example Usage\n",
    "sample = {\n",
    "    \"fund_name1\": {\n",
    "        \"a\": \"Hello\",\n",
    "        \"b\": \" World\",\n",
    "        \"c\": {},\n",
    "    },\n",
    "    \"fund_name2\": {\n",
    "        \"a\": [1, 2, 3],\n",
    "        \"b\": [4, 5, 6],\n",
    "        \"c\": {},\n",
    "    },\n",
    "}\n",
    "\n",
    "merged_sample = merge_data(sample, [\"a\", \"b\"], \"a\")\n",
    "print(merged_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT CODE DONT DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"wip\"\"\"\n",
    "class DSP(Reader):\n",
    "    \n",
    "    PARAMS = {\n",
    "        'fund': [[20,16], r'^(DSP|Bharat).*(Fund|ETF|FTF|FOF)$|^(DSP|Bharat)',[14,24],[-1]],\n",
    "        'clip_bbox': [(0,5,120,812),],#[480,5,596,812]],\n",
    "        'line_x': 120.0,\n",
    "        'data': [[7,10], [-16777216], 30.0, ['TrebuchetMS-Bold']],\n",
    "        'content_size':[30.0,10.0]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    def __init__(self, paths_config:str):\n",
    "        super().__init__(paths_config, self.PARAMS)\n",
    "        \n",
    "    #REGEX\n",
    "    def __return_all_data(self,main_key,data:list):\n",
    "        return {main_key:data}\n",
    "    \n",
    "    def __extract_inv_data(self,main_key:str, data:list):            \n",
    "        return {main_key: ' '.join(data)}\n",
    "    \n",
    "    #MAPPING\n",
    "    def match_regex_to_content(self, string:str, data:list):\n",
    "        check_header = string\n",
    "        if re.match(r\"^investment.*\", check_header, re.IGNORECASE):\n",
    "            return self.__extract_inv_data(string,data)\n",
    "        # elif re.match(r\"^aum.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_aum_data(string, data)\n",
    "        # elif re.match(r\"^fund_mana.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_manager_data(string, data)\n",
    "        # elif re.match(r\"^metrics.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_metric_data(string, data)\n",
    "        return self.__return_all_data(string,data) \n",
    "\n",
    "\"\"\" thissssssssssssssssssssssss\"\"\"\n",
    "class HSBC(Reader):\n",
    "    \n",
    "    PARAMS = {\n",
    "        'fund': [[20,16], r'^(HSBC|Bharat).*Fund$',[12,20],[-1237724]],\n",
    "        'clip_bbox': [(0,100,180,812)],\n",
    "        'line_x': 180.0,\n",
    "        'data': [[6,8], [-16777216], 30.0, ['Arial-BoldMT']],\n",
    "        'content_size':[30.0,10.0]\n",
    "    }\n",
    "    \n",
    "    def __init__(self,paths_config:str):\n",
    "        super().__init__(paths_config, self.PARAMS)\n",
    "        \n",
    "    #Fund REGEX\n",
    "    def __return_all_data(self,key,data:list):\n",
    "        return {key:data}\n",
    "    \n",
    "    def __extract_inv_data(self,key:str, data:list):            \n",
    "        return {key: ' '.join(data)}\n",
    "    \n",
    "    #MAPPING\n",
    "    def match_regex_to_content(self, string:str, data:list):\n",
    "        check_header = string\n",
    "        if re.match(r\"^(investment).*\", check_header, re.IGNORECASE):\n",
    "            return self.__extract_inv_data(string,data)\n",
    "        # elif re.match(r\"^total.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_total_expense_data(string, data)\n",
    "        # elif re.match(r\"^nav.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_nav_data(string, data)\n",
    "        # elif re.match(r\"^portfolio.*\", check_header, re.IGNORECASE): #error here portfolio is read\n",
    "        #     return self.__extract_scheme_data(string, data)\n",
    "        return self.__return_all_data(string,data)     \n",
    "\n",
    "class LIC(Reader):\n",
    "    \n",
    "    PARAMS = {\n",
    "        'fund': [[20,16], r'^(LIC|Bharat).*(Fund|ETF|FTF|FOF)$',[12,20],[-15319437]],\n",
    "        'clip_bbox': [(0,5,150,812),],\n",
    "        'line_x': 150.0,\n",
    "        'data': [[5,8], [-15445130,-14590595], 30.0, ['Frutiger-Bold']],\n",
    "        \"content_size\":[30.0,10.0]\n",
    "    }\n",
    "    def __init__(self,paths_config:str):\n",
    "        super().__init__(paths_config, self.PARAMS)          \n",
    "                    \n",
    "class QuantMF(Reader):\n",
    "    PARAMS = {\n",
    "        'fund': [[16,0], r'^(quant).*(Fund|ETF|EOF|FOF|FTF|Path)$',[16,24],[-13604430]],\n",
    "        'clip_bbox': [(0,5,180,812)],\n",
    "        'line_x': 180.0,\n",
    "        'data': [[6,11], [-16777216], 30.0, ['Calibri,Bold',]],\n",
    "        'content_size':[30.0,10.0]\n",
    "        }\n",
    "    \n",
    "    def __init__(self, paths_config:str):\n",
    "        super().__init__(paths_config,self.PARAMS)\n",
    "\n",
    "class PPFAIS(Reader):\n",
    "    PARAMS = {\n",
    "        'fund': [[16,20], r'^(Parag).*',[14,24],[-16777216,-13159371,-14869475]],\n",
    "        'clip_bbox': [(0,65,290,812)],\n",
    "        'line_x': 290.0,\n",
    "        'data': [[6,10], [-65794], 30.0, ['Arial-BoldMT',]]\n",
    "        }\n",
    "    \n",
    "    def __init__(self, paths_config:str):\n",
    "        super().__init__(paths_config,self.PARAMS)\n",
    "        \n",
    "    #REGEX\n",
    "    def __return_all_data(self,main_key,data:list):\n",
    "        return {main_key:data}\n",
    "    \n",
    "    def __extract_inv_data(self,main_key:str, data:list):            \n",
    "        return {main_key: ' '.join(data)}\n",
    "    \n",
    "    #MAPPING\n",
    "    def match_regex_to_content(self, string: str, data: list):\n",
    "        pattern_to_function = {\n",
    "            r\"^investment.*\": self.__extract_inv_data,\n",
    "            # r\"^scheme.*\": self.__extract_scheme_data,\n",
    "            # r\"^metrics.*\": self.__extract_metric_data,\n",
    "        }\n",
    "\n",
    "        for pattern, func in pattern_to_function.items():\n",
    "            if re.match(pattern, string, re.IGNORECASE):\n",
    "                return func(string, data)\n",
    "\n",
    "        return self.__return_all_data(string, data)\n",
    "    \n",
    "class SBI(Reader):\n",
    "    \n",
    "    PARAMS = {\n",
    "        'fund': [[16,0], r'^().*',[12,20],[-12371562]],\n",
    "        'clip_bbox': [(0,5,180,812)],\n",
    "        'line_x': 180.0,\n",
    "        'data': [[6,11], [-12371562], 30.0, ['Calibri,Bold',]]}\n",
    "    \n",
    "    def __init__(self, paths_config:str):\n",
    "        super().__init__(paths_config,self.PARAMS)\n",
    "          \n",
    "class PGIM(Reader):\n",
    "    PARAMS = {\n",
    "        'fund': [[20,4],r'^.*(Plan|Sensex|Fund|Path|ETF|FOF|EOF|Funds)$',[16,30],[-1]], #FUND NAME DETAILS order-> flag, regex_fund_name, font_size, font_color\n",
    "        'clip_bbox': [(0,115,210,812)],\n",
    "        'line_x': 210.0,\n",
    "        'data': [[6,12],[-1],30.0,['PrudentialModern-Bold']], #sizes, color, set_size\n",
    "        'content_size':[30.0,10.0]\n",
    "    }\n",
    "    \n",
    "    def __init__(self, path: str,dry:str,fin:str, rep:str):\n",
    "        super().__init__(path,dry,fin,rep, self.PARAMS)\n",
    "    \n",
    "    #Fund Regex  \n",
    "    def __return_all_data(self,main_key:str,data:list):\n",
    "        return{main_key:data}\n",
    "    def __extract_fund_data(self,main_key:str, data:list):\n",
    "        return {main_key:data}\n",
    "    def __extract_invest_data(self,main_key:str,data:list):\n",
    "        return {main_key: \" \".join(data)}\n",
    "    \n",
    "    #MAPPING FUNCTION\n",
    "    def match_regex_to_content(self, string: str, data: list):\n",
    "        pattern_to_function = {\n",
    "            r\"^(investment|minimum|entry|exit|load|plans|scheme_launch|benchmark).*\": self.__extract_invest_data,\n",
    "            r\"^fund_mana.*\": self.__extract_fund_data,\n",
    "        }\n",
    "\n",
    "        for pattern, func in pattern_to_function.items():\n",
    "            if re.match(pattern, string, re.IGNORECASE):\n",
    "                return func(string, data)\n",
    "\n",
    "        return self.__return_all_data(string, data)\n",
    "\n",
    "\n",
    "#something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first\n",
    "final_dic = {\n",
    "    \"metadata\": [],\n",
    "    \"records\": []\n",
    "}\n",
    "\n",
    "#second\n",
    "meta_data = {\n",
    "    \"document_name\": \"\",\n",
    "    \"file_type\": \"\",\n",
    "    \"process_date\": \"\"\n",
    "}\n",
    "record = {\n",
    "            \"amc_name\": \"\",\n",
    "            \"benchmark_index\":[],\n",
    "            \"field_location\": [],\n",
    "            \"fund_manager\": [],\n",
    "            \"load\": [],\n",
    "            \"main_scheme_name\": \"\",\n",
    "            \"metrics\": [],\n",
    "            \"min_addl_amt\": \"\",\n",
    "            \"min_addl_multiple\":\"\",\n",
    "            \"min_amt\":\"\",\n",
    "            \"monthly_aaum_date\":\"\",\n",
    "            \"monthly_aaum_value\":\"\",\n",
    "            \"mutual_fund_name\": \"\",\n",
    "            \"scheme_launch_date\":\"\"\n",
    "            \n",
    "        }\n",
    "\n",
    "#third  \n",
    "fund_manager = {\n",
    "    \"managing_fund_since\":\"\",\n",
    "    \"name\": \"\",\n",
    "    \"qualification\": \"\",\n",
    "    \"total_exp\": \"\"\n",
    "}\n",
    "load = {\n",
    "    \"type\": \"\",\n",
    "    \"comment\": \"\"\n",
    "}   \n",
    "metrics= {\n",
    "    \"name\":\"\",\n",
    "    \"value\":\"\"\n",
    "}    \n",
    "field_location = {\n",
    "    \"amc_name\": \"\",\n",
    "    \"benchmark_index\": \"\",\n",
    "    \"count\": 0,\n",
    "    \"fund_manager_managing_fund_since\": \"\",\n",
    "    \"fund_manager_name\": \"\",\n",
    "    \"fund_manager_total_exp\": \"\",\n",
    "    \"load_entry\": \"\",\n",
    "    \"load_exit\": \"\",\n",
    "    \"main_scheme_name\": \"\",\n",
    "    \"metrics_beta\": \"\",\n",
    "    \"metrics_port_turnover_ratio\": \"\",\n",
    "    \"metrics_r_squared_ratio\": \"\",\n",
    "    \"metrics_sharpe\": \"\",\n",
    "    \"metrics_std_dev\": \"\",\n",
    "    \"metrics_treynor_ratio\": \"\",\n",
    "    \"min_addl_amt\": \"\",\n",
    "    \"min_addl_amt_multiple\": \"\",\n",
    "    \"min_amt\": \"\",\n",
    "    \"min_amt_multiple\": \"\",\n",
    "    \"monthly_aaum_date\": \"\",\n",
    "    \"monthly_aaum_value\": \"\",\n",
    "    \"mutual_fund_name\": \"\",\n",
    "    \"scheme_launch_date\": \"\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aditya Birla Sun Life Mutual Fund\n",
    "# Kotak Mahindra Mutual Fund\n",
    "# Shriram Mutual fund\n",
    "# PPFAS Mutual Fund\n",
    "# ITI Mutual Fund\n",
    "# PGIM India Mutual Fund\n",
    "# BajaJ Finserv Mutual Fund\n",
    "# Union Mutual Fund\n",
    "# Sundaram Mutual Fund\n",
    "# NJ Mutual Fund\n",
    "# Samco Mutual Fund\n",
    "# Bank of India Mutual Fund\n",
    "# DSP Mutual Fund\n",
    "# Edelweiss Mutual Fund\n",
    "# Invesco Mutual Fund\n",
    "# Helios Mutual Fund\n",
    "# Groww Mutual Fund\n",
    "# Nippon India Mutual Fund\n",
    "# Quantum Mutual Fund\n",
    "# Franklin Templeton Mutual Fund\n",
    "# Bandhan Mutual Fund\n",
    "# IL&FS Mutual Fund (IDF)\n",
    "# Tata Mutual Fund\n",
    "# Mirae Asset Mutual Fund\n",
    "# Motilal Oswal Mutual Fund\n",
    "# Old Bridge Mutual Fund\n",
    "# 360 ONE Mutual Fund\n",
    "# LIC Mutual Fund\n",
    "# Mahindra Manulife Mutual Fund\n",
    "# WhiteOak Mutual Fund\n",
    "# Navi Mutual Fund\n",
    "# Baroda BNP Paribas Mutual Fund\n",
    "# SBI Mutual Fund\n",
    "# Taurus Mutual Fund\n",
    "# JM Financial Mutual Fund\n",
    "# Trust Mutual Fund\n",
    "# Zerodha Mutual Fund\n",
    "# ICICI Prudential Mutual Fund\n",
    "# Quant Mutual Fund\n",
    "# Axis Mutual Fund\n",
    "# Canara Robeco Mutual Fund\n",
    "# HDFC Mutual Fund\n",
    "# HSBC Mutual Fund\n",
    "# UTI Mutual Fund\n",
    "# Angel One Mutual Fund\n",
    "# Unifi Mutual Fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axis Asset Management Company Limited\n",
    "# Aditya Birla Sun Life AMC Limited\n",
    "# Bank of India Investment Managers Private Limited\n",
    "# Canara Robeco Asset Management Company Limited\n",
    "# PGIM India Asset Management Private Limited\n",
    "# DSP Investment Managers Private Limited\n",
    "# Edelweiss Asset Management Limited\n",
    "# Quant Money Managers Limited\n",
    "# Franklin Templeton Asset Management (India) Private Limited\n",
    "# HDFC Asset Management Company Limited\n",
    "# HSBC Asset Management (India) Private Limited\n",
    "# ICICI Prudential Asset Management Company Limited\n",
    "# Bandhan AMC Limited\n",
    "# 360 ONE Asset Management Limited\n",
    "# IL&FS Infra Asset Management Limited\n",
    "# Groww Asset Management Limited\n",
    "# Invesco Asset Management (India) Private Limited\n",
    "# JM Financial Asset Management Limited\n",
    "# Kotak Mahindra Asset Management Company Limited(KMAMCL)\n",
    "# LIC Mutual Fund Asset Management Limited\n",
    "# Mahindra Manulife Investment Management Private Limited\n",
    "# Mirae Asset Investment Managers (India) Private Limited\n",
    "# Motilal Oswal Asset Management Company Limited\n",
    "# PPFAS Asset Management Private Limited\n",
    "# Quantum Asset Management Company Private Limited\n",
    "# Nippon Life India Asset Management Limited\n",
    "# SBI Funds Management Limited\n",
    "# Shriram Asset Management Company Limited\n",
    "# Sundaram Asset Management Company Limited\n",
    "# Tata Asset Management Private Limited\n",
    "# Taurus Asset Management Company Limited\n",
    "# Union Asset Management Company Private Limited\n",
    "# UTI Asset Management Company Limited\n",
    "# WhiteOak Capital Asset Management Limited\n",
    "# ITI Asset Management Limited\n",
    "# Navi AMC Limited\n",
    "# NJ Asset Management Private Limited\n",
    "# Samco Asset Management Private Limited\n",
    "# Trust Asset Management Private Limited\n",
    "# Baroda BNP Paribas Asset Management India Private Limited\n",
    "# Bajaj Finserv Asset Management Limited\n",
    "# Helios Capital Asset Management (India) Private Limited\n",
    "# Zerodha Asset Management Private Limited\n",
    "# Old Bridge Asset Management Private Limited\n",
    "# Angel One Asset Management Company Limited\n",
    "# Unifi Asset Management Private Limited"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_generic_data(self, main_key: str, data: list, pattern: str):\n",
    "    final_dict = {}\n",
    "    for text in data:\n",
    "        text = re.sub(self.REGEX['escape'], \"\", text.strip())\n",
    "        matches = re.findall(self.REGEX[pattern], text, re.IGNORECASE)\n",
    "        for key, value in matches:\n",
    "            final_dict[key] = value\n",
    "    return {main_key: final_dict}\n",
    "\n",
    "def _extract_str_data(self, key: str, data: list):\n",
    "    return {key: ' '.join(data)}\n",
    "\n",
    "def _extract_manager_data(self, main_key: str, data: list, pattern:str):\n",
    "    final_list = []\n",
    "    for i in range(0, len(data), 3):\n",
    "        txt = \" \".join(data[i:i+3])\n",
    "        txt = re.sub(self.REGEX['escape'], \"\", txt).strip()\n",
    "        if matches := re.findall(self.REGEX[pattern], txt, re.IGNORECASE):\n",
    "            for match in matches:\n",
    "                name, desig, since, exp = match\n",
    "                final_list.append({\n",
    "                    \"name\": name,\n",
    "                    \"designation\": desig,\n",
    "                    \"managing_since\": since,\n",
    "                    \"experience\": exp\n",
    "                })\n",
    "    return {main_key: final_list}\n",
    "\n",
    "def _extract_dum_data(self, key, data):\n",
    "    return {key: data}\n",
    "\n",
    "def _extract_scheme_data(self,main_key:str,data:list, pattern:str):\n",
    "    regex_ = self.REGEX[pattern] #list\n",
    "    mention_start = regex_[:-1]\n",
    "    mention_end = regex_[1:]\n",
    "\n",
    "    patterns = [r\"({start})\\s*(.+?)\\s*({end}|$)\".format(start=start, end=end)\n",
    "        for start, end in zip(mention_start, mention_end)]\n",
    "    \n",
    "    final_dict = {}\n",
    "    scheme_data = \" \".join(data)\n",
    "    for pattern in patterns:\n",
    "        if matches:= re.findall(pattern, scheme_data, re.DOTALL|re.IGNORECASE):\n",
    "            for match in matches:\n",
    "                key, value, dummy = match\n",
    "                value = value.strip()\n",
    "                final_dict[key] = value\n",
    "    \n",
    "    return {main_key:final_dict}\n",
    "\n",
    "def match_regex_to_content(self, string: str, data: list, *args):\n",
    "    for pattern, (func_name, regex_key) in self.PATTERN_TO_FUNCTION.items():\n",
    "        if re.match(pattern, string, re.IGNORECASE):\n",
    "            func = getattr(self, func_name)\n",
    "            if regex_key:\n",
    "                return func(string, data, regex_key)\n",
    "            return func(string, data)\n",
    "    return self._extract_dum_data(string, data)\n",
    "\n",
    "def _extract_load_data(self,main_key:str,data:list, pattern:str):\n",
    "        load_data = \" \".join(data)\n",
    "        load_data = re.sub(r\"[\\^*\\$:;~]\",\"\",load_data).strip()\n",
    "        final_dict = {}\n",
    "        if match:= re.findall(self.REGEX[pattern],load_data.strip(), re.IGNORECASE):\n",
    "            exit_,entry_ = match[0]\n",
    "            final_dict['entry_load'] = entry_,\n",
    "            final_dict['exit_load'] = exit_\n",
    "        return {main_key:final_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r'([\\d,]+).*?([\\d,]+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(?:Entry Load)?\\s*(Nil|.*?)\\s*Exit Load\\s*(.*)$'\n",
    "for fund, content in final_text.items():\n",
    "    check = 'scheme_details.load_structure'\n",
    "    if check in content:\n",
    "        text =re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+', \"\",content[check]).strip()\n",
    "        print(text)\n",
    "        match = re.findall(pattern,text, re.IGNORECASE)\n",
    "        print(match)\n",
    "        \n",
    "pattern = r'(AUM|Monthly Average AUM)\\s*([\\d,.]+)'\n",
    "for fund, content in final_text.items():\n",
    "    check = 'aum'\n",
    "    if check in content:\n",
    "        for text in  content[check]:\n",
    "            text =re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+', \"\",text).strip()\n",
    "            print(text)\n",
    "            match = re.findall(pattern,text, re.IGNORECASE)\n",
    "            print(match)\n",
    "            \n",
    "pattern = r'(?:Entry Load)?\\s*(Nil|.*?)\\s*Exit Load\\s*(.*)$'\n",
    "for fund, content in final_text.items():\n",
    "    check = 'scheme_details.load_structure'\n",
    "    if check in content:\n",
    "        all_text = \"\".join(content[check])\n",
    "        all_text =re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+', \"\", all_text).strip()\n",
    "        print(all_text)\n",
    "        print(re.findall(pattern,all_text, re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'([A-Za-z\\s]+)\\s*\\(Managing Since\\s*([A-Za-z0-9\\s]+) and overall experience of ([a-z0-9\\s]+)\\)'\n",
    "nav_pattern = r'(Growth|IDCW)\\s*([\\d,]+\\.?\\d+)\\s*([\\d,]+\\.?\\d+)'\n",
    "pattern = r'(Std. Dev|Sharpe Ratio|Portfolio Beta|R Squared|Treynor|Jenson)\\s+([\\d.-]+|NA)\\s+([\\d.-]+|NA)'\n",
    "expense_pattern = r'(Regular|Direct)\\s*([\\d,.]+)'\n",
    "ptr_pattern = r'([\\d,]+\\.\\d+)'\n",
    "manager =  r'(?:Mr\\.?|Mrs\\.?|Ms\\.?)\\s*([\\w\\s]+)'\n",
    "for fund, content in final_text.items():\n",
    "    check = 'fund_manager'\n",
    "    if check in content:\n",
    "        # all_text = \" \".join(content[check])\n",
    "        # all_text = re.sub(r'[\\^\\-,:]+',\" \", all_text.strip())\n",
    "        for text in content[check]:\n",
    "            text = re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+',\" \", text.strip())\n",
    "            if matches := re.findall(manager, text, re.IGNORECASE):\n",
    "                print(matches)\n",
    "        # for text in content[check]:\n",
    "        #     print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_start = [\n",
    "        \"Date of Allotment\",\n",
    "        \"Fund Manager\",\n",
    "        \"Fund Size\",\n",
    "        \"Load Structure\",\n",
    "        \"Benchmark\",\n",
    "        \"Minimum Additional\",\n",
    "        r\"Minimum Redemption\\s*\\/\\s*Switch-out Amount\",\n",
    "    ]\n",
    "    \n",
    "mention_end = mention_start[1:] + [\"End_of_Data\"]\n",
    "\n",
    "# Generate regex patterns dynamically\n",
    "patterns = [r\"({start}\\s*)(.+?)({end}|$)\".format(start=start, end=end)\n",
    "    for start, end in zip(mention_start, mention_end)]\n",
    "final_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_keys(json_files):\n",
    "    unique_keys = set()  # Store unique keys\n",
    "\n",
    "    for file in json_files:\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "                for fund_name, fund_data in data.items():\n",
    "                    if isinstance(fund_data, dict):\n",
    "                        extract_keys(fund_data, unique_keys)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    return unique_keys\n",
    "\n",
    "def extract_keys(data, key_set):\n",
    "    \"\"\"Recursively extract keys from JSON data.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            key_set.add(\"_\".join(key.lower().split(\" \")))\n",
    "            extract_keys(value, key_set)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            extract_keys(item, key_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = r\"C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\"  # Update this to your folder path\n",
    "json_files = [os.path.join(json_folder, file) for file in os.listdir(json_folder) if file.endswith('.json')]\n",
    "unique_keys = get_unique_keys(json_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, pprint\n",
    "from app.pdfParse import Reader\n",
    "from app.fundRegex import FundRegex\n",
    "import fitz\n",
    "\n",
    "class FranklinTempleton(Reader):\n",
    "    PARAMS = {\n",
    "        'fund': [[25,20],r\"^(Franklin|Templeton).*$\",[16,24],[-65794]], #[flag], regex_fund_name, range(font_size), [font_color]\n",
    "        'clip_bbox': [(0,100,180,812)],\n",
    "        'line_x': 180.0,\n",
    "        'data': [[6,9],[-16751720],30.0,['ZurichBT-BoldCondensed']], #sizes, color, set_size font_name\n",
    "        'content_size':[30.0,10.0]\n",
    "    }\n",
    "    \n",
    "    REGEX = {\n",
    "        'nav': r'(Growth Plan|IDCW Plan|Direct Growth Plan|Direct IDCW Plan)\\s*([\\d\\-,]+\\.\\d+)',\n",
    "        'metric': r'(Sharpe Ratio|Standard Deviation|Beta|Annualised)[\\s]+([\\d\\-,]+\\.\\d+)',\n",
    "        'expense': r'(Regular|Direct)\\s*([\\d,.-]+)',\n",
    "        'load': r'ENTRY LOA(.*?)\\s*EXIT LOAD\\s*(.*?)$',\n",
    "        'aum': r'(Month End|Monthly Average)\\s*([\\d,.\\-]+)',\n",
    "        'ptr':r'^(Portfolio Turnover|Total Portfolio).*\\s*([\\d\\-,]+\\.\\d+)',\n",
    "        # 'manager': r'([A-Za-z\\s]+)\\s*\\(Managing Since\\s*([A-Za-z0-9\\s]+) and overall experience of ([a-z0-9\\s]+)\\)',\n",
    "        'escape': r'[^A-Za-z0-9\\s\\-\\(\\).,]+'\n",
    "    }\n",
    "\n",
    "    PATTERN_TO_FUNCTION = {\n",
    "        r\"^(date|benchmark|investment|type_of|scheme|multiples|minimum).*\":(\"_extract_str_data\", None),\n",
    "        r\"^nav.*\":(\"_extract_generic_data\", \"nav\"),\n",
    "        # r\"^fund_mana.*\": self.__extract_manager_data,\n",
    "        r\"^aum.*\": (\"_extract_generic_data\", 'aum'),\n",
    "        r\"^portfolio_turnover_ratio\": (\"_extract_generic_data\", 'ptr'),\n",
    "        r\"^load\": (\"_extract_load_data\", 'load'),\n",
    "        r\"^metrics\": (\"_extract_generic_data\", \"metric\"),\n",
    "    }\n",
    "\n",
    "    def __init__(self, paths_config: str):\n",
    "        super().__init__(paths_config, self.PARAMS)\n",
    "    \n",
    "    def _extract_str_data(self, key: str, data: list):\n",
    "        return {key: ' '.join(data)}\n",
    "    \n",
    "    def _extract_dummy_data(self, main_key:str, data:list):\n",
    "        return{main_key:data}\n",
    "    \n",
    "    def _extract_generic_data(self, main_key: str, data: list, pattern: str):\n",
    "        final_dict = {}\n",
    "        for text in data:\n",
    "            text = re.sub(self.REGEX['escape'], \"\", text.strip())\n",
    "            matches = re.findall(self.REGEX[pattern], text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                if len(match) == 2:\n",
    "                    key, value = match\n",
    "                    final_dict[key.strip()] = value.strip()\n",
    "                elif len(match) == 3:\n",
    "                    key,v1,v2 = match\n",
    "                    final_dict[key.strip()] = v1.strip()\n",
    "        return {main_key: final_dict}\n",
    "    \n",
    "    def _extract_manager_data(self, main_key: str, data: list, pattern:str):\n",
    "        manager_data = \" \".join(data)\n",
    "        manager_data = re.sub(self.REGEX[pattern], \"\", manager_data).strip()\n",
    "        final_list = []\n",
    "        if matches := re.findall(self.REGEX['manager'], manager_data, re.IGNORECASE):\n",
    "            for match in matches:\n",
    "                name, since, exp = match\n",
    "                final_list.append({\n",
    "                    \"name\": name.strip(),\n",
    "                    \"designation\": \"\",\n",
    "                    \"managing_since\": since.strip(),\n",
    "                    \"experience\": exp.strip()\n",
    "                })\n",
    "        return {main_key: final_list}\n",
    "    \n",
    "    def _extract_load_data(self,main_key:str,data:list, pattern:str):\n",
    "        load_data = \" \".join(data)\n",
    "        load_data = re.sub(self.REGEX['escape'], \"\", load_data).strip()\n",
    "        final_dict = {}\n",
    "        if match:= re.findall(self.REGEX[pattern],load_data.strip(), re.IGNORECASE):\n",
    "            exit_,entry_ = match[0]\n",
    "            final_dict['entry_load'] = entry_,\n",
    "            final_dict['exit_load'] = exit_\n",
    "        return {main_key:final_dict}\n",
    "        \n",
    "    \n",
    "    def match_regex_to_content(self, string: str, data: list, *args):\n",
    "        for pattern, (func_name, regex_key) in self.PATTERN_TO_FUNCTION.items():\n",
    "            if re.match(pattern, string, re.IGNORECASE):\n",
    "                func = getattr(self, func_name)\n",
    "                if regex_key and regex_key in self.REGEX:\n",
    "                    return func(string, data, regex_key)\n",
    "                return func(string, data)\n",
    "        return self._extract_dummy_data(string, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(data, keys, target_key):\n",
    "    \"\"\"\n",
    "    Merges values of two keys inside each fund and stores the result in target_key.\n",
    "\n",
    "    :param data: Dictionary containing funds.\n",
    "    :param keys: List of two keys whose values need to be merged.\n",
    "    :param target_key: The key where the merged result should be stored.\n",
    "    \"\"\"\n",
    "    if len(keys) != 2:\n",
    "        raise ValueError(\"Exactly two keys must be provided for merging.\")\n",
    "\n",
    "    key1, key2 = keys\n",
    "\n",
    "    for fund, values in data.items():\n",
    "        if key1 in values and key2 in values:\n",
    "            val1, val2 = values[key1], values[key2]\n",
    "\n",
    "            if isinstance(val1, str) and isinstance(val2, str):\n",
    "                values[target_key] = val1 + val2\n",
    "            elif isinstance(val1, list) and isinstance(val2, list):\n",
    "                values[target_key] = val1 + val2\n",
    "            elif isinstance(val1, dict) and isinstance(val2, dict):\n",
    "                values[target_key] = {**val1, **val2}\n",
    "            else:\n",
    "                raise TypeError(f\"Cannot merge different data types: {type(val1)} and {type(val2)}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example Usage\n",
    "sample = {\n",
    "    \"fund_name1\": {\n",
    "        \"a\": \"Hello\",\n",
    "        \"b\": \" World\",\n",
    "        \"c\": {},\n",
    "    },\n",
    "    \"fund_name2\": {\n",
    "        \"a\": [1, 2, 3],\n",
    "        \"b\": [4, 5, 6],\n",
    "        \"c\": {},\n",
    "    },\n",
    "}\n",
    "\n",
    "merged_sample = merge_data(sample, [\"a\", \"b\"], \"a\")\n",
    "print(merged_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT CODE DONT DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"wip\"\"\"\n",
    "class DSP(Reader):\n",
    "    \n",
    "    PARAMS = {\n",
    "        'fund': [[20,16], r'^(DSP|Bharat).*(Fund|ETF|FTF|FOF)$|^(DSP|Bharat)',[14,24],[-1]],\n",
    "        'clip_bbox': [(0,5,120,812),],#[480,5,596,812]],\n",
    "        'line_x': 120.0,\n",
    "        'data': [[7,10], [-16777216], 30.0, ['TrebuchetMS-Bold']],\n",
    "        'content_size':[30.0,10.0]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    def __init__(self, paths_config:str):\n",
    "        super().__init__(paths_config, self.PARAMS)\n",
    "        \n",
    "    #REGEX\n",
    "    def __return_all_data(self,main_key,data:list):\n",
    "        return {main_key:data}\n",
    "    \n",
    "    def __extract_inv_data(self,main_key:str, data:list):            \n",
    "        return {main_key: ' '.join(data)}\n",
    "    \n",
    "    #MAPPING\n",
    "    def match_regex_to_content(self, string:str, data:list):\n",
    "        check_header = string\n",
    "        if re.match(r\"^investment.*\", check_header, re.IGNORECASE):\n",
    "            return self.__extract_inv_data(string,data)\n",
    "        # elif re.match(r\"^aum.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_aum_data(string, data)\n",
    "        # elif re.match(r\"^fund_mana.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_manager_data(string, data)\n",
    "        # elif re.match(r\"^metrics.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_metric_data(string, data)\n",
    "        return self.__return_all_data(string,data) \n",
    "\n",
    "\"\"\" thissssssssssssssssssssssss\"\"\"\n",
    "class HSBC(Reader):\n",
    "    \n",
    "    PARAMS = {\n",
    "        'fund': [[20,16], r'^(HSBC|Bharat).*Fund$',[12,20],[-1237724]],\n",
    "        'clip_bbox': [(0,100,180,812)],\n",
    "        'line_x': 180.0,\n",
    "        'data': [[6,8], [-16777216], 30.0, ['Arial-BoldMT']],\n",
    "        'content_size':[30.0,10.0]\n",
    "    }\n",
    "    \n",
    "    def __init__(self,paths_config:str):\n",
    "        super().__init__(paths_config, self.PARAMS)\n",
    "        \n",
    "    #Fund REGEX\n",
    "    def __return_all_data(self,key,data:list):\n",
    "        return {key:data}\n",
    "    \n",
    "    def __extract_inv_data(self,key:str, data:list):            \n",
    "        return {key: ' '.join(data)}\n",
    "    \n",
    "    #MAPPING\n",
    "    def match_regex_to_content(self, string:str, data:list):\n",
    "        check_header = string\n",
    "        if re.match(r\"^(investment).*\", check_header, re.IGNORECASE):\n",
    "            return self.__extract_inv_data(string,data)\n",
    "        # elif re.match(r\"^total.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_total_expense_data(string, data)\n",
    "        # elif re.match(r\"^nav.*\", check_header, re.IGNORECASE):\n",
    "        #     return self.__extract_nav_data(string, data)\n",
    "        # elif re.match(r\"^portfolio.*\", check_header, re.IGNORECASE): #error here portfolio is read\n",
    "        #     return self.__extract_scheme_data(string, data)\n",
    "        return self.__return_all_data(string,data)     \n",
    "\n",
    "class LIC(Reader):\n",
    "    \n",
    "    PARAMS = {\n",
    "        'fund': [[20,16], r'^(LIC|Bharat).*(Fund|ETF|FTF|FOF)$',[12,20],[-15319437]],\n",
    "        'clip_bbox': [(0,5,150,812),],\n",
    "        'line_x': 150.0,\n",
    "        'data': [[5,8], [-15445130,-14590595], 30.0, ['Frutiger-Bold']],\n",
    "        \"content_size\":[30.0,10.0]\n",
    "    }\n",
    "    def __init__(self,paths_config:str):\n",
    "        super().__init__(paths_config, self.PARAMS)          \n",
    "                    \n",
    "class QuantMF(Reader):\n",
    "    PARAMS = {\n",
    "        'fund': [[16,0], r'^(quant).*(Fund|ETF|EOF|FOF|FTF|Path)$',[16,24],[-13604430]],\n",
    "        'clip_bbox': [(0,5,180,812)],\n",
    "        'line_x': 180.0,\n",
    "        'data': [[6,11], [-16777216], 30.0, ['Calibri,Bold',]],\n",
    "        'content_size':[30.0,10.0]\n",
    "        }\n",
    "    \n",
    "    def __init__(self, paths_config:str):\n",
    "        super().__init__(paths_config,self.PARAMS)\n",
    "\n",
    "class PPFAIS(Reader):\n",
    "    PARAMS = {\n",
    "        'fund': [[16,20], r'^(Parag).*',[14,24],[-16777216,-13159371,-14869475]],\n",
    "        'clip_bbox': [(0,65,290,812)],\n",
    "        'line_x': 290.0,\n",
    "        'data': [[6,10], [-65794], 30.0, ['Arial-BoldMT',]]\n",
    "        }\n",
    "    \n",
    "    def __init__(self, paths_config:str):\n",
    "        super().__init__(paths_config,self.PARAMS)\n",
    "        \n",
    "    #REGEX\n",
    "    def __return_all_data(self,main_key,data:list):\n",
    "        return {main_key:data}\n",
    "    \n",
    "    def __extract_inv_data(self,main_key:str, data:list):            \n",
    "        return {main_key: ' '.join(data)}\n",
    "    \n",
    "    #MAPPING\n",
    "    def match_regex_to_content(self, string: str, data: list):\n",
    "        pattern_to_function = {\n",
    "            r\"^investment.*\": self.__extract_inv_data,\n",
    "            # r\"^scheme.*\": self.__extract_scheme_data,\n",
    "            # r\"^metrics.*\": self.__extract_metric_data,\n",
    "        }\n",
    "\n",
    "        for pattern, func in pattern_to_function.items():\n",
    "            if re.match(pattern, string, re.IGNORECASE):\n",
    "                return func(string, data)\n",
    "\n",
    "        return self.__return_all_data(string, data)\n",
    "    \n",
    "class SBI(Reader):\n",
    "    \n",
    "    PARAMS = {\n",
    "        'fund': [[16,0], r'^().*',[12,20],[-12371562]],\n",
    "        'clip_bbox': [(0,5,180,812)],\n",
    "        'line_x': 180.0,\n",
    "        'data': [[6,11], [-12371562], 30.0, ['Calibri,Bold',]]}\n",
    "    \n",
    "    def __init__(self, paths_config:str):\n",
    "        super().__init__(paths_config,self.PARAMS)\n",
    "          \n",
    "class PGIM(Reader):\n",
    "    PARAMS = {\n",
    "        'fund': [[20,4],r'^.*(Plan|Sensex|Fund|Path|ETF|FOF|EOF|Funds)$',[16,30],[-1]], #FUND NAME DETAILS order-> flag, regex_fund_name, font_size, font_color\n",
    "        'clip_bbox': [(0,115,210,812)],\n",
    "        'line_x': 210.0,\n",
    "        'data': [[6,12],[-1],30.0,['PrudentialModern-Bold']], #sizes, color, set_size\n",
    "        'content_size':[30.0,10.0]\n",
    "    }\n",
    "    \n",
    "    def __init__(self, path: str,dry:str,fin:str, rep:str):\n",
    "        super().__init__(path,dry,fin,rep, self.PARAMS)\n",
    "    \n",
    "    #Fund Regex  \n",
    "    def __return_all_data(self,main_key:str,data:list):\n",
    "        return{main_key:data}\n",
    "    def __extract_fund_data(self,main_key:str, data:list):\n",
    "        return {main_key:data}\n",
    "    def __extract_invest_data(self,main_key:str,data:list):\n",
    "        return {main_key: \" \".join(data)}\n",
    "    \n",
    "    #MAPPING FUNCTION\n",
    "    def match_regex_to_content(self, string: str, data: list):\n",
    "        pattern_to_function = {\n",
    "            r\"^(investment|minimum|entry|exit|load|plans|scheme_launch|benchmark).*\": self.__extract_invest_data,\n",
    "            r\"^fund_mana.*\": self.__extract_fund_data,\n",
    "        }\n",
    "\n",
    "        for pattern, func in pattern_to_function.items():\n",
    "            if re.match(pattern, string, re.IGNORECASE):\n",
    "                return func(string, data)\n",
    "\n",
    "        return self.__return_all_data(string, data)\n",
    "\n",
    "\n",
    "#something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " @staticmethod\n",
    "    def dump_pickle_data(data:dict, file_path:str):\n",
    "        try:\n",
    "            with open(file_path, 'wb') as file:\n",
    "                pickle.dump(data, file)\n",
    "            print(f\"\\nData successfully dumped to {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError while dumping data to {file_path}: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_pickle_data(file_path:str):\n",
    "\n",
    "        try:\n",
    "            with open(file_path, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "            print(f\"\\nData successfully loaded from {file_path}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError while loading data from {file_path}: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #EXTRACT\n",
    "    #  def extract_clipped_data(self,input:str, pages:list, title:dict, *args:list):\n",
    "        \n",
    "    #     document = fitz.open(input)\n",
    "    #     final_list = []\n",
    "    #     bboxes = self.PARAMS['clip_bbox'] if not args else args[0] #bbox provided externally\n",
    "    #     fund_names = title\n",
    "    \n",
    "    #     for pgn in pages:\n",
    "    #         page = document[pgn]\n",
    "    #         fundName = fund_names[pgn]\n",
    "\n",
    "    #         blocks = []\n",
    "    #         seen_blocks = set()  # To store unique blocks based on content and bbox\n",
    "\n",
    "    #         for bbox in bboxes:\n",
    "    #             page_blocks = page.get_text('dict', clip=bbox)['blocks']\n",
    "    #             for block in page_blocks:\n",
    "    #                 if block['type'] == 0 and 'lines' in block: #type 0 means text block\n",
    "    #                     #hash_key\n",
    "    #                     block_key = (tuple(block['bbox']), tuple(tuple(line['spans'][0]['text'] for line in block['lines'])))\n",
    "    #                     if block_key not in seen_blocks:\n",
    "    #                         seen_blocks.add(block_key)\n",
    "    #                         blocks.append(block)\n",
    "\n",
    "    #         sorted_blocks = sorted(blocks, key=lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "\n",
    "    #         final_list.append({\n",
    "    #             \"pgn\": pgn,\n",
    "    #             \"fundname\": fundName,\n",
    "    #             \"block\": sorted_blocks\n",
    "    #         })\n",
    "\n",
    "    #     document.close()\n",
    "    #     return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_data_relative_line(self,path: str,pageSelect:list, side: str, titles:dict):\n",
    "        \n",
    "    #     doc = fitz.open(path)\n",
    "    #     final_list = []\n",
    "    #     line_x = self.PARAMS['line_x']\n",
    "            \n",
    "    #     for pgn in pageSelect:\n",
    "    #         page, fundname = doc[pgn],titles[pgn]\n",
    "    #         blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "    #         filtered_blocks = [block for block in blocks if block['type']==0 and 'lines' in block]\n",
    "    #         extracted_blocks = []\n",
    "\n",
    "    #         # Keep track of blocks\n",
    "    #         added_blocks = set()\n",
    "\n",
    "    #         for block in filtered_blocks:\n",
    "    #             block_id = id(block)  # Unique identifier\n",
    "\n",
    "    #             for line in block.get(\"lines\", []):\n",
    "    #                 for span in line.get(\"spans\", []):\n",
    "    #                     x0, _ = span[\"origin\"]\n",
    "\n",
    "    #                     #left or right\n",
    "    #                     if side == \"left\" and x0 < line_x and block_id not in added_blocks:\n",
    "    #                         extracted_blocks.append(block)\n",
    "    #                         added_blocks.add(block_id)  #added\n",
    "    #                     elif side == \"right\" and x0 > line_x and block_id not in added_blocks:\n",
    "    #                         extracted_blocks.append(block)\n",
    "    #                         added_blocks.add(block_id)  #\n",
    "\n",
    "    #         # Sort extracted blocks\n",
    "    #         sorted_blocks = sorted(extracted_blocks, key=lambda x: (x[\"bbox\"][1], x[\"bbox\"][0]))\n",
    "\n",
    "    #         final_list.append({\"pgn\": pgn,\"fundname\": fundname,\"block\": sorted_blocks})\n",
    "\n",
    "    #     doc.close()\n",
    "\n",
    "    #     return final_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

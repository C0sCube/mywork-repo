{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pprint, json, os, logging\n",
    "\n",
    "PATHS_CONFIG =os.path.join(os.getcwd(),'paths.json') #get path to paths.json\n",
    "\n",
    "with open(PATHS_CONFIG,'r') as file:\n",
    "    PATH = json.load(file)\n",
    "    \n",
    "from app.fund_data import *\n",
    "from app.json_handler import *\n",
    "from app.utils import Helper\n",
    "from logging_config import logger\n",
    "\n",
    "logger.info(\"Application Started !!\")\n",
    "mutual_fund = Helper.get_fund_paths(PATH['dirs']['fund_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 one focused equity fund\n",
      "360 one flexicap fund\n",
      "360 one quant fund\n",
      "360 one elss tax saver nifty 50 index fund\n",
      "360 one balanced hybrid fund\n",
      "360 one balanced hybrid fund\n",
      "360 one dynamic bond fund\n",
      "360 one liquid fund\n",
      "\n",
      "Doc Saved At: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\pdf_report.xlsx\n",
      "\n",
      "Pages to Extract: [5, 6, 7, 8, 9, 10, 11, 12]\n",
      "\n",
      "---<<360 one focused equity fund>>---at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "---<<360 one flexicap fund>>---at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "---<<360 one quant fund>>---at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "---<<360 one elss tax saver nifty 50 index fund>>---at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "---<<360 one balanced hybrid fund>>---at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "---<<360 one balanced hybrid fund>>---at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "---<<360 one dynamic bond fund>>---at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n",
      "\n",
      "---<<360 one liquid fund>>---at: C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\DryRun.pdf\n"
     ]
    }
   ],
   "source": [
    "'''360 ONE MAIN FILE CODE''' #No issues as of now\n",
    "amc_name = \"360 ONE Mutual Fund\"\n",
    "logger.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = ThreeSixtyOne(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "data = object.get_data(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " JSON saved at C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\output\\dump_360_16_26.json\n"
     ]
    }
   ],
   "source": [
    "final_text = object.refine_extracted_data(extracted_text, flatten=True)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_ = [\n",
    "        \"Date of Allotment\",\n",
    "        \"Bloomberg\\\\s*Code\",\n",
    "        \"Benchmark\\\\s*Index\",\n",
    "        \"Plans Offered\",\n",
    "        \"Options Offered\",\n",
    "        \"Minimum Application\",\n",
    "        \"New Purchase\",\n",
    "        \"Additional Purchase\",\n",
    "        \"Weekly SIP Option\",\n",
    "        \"Monthly SIP Option\",\n",
    "        \"Quarterly SIP Option\",\n",
    "        \"Entry Load\",\n",
    "        \"Exit Load\",\n",
    "        \"Dematerialization\",\n",
    "        \"Portfolio Turnover\",\n",
    "        \"EOL\",\n",
    "      ]\n",
    "mention_start = regex_[:-1]\n",
    "mention_end = regex_[1:]\n",
    "\n",
    "patterns = [r\"(\\b{start}\\b)\\s*(.+?)\\s*(\\b{end}\\b|$)\".format(start=start, end=end)\n",
    "    for start, end in zip(mention_start, mention_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateofallotment bloombergcode benchmarkindex plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover\n",
      "[('bloombergcode', 'benchmarkindex plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover', '')]\n",
      "[('benchmarkindex', 'plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover', '')]\n",
      "[('dematerialization', 'portfolioturnover', '')]\n",
      "dateofallotment bloombergcode benchmarkindex plansoffered optionsoffered newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover\n",
      "[('bloombergcode', 'benchmarkindex plansoffered optionsoffered newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover', '')]\n",
      "[('benchmarkindex', 'plansoffered optionsoffered newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover', '')]\n",
      "[('dematerialization', 'portfolioturnover', '')]\n",
      "dateofallotment bloombergcode benchmarkindex plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover\n",
      "[('bloombergcode', 'benchmarkindex plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover', '')]\n",
      "[('benchmarkindex', 'plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover', '')]\n",
      "[('dematerialization', 'portfolioturnover', '')]\n",
      "dateofallotment bloombergcode benchmarkindex plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover\n",
      "[('bloombergcode', 'benchmarkindex plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover', '')]\n",
      "[('benchmarkindex', 'plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization portfolioturnover', '')]\n",
      "[('dematerialization', 'portfolioturnover', '')]\n",
      "dateofallotment bloombergcode benchmarkindex plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization\n",
      "[('bloombergcode', 'benchmarkindex plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization', '')]\n",
      "[('benchmarkindex', 'plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization', '')]\n",
      "dateofallotment benchmarkindex plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization\n",
      "[('benchmarkindex', 'plansoffered optionsoffered minimumapplication newpurchase additionalpurchase weeklysipoption monthlysipoption quarterlysipoption entryload exitload dematerialization', '')]\n"
     ]
    }
   ],
   "source": [
    "pat = patterns\n",
    "for fund, content in final_text.items():\n",
    "    check = 'scheme_details'\n",
    "    if check in content:\n",
    "        all_text = \" \".join(content[check])\n",
    "        all_text =re.sub(r'[^A-Za-z0-9\\s\\-\\(\\).,]+', \"\", all_text).strip()\n",
    "        print(all_text)\n",
    "        for pattern in pat:\n",
    "            if matches:= re.findall(pattern,all_text, re.IGNORECASE):\n",
    "                print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Axis Mutual Fund\"\n",
    "\"Bank of India Mutual Fund\" \n",
    "\"Groww Mutual Fund\" \n",
    "\"HDFC Mutual Fund\"\n",
    "\"HSBC Mutual Fund\"\n",
    "\"ICICI Prudential Mutual Fund\"\n",
    "\"LIC Mutual Fund\" \n",
    "\"Old Bridge Mutual Fund\" \n",
    "\"PGIM India Mutual Fund\"\n",
    "\"PPFAS Mutual Fund\"\n",
    "\"Quant Mutual Fund\"\n",
    "\"SBI Mutual Fund\"\n",
    "\"Shriram Mutual Fund\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ADITYA BIRLA FILE CODE\"\"\" #Issue: highlight count must be lower\n",
    "#Issue: data on both side ends so issue coming , three clips\n",
    "\n",
    "amc_name = 'Aditya Birla Sun Life Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = AdityaBirla(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 10)\n",
    "title = df.title.to_dict()\n",
    "pages = [12, 14, 16, 18, 20, 22, 24, 26, 27, 28, 30, 32, 34, 35, 36, 38, 40, 44, 47, 49, 53, 55, 57, 61, 63, 66, 68, 69, 72, 73, 74, 75, 76, 78, 80, 81, 85, 95, 102, 104, 108, 110, 112, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 141, 143, 147, 149, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 170, 171, 172, 173, 174]\n",
    "# pages = [12,14,16]\n",
    "data = object.get_data(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,[\"sip\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BANDHAN MF FILE MAIN CODE\"\"\" # rgex for fund manager\n",
    "\n",
    "amc_name = \"Bandhan Mutual Fund\"\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Bandhan(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path,6)\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BARODA BNP MAIN FILE CODE\"\"\" #Issue: lumpsum arrange date \n",
    "\n",
    "amc_name = 'Baroda BNP Paribas Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = BarodaBNP(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 7)\n",
    "\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
    "title = object.get_proper_fund_names(path, pages, (0,0,210,75))\n",
    "\n",
    "data = object.get_data_via_line(path,pages,'left',title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"*BANK OF INDIA\"\"\" #Issues: Fund Manger extraction\n",
    "\n",
    "amc_name = 'Bank of India Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = BankOfIndia(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df= object.check_and_highlight(path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "\n",
    "data = object.get_data(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "\n",
    "# final_clean_text = Helper.drop_empty_dict_values(extracted_text)\n",
    "# final_text = object.refine_extracted_data(final_clean_text)\n",
    "# final_clean_text = Helper.drop_keys_by_regex(final_text, [r'^(december|total|who_|treasury|cretificate_of|equity|this_produc).*'])\n",
    "# Helper.quick_json_dump(final_clean_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"*BAJAJ FINSERV MAIN FILE CODE\"\"\" #set clip correctly #minor of dropping keys of final dict\n",
    "\n",
    "amc_name = 'Bajaj finserv Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = BajajFinServ(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 7)\n",
    "pages = [15, 17, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.get_data(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"*CANARA MUTUAL FUND\"\"\" \n",
    "\n",
    "amc_name = 'Canara Robeco Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Canara(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 7)\n",
    "\n",
    "pages = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.get_data(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "# final_text = Helper.merge_key_values(extracted_text,'fund_information','before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"*DSP MAIN FILE CODE\"\"\" #Issue: highlight count must be lower\n",
    "#Issue: data on both side ends so issue coming\n",
    "\n",
    "amc_name = 'DSP Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = DSP(PATHS_CONFIG)\n",
    "path = mutual_fund['DSP Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(path, 5)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]\n",
    "\n",
    "#segments\n",
    "nd1 = object.get_data_via_clip(path, pages,title)\n",
    "nd2 = object.get_data_via_clip(path, pages,title,[(480,5,596,812)])\n",
    "\n",
    "data = object.get_data()\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EDELWEISS MP FILE MAIN CODE\"\"\" #Issues: objective in seperate dict,#metrics are weird, scheme launch date issue\n",
    "\n",
    "amc_name = 'Edelweiss Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Edelweiss(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "\n",
    "path, df = object.check_and_highlight(path, 6)\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75]\n",
    "title,objectives = object.get_proper_fund_names(path,pages)\n",
    "\n",
    "data = object.get_data(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "# Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FRANKLIN TEMPLETON FILE MAIN CODE\"\"\"\n",
    "\n",
    "amc_name = \"Franklin Templeton Mutual Fund\"\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = FranklinTempleton(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 6)\n",
    "title = df.title.to_dict()\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "# Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"HELIOS MF FILE MAIN CODE\"\"\" \n",
    "\n",
    "amc_name = 'Helios Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Helios(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path,6)\n",
    "title = df.title.to_dict()\n",
    "pages =  [2, 4, 6, 8, 10]\n",
    "\n",
    "data = object.get_data(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text, flatten=True)\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INVESCO MF MAIN FILE CODE\"\"\" #Issue: two fund on same page\n",
    "\n",
    "amc_name = 'Invesco Mutual Fund'\n",
    "# logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "# object = Invesco(PATHS_CONFIG,amc_name)\n",
    "# path = mutual_fund[amc_name]\n",
    "\n",
    "# path,df = object.check_and_highlight(path, 7)\n",
    "# title = df.title.to_dict()\n",
    "# pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
    "\n",
    "# data = object.get_data_via_clip(path,pages,title)\n",
    "# extracted_text = object.get_generated_content(data)\n",
    "# final_text = object.refine_extracted_data(extracted_text)\n",
    "# Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ITI MAIN FILE CODE\"\"\" #Issues: more data cleaning\n",
    "\n",
    "amc_name = 'ITI Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = ITI(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text, flatten = True)\n",
    "secondary_text = object.refine_secondary_data(final_text)\n",
    "Helper.quick_json_dump(secondary_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"JM FUND MAIN FILE CODE\"\"\" #objective on left, sometimes date is with header\n",
    "#overlapppp\n",
    "\n",
    "amc_name = 'JM Financial Mutual Fund'\n",
    "# logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "# object = JMMF(PATHS_CONFIG,amc_name)\n",
    "# path = mutual_fund[amc_name]\n",
    "\n",
    "# path, df = object.check_and_highlight(path, 7)\n",
    "# title = df.title.to_dict()\n",
    "# pages = [22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37]\n",
    "\n",
    "# data = object.get_data_via_clip(path,pages,title)\n",
    "# extracted_text = object.get_generated_content(data)\n",
    "# final_text = object.refine_extracted_data(extracted_text)\n",
    "# Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"KOTAK FUND MAIN CODE\"\"\" #Issue: 1 or more fund on same page, # title overlap the content\n",
    "\n",
    "amc_name = 'Kotak Mahindra Mutual Fund'\n",
    "# logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "# object = Kotak(PATHS_CONFIG,amc_name)\n",
    "# path = mutual_fund[amc_name]\n",
    "\n",
    "# path, df = object.check_and_highlight(path, 7)\n",
    "\n",
    "# title = df.title.to_dict()\n",
    "# pages = [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 40, 41, 43, 44, 46, 48, 49, 50, 52, 54, 55, 56, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
    "\n",
    "# data = object.get_data_via_clip(path,pages,title)\n",
    "# extracted_text = object.get_generated_content(data)\n",
    "# final_text = object.refine_extracted_data(extracted_text)\n",
    "# Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MAHINDRA MANULIFE MAIN CODE\"\"\" #incrase pages count\n",
    "\n",
    "amc_name = 'Mahindra Manulife Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = MahindraManu(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path,df = object.check_and_highlight(path, 7)\n",
    "\n",
    "title = object.get_proper_fund_names(path,[i for i in range(1,80)])\n",
    "pages = [i for i in range(8,33)]\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text, flatten =True)\n",
    "secondary_text = object.refine_secondary_data(final_text)\n",
    "Helper.quick_json_dump(secondary_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MOTILAL OSWAL MAIN CODE FILE\"\"\" #Fund Manager Regex\n",
    "\n",
    "amc_name = 'Motilal Oswal Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = MotilalOswal(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path,df= object.check_and_highlight(path, 7)\n",
    "\n",
    "pages = [i for i in range(4,21)]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text, flatten= True)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MIRAE MAIN FILE CODE\"\"\"\n",
    "\n",
    "amc_name = 'Mirae Asset Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = MIRAE(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 7)\n",
    "pages = [25, 26, 27, 28, 29, 30, 31, 32, 33, 34,35, 36, 37, 38, 39, 40, 41,42,43,44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,61,62,63,64, 65, 66, 67, 68]\n",
    "title = object.get_proper_fund_names(path,pages)\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "# final_text = Helper.drop_keys_by_regex(final_text,[r'others'])\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NAVI MAIN FILE CODE\"\"\" #Issue: Left and right\n",
    "\n",
    "amc_name = 'Navi Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = NAVI(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "\n",
    "path,df = object.check_and_highlight(path,5)\n",
    "title = df.title.to_dict()\n",
    "pages = [2, 6, 8, 10, 13, 16, 18, 20, 22]\n",
    "\n",
    "nd1 = object.get_data_via_line(path,pages,'left',title)\n",
    "nd2 = object.get_data_via_line(path,pages,'right',title)\n",
    "\n",
    "data = Helper.merge_nested_dicts(nd1, nd2)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text, flatten = True)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,['^(industry_allocation|equity|this_product).*'])\n",
    "secondary_data = object.refine_secondary_data(final_text)\n",
    "Helper.quick_json_dump(secondary_data, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NIPPON MUTUAL FUND\"\"\"\n",
    "\n",
    "amc_name = 'Nippon India Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Nippon(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path,df = object.check_and_highlight(path, 7)\n",
    "pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text, flatten = True)\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NJMF MAIN CODE FILE\"\"\"\n",
    "\n",
    "amc_name = 'NJ Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = NJMF(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path,df = object.check_and_highlight(path, 7)\n",
    "pages = [1, 3, 5, 7, 9]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"QUANTUM MAIN FILE CODE\"\"\" #ISSUES: Clean data further\n",
    "\n",
    "amc_name = \"Quantum Mutual Fund\"\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Quantum(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path,df = object.check_and_highlight(path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 28, 29, 30]\n",
    " \n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SAMCO PDF FILE MAIN CODE\"\"\" \n",
    "\n",
    "amc_name = 'Samco Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Samco(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages =  [3, 5, 7, 9, 11, 13, 15, 17, 18]\n",
    "\n",
    "# data = object.get_data_via_clip(path,pages,title) #line\n",
    "# extracted_text = object.get_generated_content(data)\n",
    "# final_text = object.refine_extracted_data(extracted_text, flatten=True)\n",
    "# secondary_data = object.refine_secondary_data(final_text)\n",
    "# Helper.quick_json_dump(secondary_data,object.JSONPATH)\n",
    "data = object.extract_clipped_data(path,pages,title)\n",
    "data = object.extract_span_data(data,[])\n",
    "# clean_data = object.process_text_data(data)\n",
    "# nested, matrix = object.create_nested_dict(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SUNDARAM MAIN FILE CODE\"\"\"\n",
    "\n",
    "amc_name = 'Sundaram Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Sundaram(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path,df = object.check_and_highlight(path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "\n",
    "data = object.get_data_via_line(path,pages,\"left\",title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text,flatten = True)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,['^performance','market_capital','since_inception','^last','period'])\n",
    "secondary_data = object.refine_secondary_data(final_text)\n",
    "Helper.quick_json_dump(secondary_data,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TATA FILE MAIN CODE \"\"\"\n",
    "\n",
    "amc_name = \"Tata Mutual Fund\"\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Tata(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 10)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]\n",
    "\n",
    "# data = object.get_data_via_clip(path,pages,title)\n",
    "# extracted_text = object.get_generated_content(data)\n",
    "\n",
    "# final_text = Helper.drop_empty_dict_values(extracted_text)\n",
    "# final_text = object.refine_extracted_data(final_text)\n",
    "# Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TAURUS MAIN FILE CODE\"\"\" #Issues: Nothing Yet\n",
    "\n",
    "amc_name = 'Taurus Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Taurus(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df= object.check_and_highlight(path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [13, 14, 15, 16, 17, 19, 20]\n",
    "\n",
    "data = object.get_data_via_line(path,pages,'left',title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRUST MAIN FILE CODE\"\"\" #Issue: Clean data more, nested dict unload Invest Obj in right #Names coming as headers fund managers\n",
    "\n",
    "amc_name = 'Trust Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Trust(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df= object.check_and_highlight(path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UTI MAIN FILE CODE\"\"\"\n",
    "\n",
    "amc_name = 'UTI Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = UTI(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path,df = object.check_and_highlight(path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 46, 48, 50, 52, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77]\n",
    "\n",
    "data = object.get_data_via_line(path,pages,'left', title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "# final_text = Helper.drop_selected_dict_values(final_text,['high/low_nav_in_the_month','plans/options','porolio_details','market_capital'])\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UNION MUTUAL FUND\"\"\" #Issues: Major Issue\n",
    "\n",
    "amc_name = 'Union Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Union(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path,df = object.check_and_highlight(path, 7)\n",
    "pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,]\n",
    "title = df.title.apply(lambda x: \"Union \"+ x if x !=\"\" else x).to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WHITEOAK MUTUAL FUND\"\"\"\n",
    "\n",
    "amc_name = 'WhiteOak Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = WhiteOak(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path, df = object.check_and_highlight(path, 9)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 9, 11, 13, 15, 17, 19, 20, 21, 23, 25, 26, 28, 30, 32, 34, 35]\n",
    "\n",
    "# data = object.get_data_via_clip(path,pages,title)\n",
    "# extracted_text = object.get_generated_content(data)\n",
    "# final_text = object.refine_extracted_data(extracted_text)\n",
    "# final_text = Helper.drop_empty_dict_values(final_text)\n",
    "# Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ZERODHA MAIN CODE\"\"\" \n",
    "\n",
    "amc_name = 'Zerodha Mutual Fund'\n",
    "logging.info(f\"User Ran Fund Data of {amc_name}\")\n",
    "\n",
    "object = Zerodha(PATHS_CONFIG,amc_name)\n",
    "path = mutual_fund[amc_name]\n",
    "\n",
    "path,df= object.check_and_highlight(path,7)\n",
    "title = df.title.to_dict()\n",
    "pages = [3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "nd1 = object.get_data_via_line(path,pages,'left',title)\n",
    "nd2 = object.get_data_via_line(path,pages,'right',title) \n",
    "\n",
    "data = Helper.merge_nested_dicts(nd1,nd2)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILES TO BE CLEANED ARE BELOW , DATA ABLE TO EXTRACTED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"QUANT MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = QuantMF(PATHS_CONFIG)\n",
    "path = mutual_fund['Quant Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 61, 63, 65]\n",
    "\n",
    "\"\"\"\"HSBC MAIN FILE CODE\"\"\" #Issue: Some pages have 2 or more fund data on same page\n",
    "#some data is present on right side as well so define two lines\n",
    "#objective is to be exracted seperately\n",
    "\n",
    "object = HSBC(PATHS_CONFIG)\n",
    "path = mutual_fund['HSBC Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "\"\"\"PGIM MUTUAL FUND\"\"\"\n",
    "\n",
    "object = PGIM(PATHS_CONFIG)\n",
    "path = mutual_fund['PGIM India Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(path, 7)\n",
    "pages = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34]\n",
    "title = df.title.apply(lambda x: \"PGIM \"+x if not x == \"\" else x).to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\Kaustubh.keny\\OneDrive - Cogencis Information Services Ltd\\Documents\\mywork-repo\\data\\ex'\n",
    "all_keys = set()\n",
    "for file in os.listdir(folder_path):\n",
    "     if file.endswith(\".json\"):\n",
    "        path = os.path.join(folder_path, file)\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "            for fund,content in data.items():\n",
    "                for key in content.keys():\n",
    "                    all_keys.add(key)\n",
    "\n",
    "all_keys = list(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "folder_path = r'C:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\\data\\dsp'\n",
    "def extract_keys(data, key_set):\n",
    "    \"\"\"Recursively extract keys from JSON data, ignoring the first level.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            key_set.add(key)\n",
    "            extract_keys(value, key_set)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            extract_keys(item, key_set)\n",
    "\n",
    "file_keys = {} \n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".json\"):\n",
    "        path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                unique_keys = set() \n",
    "                for fund_data in data.values():  #first level is fund head\n",
    "                    if isinstance(fund_data, dict):  # Ensure it's a dictionary\n",
    "                        extract_keys(fund_data, unique_keys)\n",
    "                \n",
    "                \n",
    "                match = re.findall(r'^dump_([A-Za-z0-9]+).*\\.json',file,re.IGNORECASE)[0].upper()\n",
    "                file_keys[match] = list(unique_keys)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dict([(k, pd.Series(sorted(v))) for k, v in file_keys.items()]))\n",
    "\n",
    "output_path =\"json_keys.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

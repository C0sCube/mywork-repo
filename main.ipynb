{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pprint, json, os\n",
    "import fitz\n",
    "\n",
    "ROOT = os.getcwd()#root directory\n",
    "PATHS_CONFIG =os.path.join(ROOT,'data\\\\config\\\\paths.json')\n",
    "\n",
    "with open(PATHS_CONFIG,'r') as file:\n",
    "    PATH = json.load(file)\n",
    "\n",
    "from app.fundData import *\n",
    "from app.helper import Helper\n",
    "from log_config import logging\n",
    "\n",
    "mutual_fund = Helper.get_fund_paths(PATH['directories']['fund_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WHITEOAK MAIN FILE CODE\"\"\" #Issue: Inv Obj in the right #Fund Manager Data\n",
    "object = WhiteOak(PATHS_CONFIG)\n",
    "file_path = mutual_fund['WhiteOak Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 6)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 9, 11, 13, 15, 17, 19, 20, 21, 23, 25, 26, 28, 30, 32, 34, 35]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''360 ONE MAIN FILE CODE''' #No issues as of now\n",
    "\n",
    "object = ThreeSixtyOne(PATHS_CONFIG)\n",
    "file_path = mutual_fund['360 ONE Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "data = object.get_data_via_line(file_path,pages,'left',title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MAHINDRA MANULIFE MAIN CODE\"\"\" #incrase pages count\n",
    "\n",
    "object = MahindraManu(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Mahindra Manulife Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = object.get_proper_fund_names(file_path,[i for i in range(1,80)])\n",
    "pages = [i for i in range(8,34)]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"JM FUND MAIN FILE CODE\"\"\" #objective on left, sometimes date is with header\n",
    "\n",
    "object = JMMF(PATHS_CONFIG)\n",
    "file_path = mutual_fund['JM Financial Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INVESCO MF MAIN FILE CODE\"\"\" #Issue: two fund on same page\n",
    "\n",
    "object = Invesco(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Invesco Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SAMCO PDF FILE MAIN CODE\"\"\" #Issues: TTER data regex rst fine !!\n",
    "\n",
    "object = Samco(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Samco Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages =  [3, 5, 7, 9, 11, 13, 15, 17, 18]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "# final_text = object.refine_extracted_data(extracted_text)\n",
    "# Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TATA FILE MAIN CODE \"\"\"\n",
    "object = Tata(PATHS_CONFIG)\n",
    "file_path = mutual_fund[\"Tata Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 10)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = Helper.drop_empty_dict_values(extracted_text)\n",
    "final_text = object.refine_extracted_data(final_text)\n",
    "# Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" FRANKLIN TEMPLETON FILE MAIN CODE\"\"\"\n",
    "\n",
    "object = FranklinTempleton(PATHS_CONFIG)\n",
    "file_path = mutual_fund[\"Franklin Templeton Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 6)\n",
    "title = df.title.to_dict()\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,[r'expense'])\n",
    "# final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BANDHAN MF FILE MAIN CODE\"\"\" # rgex for fund manager\n",
    "\n",
    "object = Bandhan(PATHS_CONFIG)\n",
    "file_path = mutual_fund[\"Bandhan Mutual Fund\"]\n",
    "\n",
    "path, df = object.check_and_highlight(file_path,6)\n",
    "pages = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"KOTAK FUND MAIN CODE\"\"\" #Issue: 1 or more fund on same page, # title overlap the content\n",
    "object = Kotak(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Kotak Mahindra Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 40, 41, 43, 44, 46, 48, 49, 50, 52, 54, 55, 56, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,[r'^(folio|idcw|ideal|before|avalaible).*'])\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ZERODHA MAIN CODE\"\"\" \n",
    "\n",
    "object = Zerodha(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Zerodha Mutual Fund']\n",
    "\n",
    "path,df= object.check_and_highlight(file_path,7)\n",
    "title = df.title.to_dict()\n",
    "pages = [3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "nd1 = object.get_data_via_line(file_path,pages,'left',title)\n",
    "nd2 = object.get_data_via_line(file_path,pages,'right',title) \n",
    "\n",
    "data = Helper.merge_nested_dicts(nd1,nd2)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NAVI MAIN FILE CODE\"\"\" #Issue: Left and right\n",
    "\n",
    "object = NAVI(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Navi Mutual Fund']\n",
    "\n",
    "\n",
    "path,df = object.check_and_highlight(file_path,5)\n",
    "title = df.title.to_dict()\n",
    "pages = [2, 6, 8, 10, 13, 16, 18, 20, 22]\n",
    "\n",
    "nd1 = object.get_data_via_line(file_path,pages,'left',title)\n",
    "nd2 = object.get_data_via_line(file_path,pages,'right',title)\n",
    "\n",
    "data = Helper.merge_nested_dicts(nd1, nd2)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,['^(industry_allocation|equity|this_product).*'])\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BARODA BNP MAIN FILE CODE\"\"\" #Issue: Header funds #scheme details\n",
    "\n",
    "object = BarodaBNP(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Baroda BNP Paribas Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
    "title = object.get_proper_fund_names(file_path, pages, (0,0,210,75))\n",
    "\n",
    "data = object.get_data_via_line(file_path,pages,'left',title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,[r\"^(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec).*\",r'^key_statistics',r'^the_risk_free_rate_of_retu'])\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MOTILAL OSWAL MAIN CODE FILE\"\"\" #Fund Manager Regex\n",
    "\n",
    "object = MotilalOswal(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Motilal Oswal Mutual Fund']\n",
    "\n",
    "path,df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [i for i in range(4,21)]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"HELIOS MF FILE MAIN CODE\"\"\" #fund manager \n",
    "\n",
    "object = Helios(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Helios Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path,6)\n",
    "title = df.title.to_dict()\n",
    "pages =  [2, 4, 6, 8, 10]\n",
    "\n",
    "data = object.get_data_via_line(file_path,pages,'left',title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "# final_text = object.refine_extracted_data(extracted_text)\n",
    "# final_text = Helper.drop_keys_by_regex(final_text,[r'^(An open|Large).*'])\n",
    "# Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EDELWEISS MP FILE MAIN CODE\"\"\" #Issues: objective in seperate dict, scheme launch date issue\n",
    "\n",
    "object = Edelweiss(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Edelweiss Mutual Fund']\n",
    "\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 6)\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75]\n",
    "title,objectives = object.get_proper_fund_names(file_path,pages)\n",
    "\n",
    "data = object.get_data_via_line(file_path,pages,'right',title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NJMF MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = NJMF(PATHS_CONFIG)\n",
    "file_path = mutual_fund['NJ Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "pages = [1, 3, 5, 7, 9]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SUNDARAM MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = Sundaram(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Sundaram Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "\n",
    "data = object.get_data_via_line(file_path,pages,\"left\",title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,['^performance','market_capital','since_inception','^last','period'])\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ITI MAIN FILE CODE\"\"\" #Issues: more data cleaning\n",
    "\n",
    "object = ITI(PATHS_CONFIG)\n",
    "file_path = mutual_fund['ITI Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text,['this_product_is_suitable','before'])\n",
    "# final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MIRAE MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = MIRAE(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Mirae Asset Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "pages = [25, 26, 27, 28, 29, 30, 31, 32, 33, 34,35, 36, 37, 38, 39, 40, 41,42,43,44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,61,62,63,64, 65, 66, 67, 68]\n",
    "title = object.get_proper_fund_names(file_path,pages)\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_keys_by_regex(final_text,[r'others'])\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BANK OF INDIA\"\"\" #Issues: Fund Manger extraction\n",
    "object = BankOfIndia(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Bank of India Mutual Fund']\n",
    "\n",
    "path, df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "\n",
    "nd1 = object.get_data_via_line(file_path,pages,'left',title)\n",
    "nd2 = object.get_data_via_line(file_path,pages,'right',title)\n",
    "\n",
    "data = Helper.merge_nested_dicts(nd1,nd2)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "\n",
    "final_clean_text = Helper.drop_empty_dict_values(extracted_text)\n",
    "final_text = object.refine_extracted_data(final_clean_text)\n",
    "final_clean_text = Helper.drop_keys_by_regex(final_text, [r'^(december|total|who_|treasury|cretificate_of|equity|this_produc).*'])\n",
    "Helper.quick_json_dump(final_clean_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TAURUS MAIN FILE CODE\"\"\" #Issues: Nothing Yet\n",
    "\n",
    "object = Taurus(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Taurus Mutual Fund']\n",
    "\n",
    "# path, df= object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [13, 14, 15, 16, 17, 19, 20]\n",
    "\n",
    "data = object.get_data_via_line(file_path,pages,'left',title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRUST MAIN FILE CODE\"\"\" #Issue: Clean data more, nested dict unload Invest Obj in right #Names coming as headers fund managers\n",
    "\n",
    "object = Trust(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Trust Mutual Fund']\n",
    "\n",
    "path, df= object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "# Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CANARA MUTUAL FUND\"\"\" \n",
    "\n",
    "object = Canara(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Canara Robeco Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "#segments\n",
    "nd1 = object.get_data_via_clip(file_path,pages,title)\n",
    "nd2 = object.get_data_via_clip(file_path,pages,title,[(220,115,400,812)])\n",
    "\n",
    "data = Helper.merge_key_values(nd1,nd2)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "\n",
    "\n",
    "final_text = Helper.merge_key_values(extracted_text,'fund_information','before')\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text,['portfolio','product_positioning'])\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BAJAJ FINSERV MAIN FILE CODE\"\"\" #major issue of lines #minor of dropping keys of final dict\n",
    "\n",
    "object = BajajFinServ(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Bajaj finserv Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "pages = [15, 17, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "#segmants\n",
    "nd1 = object.get_data_via_line(file_path,pages,'left',title)\n",
    "nd2 = object.get_data_via_clip(file_path,pages,title,[(180,45,360,300)])\n",
    "nd3 = object.get_data_via_clip(file_path,pages,title,[(360,45,580,300)])\n",
    "\n",
    "\n",
    "data = Helper.merge_nested_dicts(nd1,nd2,nd3)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UTI MAIN FILE CODE\"\"\"\n",
    "\n",
    "object = UTI(PATHS_CONFIG)\n",
    "file_path = mutual_fund['UTI Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 46, 48, 50, 52, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77]\n",
    "\n",
    "data = object.get_data_via_line(file_path,pages,'left', title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_selected_dict_values(final_text,['high/low_nav_in_the_month','plans/options','porolio_details','market_capital'])\n",
    "Helper.quick_json_dump(final_text, object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NIPPON MUTUAL FUND\"\"\"\n",
    "\n",
    "object = Nippon(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Nippon India Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92]\n",
    "title = df.title.to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"QUANTUM MAIN FILE CODE\"\"\" #ISSUES: Clean data further\n",
    "\n",
    "object = Quantum(PATHS_CONFIG)\n",
    "file_path = mutual_fund[\"Quantum Mutual Fund\"]\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 28, 29, 30]\n",
    " \n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UNION MUTUAL FUND\"\"\" #Issues: Clean Further\n",
    "\n",
    "object = Union(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Union Mutual Fund']\n",
    "\n",
    "# path,df = object.check_and_highlight(file_path, 7)\n",
    "pages = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,]\n",
    "title = df.title.apply(lambda x: \"Union \"+ x if x !=\"\" else x).to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "# Helper.quick_json_dump(final_text,json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILES TO BE CLEANED ARE BELOW , DATA ABLE TO EXTRACTED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"QUANT MAIN CODE FILE\"\"\"\n",
    "\n",
    "object = QuantMF(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Quant Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 61, 63, 65]\n",
    "\n",
    "\"\"\"\"HSBC MAIN FILE CODE\"\"\" #Issue: Some pages have 2 or more fund data on same page\n",
    "#some data is present on right side as well so define two lines\n",
    "#objective is to be exracted seperately\n",
    "\n",
    "object = HSBC(PATHS_CONFIG)\n",
    "file_path = mutual_fund['HSBC Mutual Fund']\n",
    "\n",
    "path, df = object.check_and_highlight(file_path, 7)\n",
    "title = df.title.to_dict()\n",
    "pages = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PGIM MUTUAL FUND\"\"\"\n",
    "\n",
    "object = PGIM(PATHS_CONFIG)\n",
    "file_path = mutual_fund['PGIM India Mutual Fund']\n",
    "\n",
    "path,df = object.check_and_highlight(file_path, 7)\n",
    "pages = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34]\n",
    "title = df.title.apply(lambda x: \"PGIM \"+x if not x == \"\" else x).to_dict()\n",
    "\n",
    "data = object.get_data_via_clip(file_path,pages,title)\n",
    "extracted_text = object.get_generated_content(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DSP MAIN FILE CODE\"\"\" #Issue: highlight count must be lower\n",
    "#Issue: data on both side ends so issue coming\n",
    "\n",
    "object = DSP(PATHS_CONFIG)\n",
    "file_path = mutual_fund['DSP Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 5)\n",
    "\n",
    "title = df.title.to_dict()\n",
    "pages = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]\n",
    "\n",
    "#segments\n",
    "nd1 = object.get_data_via_clip(file_path, pages,title)\n",
    "nd2 = object.get_data_via_clip(file_path, pages,title,[(480,5,596,812)])\n",
    "\n",
    "data = Helper.merge_nested_dicts(nd1,nd2)\n",
    "extracted_text = object.get_generated_content(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ADITYA BIRLA FILE CODE\"\"\" #Issue: highlight count must be lower\n",
    "#Issue: data on both side ends so issue coming\n",
    "\n",
    "object = AdityaBirla(PATHS_CONFIG)\n",
    "file_path = mutual_fund['Aditya Birla Sun Life Mutual Fund']\n",
    "\n",
    "# path, df = object.check_and_highlight(file_path, 16)\n",
    "title = df.title.to_dict()\n",
    "pages = [12, 14, 16, 18, 20, 22, 24, 26, 27, 28, 30, 32, 34, 35, 36, 38, 40, 44, 47, 49, 53, 55, 57, 61, 63, 66, 68, 69, 72, 73, 74, 75, 76, 78, 80, 81, 85, 95, 102, 104, 108, 110, 112, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 141, 143, 147, 149, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 170, 171, 172, 173, 174]\n",
    "\n",
    "#segments\n",
    "nd1 = object.get_data_via_clip(file_path,pages,title)\n",
    "nd2 = object.get_data_via_clip(file_path,pages,title,[(200, 50, 380, 812)])\n",
    "nd3 = object.get_data_via_clip(file_path,pages,title,[(380, 50, 580, 812)])\n",
    "\n",
    "data = Helper.merge_nested_dicts(nd1, nd2,nd3)\n",
    "extracted_text = object.get_generated_content(data)\n",
    "final_text = object.refine_extracted_data(extracted_text)\n",
    "final_text = Helper.drop_empty_dict_values(final_text)\n",
    "Helper.quick_json_dump(final_text,object.JSONPATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1818d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import json, os, re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "fund_names = [\"360 ONE Mutual Fund\", \"Aditya Birla Sun Life Mutual Fund\", \"Axis Mutual Fund\", \"Angel One Mutual Fund\",\n",
    "              \"BajaJ Finserv Mutual Fund\", \"Bandhan Mutual Fund\", \"Bank of India Mutual Fund\", \n",
    "              \"Baroda BNP Paribas Mutual Fund\", \"Canara Robeco Mutual Fund\", \"DSP Mutual Fund\", \n",
    "              \"Edelweiss Mutual Fund\", \"Franklin Templeton Mutual Fund\", \"Groww Mutual Fund\", \n",
    "              \"HDFC Mutual Fund\", \"Helios Mutual Fund\", \"HSBC Mutual Fund\", \"ICICI Prudential Mutual Fund\",\n",
    "              \"Invesco Mutual Fund\", \"ITI Mutual Fund\", \"JM Financial Mutual Fund\", \"Kotak Mahindra Mutual Fund\",\n",
    "              \"PGIM India Mutual Fund\", \"LIC Mutual Fund\", \"Mahindra Manulife Mutual Fund\", \"Mirae Asset Mutual Fund\", \n",
    "              \"Motilal Oswal Mutual Fund\", \"Navi Mutual Fund\", \"Nippon India Mutual Fund\", \"NJ Mutual Fund\", \n",
    "              \"Old Bridge Mutual Fund\", \"PPFAS Mutual Fund\", \"Quantum Mutual Fund\", \"Quant Mutual Fund\", \n",
    "              \"Samco Mutual Fund\", \"SBI Mutual Fund\", \"Shriram Mutual fund\", \"Sundaram Mutual Fund\", \"Tata Mutual Fund\", \n",
    "              \"Taurus Mutual Fund\", \"Trust Mutual Fund\", \"Union Mutual Fund\", \"UTI Mutual Fund\", \"WhiteOak Mutual Fund\", \"Zerodha Mutual Fund\"]\n",
    "\n",
    "column_mapping = {\n",
    "    \"id\": \"id\",\n",
    "    \"entered_time\": \"entered_date\",\n",
    "    \"amc_for_month\": \"amc_for_month\",\n",
    "    \"data_from\": \"data_from\",\n",
    "    \"amc_name\": \"amc_name\",\n",
    "    \"main_scheme_name\": \"main_scheme_name\",\n",
    "    \"fund_name\": \"fund_name\",\n",
    "    \"benchmark_index\": \"benchmark_index\",\n",
    "    \"monthly_aaum_date\": \"monthly_aaum_date\",\n",
    "    \"monthly_aaum_value\": \"monthly_aaum_value\",\n",
    "    \"scheme_launch_date\": \"scheme_launch_date\",\n",
    "    \"min_addl_amt\": \"min_addl_amt\",\n",
    "    \"min_addl_amt_multiple\": \"min_addl_amt_multiple\",\n",
    "    \"min_amt\": \"min_amt\",\n",
    "    \"min_amt_multiple\": \"min_amt_multiple\",\n",
    "    \"entry_load\": \"entry_load\",\n",
    "    \"exit_load\": \"exit_load\",\n",
    "    \"alpha\": \"alpha\",\n",
    "    \"arithmetic_mean_ratio\": \"arithmetic_mean_ratio\",\n",
    "    \"average_div_yld\": \"average_div_yield\",\n",
    "    \"average_pb\": \"average_pb\",\n",
    "    \"average_pe\": \"average_pe\",\n",
    "    \"avg_maturity\": \"avg_maturity\",\n",
    "    \"beta\": \"beta\",\n",
    "    \"correlation_ratio\": \"correlation_ratio\",\n",
    "    \"downside_deviation\": \"downside_deviation\",\n",
    "    \"information_ratio\": \"information_ratio\",\n",
    "    \"macaulay\": \"macaulay\",\n",
    "    \"mod_duration\": \"mod_duration\",\n",
    "    \"port_turnover_ratio\": \"port_turnover_ratio\",\n",
    "    \"r_squared_ratio\": \"r_squared_ratio\",\n",
    "    \"roe_ratio\": \"roe_ratio\",\n",
    "    \"sharpe\": \"sharpe\",\n",
    "    \"sortino_ratio\": \"sortino_ratio\",\n",
    "    \"std_dev\": \"std_dev\",\n",
    "    \"tracking_error\": \"tracking_error\",\n",
    "    \"treynor_ratio\": \"treynor_ratio\",\n",
    "    \"upside_deviation\": \"upside_deviation\",\n",
    "    \"ytm\": \"ytm\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mydata\n",
    "# conn = mysql.connector.connect(\n",
    "#     host=\"172.22.225.155\",\n",
    "#     user=\"cog_mf\",\n",
    "#     password=\"bnYwFChjLAV2Z%9E\",\n",
    "#     database=\"cog_mf\",\n",
    "#     port=3306,\n",
    "#     charset='utf8mb4'\n",
    "# )\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",   \n",
    "    user=\"root\",            \n",
    "    password=\"1234\", \n",
    "    database=\"cog_updated_db\",  \n",
    "    port=3306,               \n",
    "    charset=\"utf8mb4\"\n",
    ")\n",
    "\n",
    "# conn = mysql.connector.connect(\n",
    "#     host=\"localhost\",   \n",
    "#     user=\"root\",            \n",
    "#     password=\"1234\", \n",
    "#     database=\"data_db\",  \n",
    "#     port=3306,               \n",
    "#     charset=\"utf8mb4\"\n",
    "# )\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "output_path = f\"march_self_{timestamp}.xlsx\"\n",
    "# data_from_value = \"my_data\"\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "    queries_dict = {}\n",
    "    workbook = writer.book\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7E4BC',\n",
    "        'border': 1\n",
    "    })\n",
    "    \n",
    "    for fund in fund_names:\n",
    "        search_fund = re.sub(r'mutual fund', '', fund, flags=re.IGNORECASE).strip()\n",
    "        query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM mf_common_fund_data\n",
    "        WHERE amc_name LIKE %s\n",
    "        AND amc_for_month REGEXP 'MAR25|FEB25' AND data_from LIKE \"%mydata%\"\n",
    "        AND entered_time LIKE \"%2025-05-08%\";\n",
    "        \"\"\"\n",
    "        # AND (monthly_aaum_date REGEXP \"202503|March 2025\" OR monthly_aaum_date IS NULL)\n",
    "        # AND data_from REGEXP \"mydata\"\n",
    "        \n",
    "        # query = \"\"\"\n",
    "        # SELECT *\n",
    "        # FROM mf_common_fund_manager_data\n",
    "        # WHERE amc_name LIKE %s\"\"\"\n",
    "        \n",
    "        queries_dict[sheet_name] = (\n",
    "            fund,\n",
    "            query.strip(),\n",
    "            f\"LIKE: %{search_fund}%,\"\n",
    "        )\n",
    "        \n",
    "        df = pd.read_sql(query, conn, params=(f\"%{search_fund}%\",))\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"Skipped (no data): {fund}\")\n",
    "            continue\n",
    "        \n",
    "        df.drop_duplicates(inplace=True)\n",
    "        # df.drop(columns=[\"id\",\"amc_id\",\"fund_id\",\"entered_time\",\"amc_name\",\"fund_name\"], axis=1, inplace=True)\n",
    "        \n",
    "        first = \"main_scheme_name\"\n",
    "        cols = [first]+[col for col in df.columns if col!=first]\n",
    "        \n",
    "        df = df[cols]\n",
    "        \n",
    "        sheet_name = \"_\".join(search_fund.lower().split())[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "        for col_num, header in enumerate(df.columns.values):\n",
    "            worksheet.write(0, col_num, header, header_format)\n",
    "            worksheet.set_column(col_num, col_num, min(len(header) + 8, 50))\n",
    "\n",
    "        #add query content to excel sheet\n",
    "        query_rows = [\n",
    "        {\"Fund\": fund, \"Query\": q, \"Params\": p}\n",
    "        for sheet, (fund, q, p) in queries_dict.items()\n",
    "        ]\n",
    "        queries_df = pd.DataFrame(query_rows)\n",
    "        queries_df.to_excel(writer, sheet_name=\"Queries\", index=False)\n",
    "\n",
    "        query_ws = writer.sheets[\"Queries\"]\n",
    "        for col_num, header in enumerate(queries_df.columns):\n",
    "            query_ws.write(0, col_num, header, header_format)\n",
    "            query_ws.set_column(col_num, col_num, 50)\n",
    "        \n",
    "print(f\"Done! Exported to: {output_path}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finklivedb\n",
    "# query = \"\"\"\n",
    "#             SELECT *\n",
    "#             FROM mf_json_common_details\n",
    "#             WHERE (monthly_aaum_date REGEXP '2025|FEBRU' OR monthly_aaum_date IS NULL)\n",
    "#               AND fund_name LIKE %s\n",
    "#         \"\"\"\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"172.22.225.155\",\n",
    "    user=\"cog_mf\",\n",
    "    password=\"bnYwFChjLAV2Z%9E\",\n",
    "    database=\"cog_mf\",\n",
    "    port=3306,\n",
    "    charset='utf8mb4'\n",
    ")\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "output_path = f\"march_live_{timestamp}.xlsx\"\n",
    "data_from_value = \"cog_mf\"\n",
    "aaum_date = '202503|202502|MARCH 2025|FEBRUARY 2025'\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "    queries_dict = {}\n",
    "    workbook = writer.book\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7E4BC',\n",
    "        'border': 1\n",
    "    })\n",
    "    \n",
    "    for fund in fund_names:\n",
    "        search_fund = re.sub(r'mutual fund', '', fund, flags=re.IGNORECASE).strip()\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            d.*,\n",
    "            MAX(COALESCE(d.benchmark_index, bi.benchmark_index)) AS final_benchmark_index,\n",
    "            MAX(bi.riskometer_benchmark) AS riskometer_benchmark,\n",
    "            MAX(CASE WHEN l.type = 'Entry' THEN l.comment END) AS entry_load,\n",
    "            MAX(CASE WHEN l.type = 'Exit' THEN l.comment END) AS exit_load\n",
    "        FROM mf_json_common_details d\n",
    "        LEFT JOIN mf_json_loads l\n",
    "        ON d.MainScheme_ID = l.MainScheme_ID\n",
    "        AND d.document_detail_id = l.document_detail_id\n",
    "        LEFT JOIN mf_json_benchmark_indices bi\n",
    "        ON d.MainScheme_ID = bi.MainScheme_ID\n",
    "        AND d.document_detail_id = bi.document_detail_id\n",
    "        WHERE d.fund_name LIKE %s\n",
    "        AND d.monthly_aaum_date REGEXP %s\n",
    "        GROUP BY d.id;\n",
    "        \"\"\"\n",
    "        #  AND (d.monthly_aaum_date REGEXP '202503|MARCH' OR d.monthly_aaum_date IS NULL)\n",
    "        \n",
    "        queries_dict[sheet_name] = (\n",
    "            fund,\n",
    "            query.strip(),\n",
    "            f\"LIKE: %{search_fund}%, REGEXP: {aaum_date}\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "        df = pd.read_sql(query, conn, params=(f\"%{search_fund}%\",aaum_date))\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"Skipped (no data): {fund}\")\n",
    "            continue\n",
    "        \n",
    "        #promote nonempty aaum_date\n",
    "        df = df.sort_values(by='monthly_aaum_date', key=lambda col: col.isnull())\n",
    "        \n",
    "        df.insert(0, 'data_from', data_from_value)\n",
    "        cols = df.columns.tolist()\n",
    "        \n",
    "        # Move 'main_scheme_name' to second column position\n",
    "        if 'main_scheme_name' in cols:\n",
    "            cols.remove('main_scheme_name')\n",
    "            cols.insert(1, 'main_scheme_name')\n",
    "            df = df[cols]\n",
    "\n",
    "        df['benchmark_index'] = df['final_benchmark_index']\n",
    "        df.drop('final_benchmark_index', axis = 1, inplace=True)\n",
    "        \n",
    "        sheet_name = \"_\".join(search_fund.lower().split())[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "        for col_num, header in enumerate(df.columns.values):\n",
    "            worksheet.write(0, col_num, header, header_format)\n",
    "            worksheet.set_column(col_num, col_num, min(len(header) + 8, 50))\n",
    "\n",
    "        #add query content to excel sheet\n",
    "        query_rows = [\n",
    "        {\"Fund\": fund, \"Query\": q, \"Params\": p}\n",
    "        for sheet, (fund, q, p) in queries_dict.items()\n",
    "        ]\n",
    "        queries_df = pd.DataFrame(query_rows)\n",
    "        queries_df.to_excel(writer, sheet_name=\"Queries\", index=False)\n",
    "\n",
    "        query_ws = writer.sheets[\"Queries\"]\n",
    "        for col_num, header in enumerate(queries_df.columns):\n",
    "            query_ws.write(0, col_num, header, header_format)\n",
    "            query_ws.set_column(col_num, col_num, 50)\n",
    "            \n",
    "print(f\"Done! Exported to: {output_path}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd1e40ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
      "C:\\Users\\Kaustubh.keny\\AppData\\Local\\Temp\\ipykernel_6640\\2791599203.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "live_data = pd.read_excel(os.path.join(os.getcwd(),\"march_live_20250508_1054.xlsx\"), sheet_name=None)\n",
    "self_data = pd.read_excel(os.path.join(os.getcwd(),\"march_self_20250508_1109.xlsx\"), sheet_name=None)\n",
    "\n",
    "\n",
    "fund_names = list(live_data.keys())\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "output_path = f\"march_self_live_{timestamp}.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "    workbook = writer.book\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7E4BC',\n",
    "        'border': 1\n",
    "    })\n",
    "\n",
    "    for fund in fund_names:\n",
    "        df_live = live_data[fund].copy()\n",
    "\n",
    "        df_live[\"data_from\"] = \"livedb\"\n",
    "\n",
    "        df_offline = self_data.get(fund, pd.DataFrame()).copy()\n",
    "        if df_offline.empty:\n",
    "            df_combined = df_live\n",
    "        else:\n",
    "            # df_offline[\"data_from\"] = \"mydata\"\n",
    "            df_offline_renamed = df_offline.rename(columns=column_mapping)\n",
    "\n",
    "            df_offline_aligned = df_offline_renamed.reindex(columns=df_live.columns)\n",
    "\n",
    "            # Combine live + offline\n",
    "            df_combined = pd.concat([df_live, df_offline_aligned], ignore_index=True)\n",
    "\n",
    "        df_combined.to_excel(writer, sheet_name=fund, index=False)\n",
    "        worksheet = writer.sheets[fund]\n",
    "\n",
    "        for col_num, header in enumerate(df_combined.columns):\n",
    "            worksheet.write(0, col_num, header, header_format)\n",
    "            worksheet.set_column(col_num, col_num, min(len(header) + 8, 50))\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23974cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT \n",
    "    d.*,\n",
    "    COALESCE(d.benchmark_index, bi.benchmark_index) AS final_benchmark_index,\n",
    "    bi.riskometer_benchmark,\n",
    "    MAX(CASE WHEN l.type = 'Entry' THEN l.comment END) AS entry_load,\n",
    "    MAX(CASE WHEN l.type = 'Exit' THEN l.comment END) AS exit_load\n",
    "FROM mf_json_common_details d\n",
    "LEFT JOIN mf_json_loads l\n",
    "  ON d.MainScheme_ID = l.MainScheme_ID\n",
    " AND d.document_detail_id = l.document_detail_id\n",
    "LEFT JOIN mf_json_benchmark_indices bi\n",
    "  ON d.MainScheme_ID = bi.MainScheme_ID\n",
    " AND d.document_detail_id = bi.document_detail_id\n",
    "WHERE d.fund_name LIKE %s\n",
    "  AND (d.monthly_aaum_date REGEXP '202502|FEBRUARY' OR d.monthly_aaum_date IS NULL)\n",
    "GROUP BY d.id;\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5e1d5bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Config already loaded. Skipping re-initialization.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from app.config_loader import load_config_once\n",
    "conf = load_config_once(output_folder=\"SIDKIM\")\n",
    "import pdfplumber, camelot, pprint, json5,json, os, re\n",
    "import fitz #type: ignore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from app.fund_sid_data import *\n",
    "\n",
    "with open(\"config\\\\sid_params.json5\",\"r+\") as file:\n",
    "    params = json5.load(file)\n",
    "\n",
    "# with open(\"config\\\\sid_params.json5\",\"r+\") as file:\n",
    "#     params = json5.dump(params,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(),\"pdfs\",\"96_17078_Apr-2025_1746183006_SID.pdf\")\n",
    "object = AngelOne(amc_id=\"96\",path=path)\n",
    "temp_dict = {}\n",
    "temp_dict.update(object._parse_page_zero([0]))\n",
    "temp_dict.update(object._parse_scheme_table_data(\"5,6,7,8,9,10\"))\n",
    "temp_dict.update(object._parse_fund_manager_info(\"16,17\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e335c1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Running: refine_extracted_data\n",
      "Function Running: merge_and_select_data\n"
     ]
    }
   ],
   "source": [
    "object = AngelOne(amc_id=\"96\",path=path)\n",
    "data = object.refine_extracted_data(temp_dict)\n",
    "dfs = object.merge_and_select_data(data,sid_or_kim=\"sid\",special_func=False)\n",
    "with open(\"tempor.json\",\"w+\") as file:\n",
    "    json.dump(dfs,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3e8d365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tempor.json\",\"w+\") as file:\n",
    "    json.dump(temp_dict,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaca3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(),\"pdfs\",\"unifi1747199156275.pdf\")\n",
    "object = Unifi(amc_id=97, path=path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b62cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df1d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1541927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_managerial_data(self, main_key: str, data, pattern: str):\n",
    "        # print(\"running manager data\")\n",
    "        final_list = []\n",
    "        manager_regex = self.REGEX[pattern]\n",
    "        if not isinstance(data,list):\n",
    "            print(\"_extract_manager_data-> data not list\")\n",
    "            return list(data)\n",
    "        \n",
    "        for manager in data:\n",
    "            temp = {}\n",
    "            for key, val in manager.items():\n",
    "                clean_val = re.findall(manager_regex[key],val,re.IGNORECASE)\n",
    "                update_val = \" \".join(clean_val)\n",
    "                temp[key] = update_val\n",
    "            if temp[\"name\"]:\n",
    "                final_list.append(temp)\n",
    "        return {\"fund_manager\": final_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0de0af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(),\"pdfs\",\"unifi1747199772321.pdf\")\n",
    "path2 = os.path.join(os.getcwd(),\"pdfs\",\"SID-Angel-One-Nifty-50-Index-Fund-2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa68ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pdf_path = \"your_file.pdf\"\n",
    "table_bbox = (0, 190, 600, 500)  # (x0, top, x1, bottom)\n",
    "\n",
    "table_df = None\n",
    "text_lines = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        cropped = page.within_bbox(table_bbox)\n",
    "        table = cropped.extract_table()\n",
    "        if table:\n",
    "            table_df = pd.DataFrame(table[1:], columns=table[0])\n",
    "\n",
    "        full_text = page.extract_text()\n",
    "        if full_text:\n",
    "            text_lines.extend(full_text.splitlines())\n",
    "\n",
    "# Now you have:\n",
    "# table_df -> the DataFrame containing the table\n",
    "# text_lines -> list of all text lines on the page(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6896d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheme_tables = camelot.read_pdf(path, pages=\"1\", flavor='lattice',table_areas = [\"20, 190, 580, 600\"])\n",
    "df = pd.concat([table.df for table in scheme_tables], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bbcfc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"first_page.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff62d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e62232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_page_zero(path:str,amc:str,pages:list):\n",
    "    final_dict = {}\n",
    "    bbox_text = []\n",
    "    other_text = []\n",
    "    risk_bbox = params[amc][\"PARAMS\"][\"page_zero\"][\"bbox\"]\n",
    "    with fitz.open(path) as doc:\n",
    "        for pgn, page in enumerate(doc):\n",
    "            if pgn in pages:\n",
    "                bbox_text.append(page.get_text(\"text\", clip=risk_bbox).replace(\"\\n\", \"\"))\n",
    "                other_text.append(page.get_text(\"text\").replace(\"\\n\", \"\"))\n",
    "        final_dict[\"risk_bbox\"] = bbox_text\n",
    "        final_dict[\"other_text\"] = other_text\n",
    "    return final_dict\n",
    "\n",
    "def _detect_column_start_by_keywords(df,threshold,keywords): \n",
    "    for i in range(df.shape[1]):\n",
    "        col = df.iloc[:, i]\n",
    "        col_cleaned = col.dropna().astype(str)\n",
    "        col_cleaned = col_cleaned.apply(lambda x: re.sub(r\"\\s+\", \" \", x).strip())\n",
    "        col_cleaned = col_cleaned[col_cleaned.str.strip() != \"\"]\n",
    "\n",
    "        count = sum(any(kw in cell for kw in keywords) for cell in col_cleaned)\n",
    "\n",
    "        if count >= threshold:\n",
    "            return i\n",
    "    return 1\n",
    "\n",
    "def _parse_scheme_table_data(path:str,amc:str,pages:str):\n",
    "    final_dict = {}\n",
    "    \n",
    "    threshold = params[amc][\"PARAMS\"][\"table_data\"][\"threshold\"]\n",
    "    keywords = params[amc][\"PARAMS\"][\"table_data\"][\"keywords\"]\n",
    "    \n",
    "    scheme_tables = camelot.read_pdf(path, pages=pages, flavor='lattice')\n",
    "    \n",
    "    dfs = pd.concat([table.df for table in scheme_tables], ignore_index=True)\n",
    "    col_start = _detect_column_start_by_keywords(dfs,threshold=threshold,keywords=keywords)\n",
    "    dfs = dfs.iloc[:,col_start:]\n",
    "    # print(dfs.head(20))\n",
    "    dfs = dfs.applymap(lambda x: x.replace('\\n', ' ') if isinstance(x, str) else x) #applies to dataframe not series\n",
    "    dfs.iloc[:, 0] = dfs.iloc[:, 0].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    dfs.iloc[:, 0] = dfs.iloc[:, 0].ffill() #fill corresponding structure\n",
    "    dfs.columns = ['Title'] + [f'Data{i}' for i in range(1, dfs.shape[1])] #new col structure\n",
    "    \n",
    "    data_cols = [col for col in dfs.columns if col != 'Title']\n",
    "    for title, group_df in dfs.groupby('Title', sort=False):\n",
    "        title = re.sub(r\"[^A-Za-z0-9\\s]+\",\"\",title).strip()\n",
    "        title = re.sub(r\"\\s+\",\" \",title).strip()\n",
    "        title = \"_\".join(title.lower().split(\" \"))\n",
    "        \n",
    "        current_title_values = []\n",
    "        for index, row in group_df.iterrows():\n",
    "            for col_name in data_cols:\n",
    "                cell_value = row[col_name]\n",
    "                if isinstance(cell_value, str) and cell_value.strip() != '':\n",
    "                    current_title_values.append(cell_value)\n",
    "        final_dict[title] = current_title_values\n",
    "        \n",
    "    return final_dict\n",
    "\n",
    "def _parse_fund_manager_info(path:str,amc:str,pages:str):\n",
    "    \n",
    "    row_count = params[amc][\"PARAMS\"][\"manager_data\"][\"row_count\"]\n",
    "    match_order = params[amc][\"PARAMS\"][\"manager_data\"][\"order\"]\n",
    "    manager_tables = camelot.read_pdf(path, pages=pages, flavor='lattice')\n",
    "    dfs = pd.concat([table.df for table in manager_tables], ignore_index=True)\n",
    "    dfs = dfs.applymap(lambda x: x.replace('\\n', ' ') if isinstance(x, str) else x)\n",
    "    \n",
    "    data_rows = [list(row) for _, row in dfs.iterrows() if row.count()==row_count]\n",
    "    manager_list = []\n",
    "    for data_r in data_rows:\n",
    "        manager_list.append({\n",
    "            \"name\":data_r[match_order[\"name\"]],\n",
    "            \"experience\":data_r[match_order[\"experience\"]],\n",
    "            \"qualification\":data_r[match_order[\"qualification\"]],\n",
    "        })\n",
    "    return  {\"fund_manager\": manager_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "temp_dict.update(_parse_page_zero(path,\"59\",[0]))\n",
    "temp_dict.update(_parse_scheme_table_data(path,\"59\",\"5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21\"))\n",
    "temp_dict.update(_parse_fund_manager_info(path,\"59\",\"29,30\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "temp_dict.update(_parse_page_zero(path2,\"96\",[0]))\n",
    "temp_dict.update(_parse_scheme_table_data(path2,\"96\",\"5,6,7,8,9,10\"))\n",
    "temp_dict.update(_parse_fund_manager_info(path2,\"96\",\"16,17\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9eb75c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tempor.json\",\"w+\") as file:\n",
    "    json.dump(temp_dict,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

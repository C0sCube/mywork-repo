{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1d5bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config with output_folder = SIDKIM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from app.config_loader import load_config_once\n",
    "conf = load_config_once(output_folder=\"SIDKIM\")\n",
    "import pdfplumber, camelot, pprint, json5,json, os, re\n",
    "import fitz #type: ignore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from app.fund_sid_data import *\n",
    "\n",
    "with open(\"config\\\\sid_params.json5\",\"r+\") as file:\n",
    "    params = json5.load(file)\n",
    "\n",
    "# with open(\"config\\\\sid_params.json5\",\"r+\") as file:\n",
    "#     params = json5.dump(params,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afaca3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Running: _parse_fund_manager_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\\app\\parse_sid_pdf.py:192: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(),\"pdfs\",\"May SID\\\\DSP Mutual Fund\\\\8_17162_May-2025_1748246532_SID.pdf\")\n",
    "object = DSP(amc_id=\"8\", path=path)\n",
    "temp_dict = {}\n",
    "# temp_dict.update(object._parse_page_zero([0]))\n",
    "# temp_dict.update(object._parse_scheme_table_data(\"5,6,7,8\"))\n",
    "temp_dict.update(object._parse_fund_manager_info(\"21,22\"))\n",
    "# data = object.refine_extracted_data(temp_dict)\n",
    "# dfs = object.merge_and_select_data(data,sid_or_kim=\"sid\",special_func=False)\n",
    "# with open(\"tempor.json\",\"w+\") as file:\n",
    "#     json.dump(dfs,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a5f2be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Running: _parse_fund_manager_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\\app\\parse_sid_pdf.py:192: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(),\"pdfs\",\"May SID\\\\Tata Mutual Fund\\\\38_17082_May-2025_1746423571_SID.pdf\")\n",
    "object = Tata(amc_id=\"38\", path=path)\n",
    "temp_dict = {}\n",
    "# temp_dict.update(object._parse_page_zero([0]))\n",
    "# temp_dict.update(object._parse_scheme_table_data(\"3,4,5\"))\n",
    "temp_dict.update(object._parse_fund_manager_info(\"12\"))\n",
    "# data = object.refine_extracted_data(temp_dict)\n",
    "# dfs = object.merge_and_select_data(data,sid_or_kim=\"sid\",special_func=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01e48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Running: _parse_fund_manager_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\\app\\parse_sid_pdf.py:192: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(),\"pdfs\",\"May SID\\\\Nippon India Mutual Fund\\\\33_17142_May-2025_1747631690_SID.pdf\")\n",
    "object = Nippon(amc_id=\"33\", path=path)\n",
    "temp_dict = {}\n",
    "# temp_dict.update(object._parse_page_zero([0]))\n",
    "# temp_dict.update(object._parse_scheme_table_data(\"3,4,5,6,7\"))\n",
    "temp_dict.update(object._parse_fund_manager_info(\"11\"))\n",
    "# data = object.refine_extracted_data(temp_dict)\n",
    "# dfs = object.merge_and_select_data(data,sid_or_kim=\"sid\",special_func=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22442077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Running: _parse_fund_manager_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\\app\\parse_sid_pdf.py:192: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(),\"pdfs\",\"May SID\\\\SBI Mutual Fund\\\\35_17126_May-2025_1747282059_SID.pdf\")\n",
    "object = SBI(amc_id=\"35\", path=path)\n",
    "temp_dict = {}\n",
    "# temp_dict.update(object._parse_page_zero([0]))\n",
    "# temp_dict.update(object._parse_scheme_table_data(\"3,4,5\"))\n",
    "temp_dict.update(object._parse_fund_manager_info(\"13\"))\n",
    "# data = object.refine_extracted_data(temp_dict)\n",
    "# dfs = object.merge_and_select_data(data,sid_or_kim=\"sid\",special_func=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0117add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(),\"pdfs\",\"May SID\\\\Samco Mutual Fund\\\\58_17166_May-2025_1748246684_SID.pdf\")\n",
    "object = Samco(amc_id=\"58\", path=path)\n",
    "temp_dict = {}\n",
    "# temp_dict.update(object._parse_page_zero([0]))\n",
    "# temp_dict.update(object._parse_scheme_table_data(\"3,4,5\"))\n",
    "temp_dict.update(object._parse_fund_manager_info(\"14,15\"))\n",
    "# data = object.refine_extracted_data(temp_dict)\n",
    "# dfs = object.merge_and_select_data(data,sid_or_kim=\"sid\",special_func=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4575a93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Running: _parse_fund_manager_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rando\\OneDrive\\Documents\\mywork-repo\\app\\parse_sid_pdf.py:192: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(),\"pdfs\",\"May SID\\\\Baroda BNP Paribas Mutual Fund\\\\2_17091_May-2025_1746765998_SID.pdf\")\n",
    "object = BarodaBNP(amc_id=\"2\", path=path)\n",
    "temp_dict = {}\n",
    "# temp_dict.update(object._parse_page_zero([0]))\n",
    "# temp_dict.update(object._parse_scheme_table_data(\"3,4,5\"))\n",
    "temp_dict.update(object._parse_fund_manager_info(\"13,14\"))\n",
    "# data = object.refine_extracted_data(temp_dict)\n",
    "# dfs = object.merge_and_select_data(data,sid_or_kim=\"sid\",special_func=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0d981e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fund_manager': [{'name': 'Name of Fund Manager',\n",
       "   'experience': 'Previous Experience',\n",
       "   'qualification': 'Age & Qualifications'},\n",
       "  {'name': 'Mr. Prashant Pimple',\n",
       "   'experience': 'Mr. Prashant Pimple has an overall experience of 25 years. He is designated as Chief Investment Officer Fixed Income of Baroda BNP Paribas Asset Management India Private Limited. His previous stint was with JM Financial AMC as CIO Fixed',\n",
       "   'qualification': '47 years, BCom, MMS (Fin), ACTM'},\n",
       "  {'name': '',\n",
       "   'experience': 'Income. Prior to that, he has also worked with Nippon AMC',\n",
       "   'qualification': ''},\n",
       "  {'name': 'Mr. Neeraj Saxena',\n",
       "   'experience': 'Mr. Neeraj Saxena has rich experience of 21 years in the Indian financial services industry, handles the responsibility of being the Fund Manager & Dealer in equity domain for Baroda BNP Paribas AMC. Prior to joining BBNPP AMC, Mr. Saxena was the Assistant Vice President - Institutional Equity Sales at Stratcap Securities. He has also held notable positions like Head - Communication Cell at Karvy Stock Broking and Senior Investment Advisor at Iden Investment Advisor',\n",
       "   'qualification': '47 years, PGDBA Finance from Welingkars Institute, M.Sc. (Organic Chemistry)'}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ebb4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df1d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp.json\",\"w+\") as file:\n",
    "    json.dump(temp_dict,file)\n",
    "# with open(\"data.json\",\"w+\") as file:\n",
    "#     json.dump(data,file)\n",
    "# with open(\"dfs.json\",\"w+\") as file:\n",
    "#     json.dump(dfs,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e62232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _parse_page_zero(path:str,amc:str,pages:list):\n",
    "#     final_dict = {}\n",
    "#     bbox_text = []\n",
    "#     other_text = []\n",
    "#     risk_bbox = params[amc][\"PARAMS\"][\"page_zero\"][\"bbox\"]\n",
    "#     with fitz.open(path) as doc:\n",
    "#         for pgn, page in enumerate(doc):\n",
    "#             if pgn in pages:\n",
    "#                 bbox_text.append(page.get_text(\"text\", clip=risk_bbox).replace(\"\\n\", \"\"))\n",
    "#                 other_text.append(page.get_text(\"text\").replace(\"\\n\", \"\"))\n",
    "#         final_dict[\"risk_bbox\"] = bbox_text\n",
    "#         final_dict[\"other_text\"] = other_text\n",
    "#     return final_dict\n",
    "\n",
    "def _parse_page_zero(path: str, amc: str, pages: list) -> dict:\n",
    "    final_dict = {\"risk_bbox\": [], \"other_text\": []}\n",
    "    risk_bbox = params[amc][\"PARAMS\"][\"page_zero\"][\"bbox\"]\n",
    "\n",
    "    with fitz.open(path) as doc:\n",
    "        for pgn in pages:\n",
    "            page = doc[pgn]\n",
    "\n",
    "            def extract_sorted_text_blocks(clip_area=None):\n",
    "                blocks = page.get_text(\"dict\", clip=clip_area)[\"blocks\"]\n",
    "                text_blocks = []\n",
    "\n",
    "                for block in blocks:\n",
    "                    if block.get(\"type\") == 0:\n",
    "                        text = \"\"\n",
    "                        for line in block.get(\"lines\", []):\n",
    "                            for span in line.get(\"spans\", []):\n",
    "                                text += span.get(\"text\", \"\")\n",
    "                        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "                        if text:\n",
    "                            text_blocks.append((block[\"bbox\"], text))\n",
    "\n",
    "                return [text for _, text in sorted(text_blocks, key=lambda b: (b[0][1], b[0][0]))]\n",
    "\n",
    "            # Extract bbox text\n",
    "            final_dict[\"risk_bbox\"].extend(extract_sorted_text_blocks(clip_area=risk_bbox))\n",
    "\n",
    "            # Extract full text\n",
    "            final_dict[\"other_text\"].extend(extract_sorted_text_blocks())\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "def _detect_column_start_by_keywords(df, threshold, keywords):\n",
    "    normalized_keywords = [re.sub(r\"\\s+\", \" \", kw.strip().lower()) for kw in keywords]\n",
    "\n",
    "    for i in range(df.shape[1]):\n",
    "        col = df.iloc[:, i].dropna().astype(str)\n",
    "        col_cleaned = col.apply(lambda x: re.sub(r\"\\s+\", \" \", x).strip().lower())\n",
    "        col_cleaned = col_cleaned[col_cleaned != \"\"]\n",
    "\n",
    "        count = sum(any(kw in cell for kw in normalized_keywords) for cell in col_cleaned)\n",
    "\n",
    "        if count >= threshold:\n",
    "            return i\n",
    "    return 1\n",
    "\n",
    "def _parse_scheme_table_data(path:str,amc:str,pages:str):\n",
    "    final_dict = {}\n",
    "    \n",
    "    threshold = params[amc][\"PARAMS\"][\"table_data\"][\"threshold\"]\n",
    "    keywords = params[amc][\"PARAMS\"][\"table_data\"][\"keywords\"]\n",
    "    # print(keywords)\n",
    "    \n",
    "    scheme_tables = camelot.read_pdf(path, pages=pages, flavor='lattice')\n",
    "    \n",
    "    dfs = pd.concat([table.df for table in scheme_tables], ignore_index=True)\n",
    "    col_start = _detect_column_start_by_keywords(dfs,threshold=threshold,keywords=keywords)\n",
    "    # print(col_start)\n",
    "    \n",
    "    dfs = dfs.iloc[:,col_start:]\n",
    "    # print(dfs.head(20))\n",
    "    dfs = dfs.applymap(lambda x: x.replace('\\n', ' ') if isinstance(x, str) else x) #applies to dataframe not series\n",
    "    dfs.iloc[:, 0] = dfs.iloc[:, 0].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    dfs.iloc[:, 0] = dfs.iloc[:, 0].ffill() #fill corresponding structure\n",
    "    dfs.columns = ['Title'] + [f'Data{i}' for i in range(1, dfs.shape[1])] #new col structure\n",
    "    \n",
    "    data_cols = [col for col in dfs.columns if col != 'Title']\n",
    "    for title, group_df in dfs.groupby('Title', sort=False):\n",
    "        title = re.sub(r\"[^A-Za-z0-9\\s]+\",\"\",title).strip()\n",
    "        title = re.sub(r\"\\s+\",\" \",title).strip()\n",
    "        title = \"_\".join(title.lower().split(\" \"))\n",
    "        \n",
    "        current_title_values = []\n",
    "        for index, row in group_df.iterrows():\n",
    "            for col_name in data_cols:\n",
    "                cell_value = row[col_name]\n",
    "                if isinstance(cell_value, str) and cell_value.strip() != '':\n",
    "                    current_title_values.append(cell_value)\n",
    "        final_dict[title] = current_title_values\n",
    "        \n",
    "    return final_dict\n",
    "\n",
    "def _detect_manager_column_start_by_keywords(df, threshold, keywords):\n",
    "    normalized_keywords = [re.sub(r\"\\s+\", \" \", kw.strip().lower()) for kw in keywords]\n",
    "    first_keyword = normalized_keywords[0]\n",
    "\n",
    "    for i in range(df.shape[1]):\n",
    "        col = df.iloc[:, i].dropna().astype(str)\n",
    "        col_cleaned = col.apply(lambda x: re.sub(r\"\\s+\", \" \", x).strip().lower())\n",
    "        col_cleaned = col_cleaned[col_cleaned != \"\"]\n",
    "\n",
    "        count = sum(any(kw in cell for kw in normalized_keywords) for cell in col_cleaned)\n",
    "\n",
    "        if count >= threshold:\n",
    "            return i\n",
    "    return 1\n",
    "\n",
    "# def _parse_fund_manager_info(path:str,amc:str,pages:str):\n",
    "    \n",
    "    # row_count = params[amc][\"PARAMS\"][\"manager_data\"][\"row_count\"]\n",
    "    # match_order = params[amc][\"PARAMS\"][\"manager_data\"][\"order\"]\n",
    "#     print(row_count, match_order)\n",
    "#     manager_tables = camelot.read_pdf(path, pages=pages, flavor='lattice')\n",
    "#     dfs = pd.concat([table.df for table in manager_tables], ignore_index=True)\n",
    "#     dfs = dfs.applymap(lambda x: x.replace('\\n', ' ') if isinstance(x, str) else x)\n",
    "    \n",
    "#     data_rows = [list(row) for _, row in dfs.iterrows() if row.count()==row_count]\n",
    "#     manager_list = []\n",
    "#     for data_r in data_rows:\n",
    "#         manager_list.append({\n",
    "#             \"name\":data_r[match_order[\"name\"]],\n",
    "#             \"experience\":data_r[match_order[\"experience\"]],\n",
    "#             \"qualification\":data_r[match_order[\"qualification\"]],\n",
    "#         })\n",
    "#     return dfs, {\"fund_manager\": manager_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "temp_dict.update(_parse_page_zero(path,\"38\",[0]))\n",
    "temp_dict.update(_parse_scheme_table_data(path,\"38\",\"3,4,5\"))\n",
    "# temp_dict.update(_parse_fund_manager_info(path,\"38\",\"29,30\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envPDF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

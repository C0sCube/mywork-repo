{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e1d5bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pdfplumber, camelot, pprint, json5\n",
    "import fitz #type: ignore\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, os, re\n",
    "\n",
    "with open(\"config\\\\sid_params.json5\",\"r+\") as file:\n",
    "    params = json5.load(file)\n",
    "\n",
    "# with open(\"config\\\\sid_params.json5\",\"r+\") as file:\n",
    "#     params = json5.dump(params,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08df78c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | Tool      | Page Indexing | Example                  |\n",
    "# | --------- | ------------- | ------------------------ |\n",
    "# | `fitz`    | **0-based**   | `doc[0]` → first page    |\n",
    "# | `camelot` | **1-based**   | `pages=\"1\"` → first page |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0de0af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(),\"pdfs\",\"bajaj1727439432823.pdf\")\n",
    "path2 = os.path.join(os.getcwd(),\"pdfs\",\"SID-Angel-One-Nifty-50-Index-Fund-2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de7922",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "with fitz.open(path) as doc:\n",
    "    for i, page in enumerate(doc):\n",
    "        if i in [0]:\n",
    "            text = page.get_text(\"text\",clip =(5, 125, 190, 455)).split(\"\\n\")\n",
    "            for t in text:\n",
    "                all_data.append(t)\n",
    "# pprint.pprint(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae17204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_page_zero(path:str,amc:str,pages:list):\n",
    "    final_dict = {}\n",
    "    bbox_text = []\n",
    "    other_text = []\n",
    "    risk_bbox = params[amc][\"PARAMS\"][\"page_zero\"][\"bbox\"]\n",
    "    with fitz.open(path) as doc:\n",
    "        for pgn, page in enumerate(doc):\n",
    "            if pgn in pages:\n",
    "                bbox_text.append(page.get_text(\"text\", clip=risk_bbox).replace(\"\\n\", \"\"))\n",
    "                other_text.append(page.get_text(\"text\").replace(\"\\n\", \"\"))\n",
    "        final_dict[\"risk_bbox\"] = bbox_text\n",
    "        final_dict[\"other_text\"] = other_text\n",
    "    return final_dict\n",
    "\n",
    "def _detect_column_start_by_keywords(df,threshold,keywords): \n",
    "    for i in range(df.shape[1]):\n",
    "        col = df.iloc[:, i]\n",
    "        col_cleaned = col.dropna().astype(str)\n",
    "        col_cleaned = col_cleaned.apply(lambda x: re.sub(r\"\\s+\", \" \", x).strip())\n",
    "        col_cleaned = col_cleaned[col_cleaned.str.strip() != \"\"]\n",
    "\n",
    "        count = sum(any(kw in cell for kw in keywords) for cell in col_cleaned)\n",
    "\n",
    "        if count >= threshold:\n",
    "            return i\n",
    "    return 1\n",
    "\n",
    "def _parse_scheme_table_data(path:str,amc:str,pages:str):\n",
    "    final_dict = {}\n",
    "    \n",
    "    threshold = params[amc][\"PARAMS\"][\"table_data\"][\"threshold\"]\n",
    "    keywords = params[amc][\"PARAMS\"][\"table_data\"][\"keywords\"]\n",
    "    \n",
    "    scheme_tables = camelot.read_pdf(path, pages=pages, flavor='lattice')\n",
    "    \n",
    "    dfs = pd.concat([table.df for table in scheme_tables], ignore_index=True)\n",
    "    col_start = _detect_column_start_by_keywords(dfs,threshold=threshold,keywords=keywords)\n",
    "    dfs = dfs.iloc[:,col_start:]\n",
    "    # print(dfs.head(20))\n",
    "    dfs = dfs.applymap(lambda x: x.replace('\\n', ' ') if isinstance(x, str) else x) #applies to dataframe not series\n",
    "    dfs.iloc[:, 0] = dfs.iloc[:, 0].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    dfs.iloc[:, 0] = dfs.iloc[:, 0].ffill() #fill corresponding structure\n",
    "    dfs.columns = ['Title'] + [f'Data{i}' for i in range(1, dfs.shape[1])] #new col structure\n",
    "    \n",
    "    data_cols = [col for col in dfs.columns if col != 'Title']\n",
    "    for title, group_df in dfs.groupby('Title', sort=False):\n",
    "        title = re.sub(r\"[^A-Za-z0-9\\s]+\",\"\",title).strip()\n",
    "        title = re.sub(r\"\\s+\",\" \",title).strip()\n",
    "        title = \"_\".join(title.lower().split(\" \"))\n",
    "        \n",
    "        current_title_values = []\n",
    "        for index, row in group_df.iterrows():\n",
    "            for col_name in data_cols:\n",
    "                cell_value = row[col_name]\n",
    "                if isinstance(cell_value, str) and cell_value.strip() != '':\n",
    "                    current_title_values.append(cell_value)\n",
    "        final_dict[title] = current_title_values\n",
    "        \n",
    "    return final_dict\n",
    "\n",
    "def _parse_fund_manager_info(path:str,amc:str,pages:str):\n",
    "    \n",
    "    row_count = params[amc][\"PARAMS\"][\"manager_data\"][\"row_count\"]\n",
    "    match_order = params[amc][\"PARAMS\"][\"manager_data\"][\"order\"]\n",
    "    manager_tables = camelot.read_pdf(path, pages=pages, flavor='lattice')\n",
    "    dfs = pd.concat([table.df for table in manager_tables], ignore_index=True)\n",
    "    dfs = dfs.applymap(lambda x: x.replace('\\n', ' ') if isinstance(x, str) else x)\n",
    "    \n",
    "    data_rows = [list(row) for _, row in dfs.iterrows() if row.count()==row_count]\n",
    "    manager_list = []\n",
    "    for data_r in data_rows:\n",
    "        manager_list.append({\n",
    "            \"name\":data_r[match_order[\"name\"]],\n",
    "            \"experience\":data_r[match_order[\"experience\"]],\n",
    "            \"qualification\":data_r[match_order[\"qualification\"]],\n",
    "        })\n",
    "    return  {\"fund_manager\": manager_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "temp_dict.update(_parse_page_zero(path,\"59\",[0]))\n",
    "temp_dict.update(_parse_scheme_table_data(path,\"59\",\"5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21\"))\n",
    "temp_dict.update(_parse_fund_manager_info(path,\"59\",\"29,30\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "temp_dict.update(_parse_page_zero(path2,\"96\",[0]))\n",
    "temp_dict.update(_parse_scheme_table_data(path2,\"96\",\"5,6,7,8,9,10\"))\n",
    "temp_dict.update(_parse_fund_manager_info(path2,\"96\",\"16,17\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9eb75c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tempor.json\",\"w+\") as file:\n",
    "    json.dump(temp_dict,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654ef80",
   "metadata": {},
   "source": [
    "MANAGER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envPDF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
